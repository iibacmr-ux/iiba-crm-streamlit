# Streamlit CRM IIBA Cameroun - app.py corrigÃ© et complet

from datetime import datetime, date, timedelta
from pathlib import Path
import io
import json
import re
import unicodedata
import numpy as np
import pandas as pd
import streamlit as st

# AgGrid
try:
    from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode, JsCode
    HAS_AGGRID = True
except Exception:
    HAS_AGGRID = False

# Graphiques Altair
try:
    import altair as alt
except Exception:
    alt = None

import openpyxl

st.set_page_config(page_title="IIBA Cameroun â€” CRM", page_icon="ğŸ“Š", layout="wide")

# ----------- Paths et schÃ©mas ----------------
DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)

PATHS = {
    "contacts": DATA_DIR / "contacts.csv",
    "inter": DATA_DIR / "interactions.csv",
    "events": DATA_DIR / "evenements.csv",
    "parts": DATA_DIR / "participations.csv",
    "pay": DATA_DIR / "paiements.csv",
    "cert": DATA_DIR / "certifications.csv",
    "params": DATA_DIR / "parametres.csv",
    "logs": DATA_DIR / "migration_logs.jsonl"
}

C_COLS = ["ID","Nom","PrÃ©nom","Genre","Titre","SociÃ©tÃ©","Secteur","Email","TÃ©lÃ©phone","LinkedIn",
          "Ville","Pays","Type","Source","Statut","Score_Engagement","Date_Creation","Notes","Top20"]
I_COLS = ["ID_Interaction","ID","Date","Canal","Objet","RÃ©sumÃ©","RÃ©sultat","Prochaine_Action","Relance","Responsable"]
E_COLS = ["ID_Ã‰vÃ©nement","Nom_Ã‰vÃ©nement","Type","Date","DurÃ©e_h","Lieu","Formateur","Objectif","Periode",
          "Cout_Salle","Cout_Formateur","Cout_Logistique","Cout_Pub","Cout_Autres","Cout_Total","Notes"]
P_COLS = ["ID_Participation","ID","ID_Ã‰vÃ©nement","RÃ´le","Inscription","ArrivÃ©e","Temps_Present","Feedback","Note","Commentaire"]
PAY_COLS = ["ID_Paiement","ID","ID_Ã‰vÃ©nement","Date_Paiement","Montant","Moyen","Statut","RÃ©fÃ©rence","Notes","Relance"]
CERT_COLS = ["ID_Certif","ID","Type_Certif","Date_Examen","RÃ©sultat","Score","Date_Obtention","ValiditÃ©","Renouvellement","Notes"]

ALL_SCHEMAS = {
    "contacts": C_COLS, "interactions": I_COLS, "evenements": E_COLS,
    "participations": P_COLS, "paiements": PAY_COLS, "certifications": CERT_COLS,
}

DEFAULT_LISTS = {
    "genres":"Homme|Femme|Autre",
    "secteurs":"Banque|TÃ©lÃ©com|IT|Ã‰ducation|SantÃ©|ONG|Industrie|Public|Autre",
    "types_contact":"Membre|Prospect|Formateur|Partenaire",
    "sources":"Afterwork|Formation|LinkedIn|Recommandation|Site Web|Salon|Autre",
    "statuts_engagement":"Actif|Inactif|Ã€ relancer",
    "canaux":"Appel|Email|WhatsApp|Zoom|PrÃ©sentiel|Autre",
    "villes":"Douala|YaoundÃ©|Limbe|Bafoussam|Garoua|Autres",
    "pays":"Cameroun|CÃ´te d'Ivoire|SÃ©nÃ©gal|France|Canada|Autres",
    "types_evenements":"Formation|Groupe d'Ã©tude|BA MEET UP|Webinaire|ConfÃ©rence|Certification",
    "lieux":"PrÃ©sentiel|Zoom|Hybride",
    "resultats_inter":"Positif|NÃ©gatif|Ã€ suivre|Sans suite",
    "statuts_paiement":"RÃ©glÃ©|Partiel|Non payÃ©",
    "moyens_paiement":"Mobile Money|Virement|CB|Cash",
    "types_certif":"ECBA|CCBA|CBAP|PBA",
    "entreprises_cibles":"Dangote|MUPECI|SALAM|SUNU IARD|ENEO|PAD|PAK",
}

PARAM_DEFAULTS = {
    "vip_threshold":"500000",
    "score_w_interaction":"1",
    "score_w_participation":"1",
    "score_w_payment_regle":"2",
    "interactions_lookback_days":"90",
    "rule_hot_interactions_recent_min":"3",
    "rule_hot_participations_min":"1",
    "rule_hot_payment_partial_counts_as_hot":"1",
    "grid_crm_columns": ",".join([
        "ID","Nom","PrÃ©nom","SociÃ©tÃ©","Type","Statut","Email",
        "Interactions","Participations","CA_rÃ©glÃ©","ImpayÃ©","Resp_principal","A_animÃ©_ou_invitÃ©",
        "Score_composite","Proba_conversion","Tags"
    ]),
    "grid_events_columns": ",".join(E_COLS),
    "kpi_enabled": ",".join([
        "contacts_total","prospects_actifs","membres","events_count",
        "participations_total","ca_regle","impayes","taux_conversion"
    ]),
    "kpi_target_contacts_total_year_2025":"1000",
    "kpi_target_ca_regle_year_2025":"5000000",
}

ALL_DEFAULTS = {**PARAM_DEFAULTS, **{f"list_{k}":v for k,v in DEFAULT_LISTS.items()}}

def load_params()->dict:
    if not PATHS["params"].exists():
        df = pd.DataFrame({"key":list(ALL_DEFAULTS.keys()), "value":list(ALL_DEFAULTS.values())})
        df.to_csv(PATHS["params"], index=False, encoding="utf-8")
        return ALL_DEFAULTS.copy()
    try:
        df = pd.read_csv(PATHS["params"], dtype=str).fillna("")
        d = {r["key"]: r["value"] for _,r in df.iterrows()}
    except Exception:
        d = ALL_DEFAULTS.copy()
    for k,v in ALL_DEFAULTS.items():
        if k not in d: d[k]=v
    return d

def save_params(d:dict):
    rows = [{"key":k,"value":str(v)} for k,v in d.items()]
    pd.DataFrame(rows).to_csv(PATHS["params"], index=False, encoding="utf-8")

PARAMS = load_params()

def get_list(name:str)->list:
    raw = PARAMS.get(f"list_{name}", DEFAULT_LISTS.get(name,""))
    vals = [x.strip() for x in str(raw).split("|") if x.strip()]
    return vals

SET = {
    "genres": get_list("genres"),
    "secteurs": get_list("secteurs"),
    "types_contact": get_list("types_contact"),
    "sources": get_list("sources"),
    "statuts_engagement": get_list("statuts_engagement"),
    "canaux": get_list("canaux"),
    "villes": get_list("villes"),
    "pays": get_list("pays"),
    "types_evenements": get_list("types_evenements"),
    "lieux": get_list("lieux"),
    "resultats_inter": get_list("resultats_inter"),
    "statuts_paiement": get_list("statuts_paiement"),
    "moyens_paiement": get_list("moyens_paiement"),
    "types_certif": get_list("types_certif"),
    "entreprises_cibles": get_list("entreprises_cibles"),
}

# Utils for dataframe loading/saving

def ensure_df(path:Path, cols:list)->pd.DataFrame:
    if path.exists():
        try: 
            df = pd.read_csv(path, dtype=str, encoding="utf-8")
        except Exception:
            df = pd.DataFrame(columns=cols)
    else:
        df = pd.DataFrame(columns=cols)
    for c in cols:
        if c not in df.columns:
            df[c]=""
    return df[cols]

def save_df(df:pd.DataFrame, path:Path):
    df.to_csv(path, index=False, encoding="utf-8")

def parse_date(s:str):
    if not s or str(s).strip()=="" or str(s).lower()=="nan":
        return None
    for fmt in ("%Y-%m-%d","%d/%m/%Y","%Y/%m/%d"):
        try:
            return datetime.strptime(str(s), fmt).date()
        except:
            pass
    try:
        return pd.to_datetime(s).date()
    except:
        return None

def email_ok(s:str)->bool:
    if not s or str(s).strip()=="" or str(s).lower()=="nan":
        return True
    return bool(re.match(r"^[^@\s]+@[^@\s]+\.[^@\s]+$", str(s).strip()))

def phone_ok(s:str)->bool:
    if not s or str(s).strip()=="" or str(s).lower()=="nan":
        return True
    s2 = re.sub(r"[ \.\-\(\)]","",str(s)).replace("+","")
    return s2.isdigit() and len(s2)>=8

def generate_id(prefix:str, df:pd.DataFrame, id_col:str, width:int=3)->str:
    if df.empty or id_col not in df.columns:
        return f"{prefix}_{str(1).zfill(width)}"
    patt = re.compile(rf"^{re.escape(prefix)}_(\d+)$")
    mx = 0
    for x in df[id_col].dropna().astype(str):
        m = patt.match(x.strip())
        if m:
            try:
                mx = max(mx, int(m.group(1)))
            except:
                pass
    return f"{prefix}_{str(mx+1).zfill(width)}"

def log_event(kind:str, payload:dict):
    rec = {"ts": datetime.now().isoformat(), "kind": kind, **payload}
    with PATHS["logs"].open("a", encoding="utf-8") as f:
        f.write(json.dumps(rec, ensure_ascii=False) + "\n")

# Load data
df_contacts = ensure_df(PATHS["contacts"], C_COLS)
df_inter    = ensure_df(PATHS["inter"], I_COLS)
df_events   = ensure_df(PATHS["events"], E_COLS)
df_parts    = ensure_df(PATHS["parts"], P_COLS)
df_pay      = ensure_df(PATHS["pay"], PAY_COLS)
df_cert     = ensure_df(PATHS["cert"], CERT_COLS)
if not df_contacts.empty:
    df_contacts["Top20"] = df_contacts["SociÃ©tÃ©"].fillna("").apply(lambda x: x in SET["entreprises_cibles"])

# Aggregate function for contacts (calculs des scores, tags, etc.)

def aggregates_for_contacts(today=None):
    today = today or date.today()
    vip_thr = float(PARAMS.get("vip_threshold", "500000"))
    w_int = float(PARAMS.get("score_w_interaction", "1"))
    w_part = float(PARAMS.get("score_w_participation", "1"))
    w_pay = float(PARAMS.get("score_w_payment_regle", "2"))
    lookback = int(PARAMS.get("interactions_lookback_days", "90"))
    hot_int_min = int(PARAMS.get("rule_hot_interactions_recent_min", "3"))
    hot_part_min = int(PARAMS.get("rule_hot_participations_min", "1"))
    hot_partiel = PARAMS.get("rule_hot_payment_partial_counts_as_hot", "1") in ("1", "true", "True")

    inter_count = df_inter.groupby("ID")["ID_Interaction"].count() if not df_inter.empty else pd.Series(dtype=int)
    inter_dates = pd.to_datetime(df_inter["Date"], errors="coerce") if not df_inter.empty else pd.Series(dtype="datetime64[ns]")
    last_contact = df_inter.assign(_d=inter_dates).groupby("ID")["_d"].max() if not df_inter.empty else pd.Series(dtype="datetime64[ns]")
    recent_cut = today - timedelta(days=lookback)
    recent_inter = df_inter.assign(_d=inter_dates).loc[lambda d: d["_d"] >= pd.Timestamp(recent_cut)].groupby("ID")["ID_Interaction"].count() if not df_inter.empty else pd.Series(dtype=int)

    resp_max = pd.Series(dtype=str)
    if not df_inter.empty:
        tmp = df_inter.groupby(["ID","Responsable"])["ID_Interaction"].count().reset_index()
        idx = tmp.groupby("ID")["ID_Interaction"].idxmax()
        resp_max = tmp.loc[idx].set_index("ID")["Responsable"]
        
    parts_count = df_parts.groupby("ID")["ID_Participation"].count() if not df_parts.empty else pd.Series(dtype=int)
    has_anim = pd.Series(dtype=bool)
    if not df_parts.empty:
        has_anim = df_parts.assign(_anim=df_parts["RÃ´le"].isin(["Animateur","InvitÃ©"])).groupby("ID")["_anim"].any()

    pay_reg_count = pd.Series(dtype=int)
    if not df_pay.empty:
        pay = df_pay.copy()
        pay["Montant"] = pd.to_numeric(pay["Montant"], errors="coerce").fillna(0.0)
        total_pay = pay.groupby("ID")["Montant"].sum()
        pay_regle = pay[pay["Statut"]=="RÃ©glÃ©"].groupby("ID")["Montant"].sum()
        pay_impaye = pay[pay["Statut"]!="RÃ©glÃ©"].groupby("ID")["Montant"].sum()
        pay_reg_count = pay[pay["Statut"]=="RÃ©glÃ©"].groupby("ID")["Montant"].count()
        has_partiel = pay[pay["Statut"]=="Partiel"].groupby("ID")["Montant"].count()
    else:
        total_pay = pd.Series(dtype=float)
        pay_regle = pd.Series(dtype=float)
        pay_impaye = pd.Series(dtype=float)
        has_partiel = pd.Series(dtype=int)

    has_cert = pd.Series(dtype=bool)
    if not df_cert.empty:
        has_cert = df_cert[df_cert["RÃ©sultat"]=="RÃ©ussi"].groupby("ID")["ID_Certif"].count() > 0

    ag = pd.DataFrame(index=df_contacts["ID"])
    ag["Interactions"] = ag.index.map(inter_count).fillna(0).astype(int)
    ag["Interactions_recent"] = ag.index.map(recent_inter).fillna(0).astype(int)
    # remonte la date la plus rÃ©cente de contact, gÃ¨re les valeurs manquantes
    ag["Dernier_contact"] = ag.index.map(last_contact)  # sÃ©rie de Timestamps ou NaT
    ag["Dernier_contact"] = pd.to_datetime(ag["Dernier_contact"], errors="coerce")  # convertit en datetime
    ag["Dernier_contact"] = ag["Dernier_contact"].dt.date  # extrait la date, les NaT deviennent None
    ag["Resp_principal"] = ag.index.map(resp_max).fillna("")
    ag["Participations"] = ag.index.map(parts_count).fillna(0).astype(int)
    ag["A_animÃ©_ou_invitÃ©"] = ag.index.map(has_anim).fillna(False)
    ag["CA_total"] = ag.index.map(total_pay).fillna(0.0)
    ag["CA_rÃ©glÃ©"] = ag.index.map(pay_regle).fillna(0.0)
    ag["ImpayÃ©"] = ag.index.map(pay_impaye).fillna(0.0)
    ag["Paiements_regles_n"] = ag.index.map(pay_reg_count).fillna(0).astype(int)
    ag["A_certification"] = ag.index.map(has_cert).fillna(False)

    ag["Score_composite"] = (w_int * ag["Interactions"] + w_part * ag["Participations"] + w_pay * ag["Paiements_regles_n"]).round(2)

    def make_tags(row):
        tags=[]
        if row.name in set(df_contacts.loc[(df_contacts["Type"]=="Prospect") & (df_contacts["Top20"]==True), "ID"]):
            tags.append("Prospect Top-20")
        if row["Participations"] >= 3 and row.name in set(df_contacts[df_contacts["Type"]=="Prospect"]["ID"]) and row["CA_rÃ©glÃ©"] <= 0:
            tags.append("RÃ©gulier-non-converti")
        if row["A_animÃ©_ou_invitÃ©"] or row["Participations"] >= 4:
            tags.append("Futur formateur")
        if row["A_certification"]:
            tags.append("Ambassadeur (certifiÃ©)")
        if row["CA_rÃ©glÃ©"] >= vip_thr:
            tags.append("VIP (CA Ã©levÃ©)")
        return ", ".join(tags)

    ag["Tags"] = ag.apply(make_tags, axis=1)

    def proba(row):
        if row.name in set(df_contacts[df_contacts["Type"]=="Membre"]["ID"]):
            return "Converti"
        chaud = (row["Interactions_recent"] >= hot_int_min and row["Participations"] >= hot_part_min)
        if hot_partiel and row["ImpayÃ©"] > 0 and row["CA_rÃ©glÃ©"] == 0:
            chaud = True
        tiede = (row["Interactions_recent"] >= 1 or row["Participations"] >= 1)
        if chaud:
            return "Chaud"
        if tiede:
            return "TiÃ¨de"
        return "Froid"

    ag["Proba_conversion"] = ag.apply(proba, axis=1)

    return ag.reset_index(names="ID")

# ------------------ Navigation & pages ----------------------

st.sidebar.title("Navigation")
page = st.sidebar.radio("Aller Ã ", ["CRM (Grille centrale)","Ã‰vÃ©nements","Rapports","Admin"], index=0)
this_year = datetime.now().year
annee = st.sidebar.selectbox("AnnÃ©e", ["Toutes"]+[str(this_year-1),str(this_year),str(this_year+1)], index=1)
mois = st.sidebar.selectbox("Mois", ["Tous"]+[f"{m:02d}" for m in range(1,13)], index=0)

# CRM Grille centrale
if page == "CRM (Grille centrale)":
    st.title("ğŸ‘¥ CRM â€” Grille centrale (Contacts)")
    colf1, colf2, colf3, colf4 = st.columns([2,1,1,1])
    q = colf1.text_input("Recherche (nom, sociÃ©tÃ©, email)â€¦","")
    page_size = colf2.selectbox("Taille de page", [20,50,100,200], index=0)
    type_filtre = colf3.selectbox("Type", ["Tous"] + SET["types_contact"])
    top20_only = colf4.checkbox("Top-20 uniquement", value=False)

    dfc = df_contacts.copy()
    ag = aggregates_for_contacts()
    dfc = dfc.merge(ag, on="ID", how="left")

    if q:
        qs = q.lower()
        dfc = dfc[dfc.apply(lambda r: qs in str(r["Nom"]).lower() or qs in str(r["PrÃ©nom"]).lower()
                          or qs in str(r["SociÃ©tÃ©"]).lower() or qs in str(r["Email"]).lower(), axis=1)]
    if type_filtre != "Tous":
        dfc = dfc[dfc["Type"] == type_filtre]
    if top20_only:
        dfc = dfc[dfc["Top20"] == True]

    def parse_cols(s, defaults):
        cols = [c.strip() for c in str(s).split(",") if c.strip()]
        valid = [c for c in cols if c in dfc.columns]
        return valid if valid else defaults

    table_cols = parse_cols(PARAMS.get("grid_crm_columns", ""), [
        "ID","Nom","PrÃ©nom","SociÃ©tÃ©","Type","Statut","Email",
        "Interactions","Participations","CA_rÃ©glÃ©","ImpayÃ©","Resp_principal","A_animÃ©_ou_invitÃ©",
        "Score_composite","Proba_conversion","Tags"
    ])

    def _label_contact(row):
        return f"{row['ID']} â€” {row['PrÃ©nom']} {row['Nom']} â€” {row['SociÃ©tÃ©']}"
    options = [] if dfc.empty else dfc.apply(_label_contact, axis=1).tolist()
    id_map = {} if dfc.empty else dict(zip(options, dfc["ID"]))

    colsel, _ = st.columns([3,1])
    sel_label = colsel.selectbox("Contact sÃ©lectionnÃ© (sÃ©lecteur maÃ®tre)", [""] + options, index=0, key="select_contact_label")
    if sel_label:
        st.session_state["selected_contact_id"] = id_map[sel_label]

    # Affichage grille avec AgGrid (si installÃ©)
    if HAS_AGGRID and not dfc.empty:
        dfc_show = dfc[table_cols].copy()
        proba_style = JsCode("""
            function(params) {
              const v = params.value;
              let color = null;
              if (v === 'Chaud') color = '#10B981';
              else if (v === 'TiÃ¨de') color = '#F59E0B';
              else if (v === 'Froid') color = '#EF4444';
              else if (v === 'Converti') color = '#6366F1';
              if (color){
                return { color: 'white', 'font-weight':'600', 'text-align':'center', 'border-radius':'12px', 'background-color': color };
              }
              return {};
            }
        """)
        gob = GridOptionsBuilder.from_dataframe(dfc_show)
        gob.configure_default_column(filter=True, sortable=True, resizable=True)
        gob.configure_selection("single", use_checkbox=True)
        gob.configure_pagination(paginationAutoPageSize=False, paginationPageSize=page_size)
        gob.configure_side_bar()
        if "Proba_conversion" in dfc_show.columns:
            gob.configure_column("Proba_conversion", cellStyle=proba_style)
        grid = AgGrid(
            dfc_show, gridOptions=gob.build(), height=520,
            update_mode=GridUpdateMode.SELECTION_CHANGED,
            data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
            key="crm_grid", allow_unsafe_jscode=True
        )
        if grid and grid.get("selected_rows"):
            new_sel = grid["selected_rows"][0].get("ID")
            if new_sel:
                st.session_state["selected_contact_id"] = new_sel
    else:
        st.info("Installez `streamlit-aggrid` pour filtres & pagination avancÃ©s.")
        st.dataframe(dfc[table_cols], use_container_width=True)

    st.markdown("---")
    cL, cR = st.columns([1,2])

    with cL:
        st.subheader("Fiche Contact")
        sel_id = st.session_state.get("selected_contact_id", None)
        if sel_id:
            c = df_contacts[df_contacts["ID"] == sel_id]
            if not c.empty:
                d = c.iloc[0].to_dict()
                with st.form("edit_contact"):
                    st.text_input("ID", value=d["ID"], disabled=True)
                    n1, n2 = st.columns(2)
                    nom = n1.text_input("Nom", d.get("Nom",""))
                    prenom = n2.text_input("PrÃ©nom", d.get("PrÃ©nom",""))
                    g1,g2 = st.columns(2)
                    genre = g1.selectbox("Genre", SET["genres"], index=SET["genres"].index(d.get("Genre","Homme")) if d.get("Genre","Homme") in SET["genres"] else 0)
                    titre = g2.text_input("Titre / Position", d.get("Titre",""))
                    s1,s2 = st.columns(2)
                    societe = s1.text_input("SociÃ©tÃ©", d.get("SociÃ©tÃ©",""))
                    secteur = s2.selectbox("Secteur", SET["secteurs"], index=SET["secteurs"].index(d.get("Secteur","Autre")) if d.get("Secteur","Autre") in SET["secteurs"] else len(SET["secteurs"])-1)
                    e1,e2,e3 = st.columns(3)
                    email = e1.text_input("Email", d.get("Email",""))
                    tel = e2.text_input("TÃ©lÃ©phone", d.get("TÃ©lÃ©phone",""))
                    linkedin = e3.text_input("LinkedIn", d.get("LinkedIn",""))
                    l1,l2,l3 = st.columns(3)
                    ville = l1.selectbox("Ville", SET["villes"], index=SET["villes"].index(d.get("Ville","Autres")) if d.get("Ville","Autres") in SET["villes"] else len(SET["villes"])-1)
                    pays = l2.selectbox("Pays", SET["pays"], index=SET["pays"].index(d.get("Pays","Cameroun")) if d.get("Pays","Cameroun") in SET["pays"] else 0)
                    typec = l3.selectbox("Type", SET["types_contact"], index=SET["types_contact"].index(d.get("Type","Prospect")) if d.get("Type","Prospect") in SET["types_contact"] else 0)
                    s3,s4,s5 = st.columns(3)
                    source = s3.selectbox("Source", SET["sources"], index=SET["sources"].index(d.get("Source","LinkedIn")) if d.get("Source","LinkedIn") in SET["sources"] else 0)
                    statut = s4.selectbox("Statut", SET["statuts_engagement"], index=SET["statuts_engagement"].index(d.get("Statut","Actif")) if d.get("Statut","Actif") in SET["statuts_engagement"] else 0)
                    score = s5.number_input("Score IIBA", value=float(d.get("Score_Engagement") or 0), step=1.0)
                    dc = st.date_input("Date de crÃ©ation", value=parse_date(d.get("Date_Creation")) or date.today())
                    notes = st.text_area("Notes", d.get("Notes",""))
                    top20 = st.checkbox("Top-20 entreprise", value=bool(str(d.get("Top20")).lower() in ["true","1","yes"]))
                    ok = st.form_submit_button("ğŸ’¾ Enregistrer le contact")
                    if ok:
                        if not email_ok(email):
                            st.error("Email invalide.")
                            st.stop()
                        if not phone_ok(tel):
                            st.error("TÃ©lÃ©phone invalide.")
                            st.stop()
                        idx = df_contacts.index[df_contacts["ID"] == sel_id][0]
                        new_row = {"ID":sel_id,"Nom":nom,"PrÃ©nom":prenom,"Genre":genre,"Titre":titre,"SociÃ©tÃ©":societe,"Secteur":secteur,
                                   "Email":email,"TÃ©lÃ©phone":tel,"LinkedIn":linkedin,"Ville":ville,"Pays":pays,"Type":typec,"Source":source,
                                   "Statut":statut,"Score_Engagement":int(score),"Date_Creation":dc.isoformat(),"Notes":notes,"Top20":top20}
                        df_contacts.loc[idx] = new_row
                        save_df(df_contacts, PATHS["contacts"])
                        st.success("Contact mis Ã  jour.")
                st.markdown("---")
                with st.expander("â• Ajouter ce contact Ã  un **nouvel Ã©vÃ©nement**"):
                    with st.form("quick_evt"):
                        c1,c2 = st.columns(2)
                        nom_ev = c1.text_input("Nom de l'Ã©vÃ©nement")
                        type_ev = c2.selectbox("Type", SET["types_evenements"])
                        c3,c4 = st.columns(2)
                        date_ev = c3.date_input("Date", value=date.today())
                        lieu_ev = c4.selectbox("Lieu", SET["lieux"])
                        role = st.selectbox("RÃ´le du contact", ["Participant","Animateur","InvitÃ©"])
                        ok2 = st.form_submit_button("ğŸ’¾ CrÃ©er l'Ã©vÃ©nement **et** inscrire ce contact")
                        if ok2:
                            new_eid = generate_id("EVT", df_events, "ID_Ã‰vÃ©nement")
                            rowe = {"ID_Ã‰vÃ©nement":new_eid,"Nom_Ã‰vÃ©nement":nom_ev,"Type":type_ev,"Date":date_ev.isoformat(),
                                    "DurÃ©e_h":"2","Lieu":lieu_ev,"Formateur":"","Objectif":"","Periode":"",
                                    "Cout_Salle":0,"Cout_Formateur":0,"Cout_Logistique":0,"Cout_Pub":0,"Cout_Autres":0,"Cout_Total":0,"Notes":""}
                            globals()["df_events"] = pd.concat([df_events, pd.DataFrame([rowe])], ignore_index=True)
                            save_df(df_events, PATHS["events"])
                            new_pid = generate_id("PAR", df_parts, "ID_Participation")
                            rowp = {"ID_Participation":new_pid,"ID":sel_id,"ID_Ã‰vÃ©nement":new_eid,"RÃ´le":role,
                                    "Inscription":"","ArrivÃ©e":"","Temps_Present":"","Feedback":"","Note":"","Commentaire":""}
                            globals()["df_parts"] = pd.concat([df_parts, pd.DataFrame([rowp])], ignore_index=True)
                            save_df(df_parts, PATHS["parts"])
                            st.success(f"Ã‰vÃ©nement crÃ©Ã© ({new_eid}) et contact inscrit ({new_pid}).")
            else:
                st.warning("ID introuvable (rafraÃ®chissez la page).")
        else:
            st.info("SÃ©lectionnez un contact via la grille ou le sÃ©lecteur maÃ®tre.")
    with cR:
        st.subheader("Actions liÃ©es au contact sÃ©lectionnÃ©")
        sel_id = st.session_state.get("selected_contact_id")
        if not sel_id:
            st.info("SÃ©lectionnez un contact pour crÃ©er une interaction, participation, paiement ou certification.")
        else:
            tabs = st.tabs(["â• Interaction","â• Participation","â• Paiement","â• Certification","ğŸ“‘ Vue 360Â°"])
            with tabs[0]:
                with st.form("add_inter"):
                    c1,c2,c3 = st.columns(3)
                    dti = c1.date_input("Date", value=date.today())
                    canal = c2.selectbox("Canal", SET["canaux"])
                    resp = c3.selectbox("Responsable", ["Aymard","Alix","Autre"])
                    obj = st.text_input("Objet")
                    resu = st.selectbox("RÃ©sultat", SET["resultats_inter"])
                    resume = st.text_area("RÃ©sumÃ©")
                    add_rel = st.checkbox("Planifier une relance ?")
                    rel = st.date_input("Relance", value=date.today()) if add_rel else None
                    ok = st.form_submit_button("ğŸ’¾ Enregistrer l'interaction")
                    if ok:
                        nid = generate_id("INT", df_inter, "ID_Interaction")
                        row = {"ID_Interaction":nid,"ID":sel_id,"Date":dti.isoformat(),"Canal":canal,"Objet":obj,"RÃ©sumÃ©":resume,
                               "RÃ©sultat":resu,"Prochaine_Action":"","Relance":rel.isoformat() if rel else "","Responsable":resp}
                        globals()["df_inter"] = pd.concat([df_inter, pd.DataFrame([row])], ignore_index=True)
                        save_df(df_inter, PATHS["inter"])
                        st.success(f"Interaction enregistrÃ©e ({nid}).")
            with tabs[1]:
                with st.form("add_part"):
                    if df_events.empty:
                        st.warning("CrÃ©ez d'abord un Ã©vÃ©nement.")
                    else:
                        ide = st.selectbox("Ã‰vÃ©nement", df_events["ID_Ã‰vÃ©nement"].tolist())
                        role = st.selectbox("RÃ´le", ["Participant","Animateur","InvitÃ©"])
                        fb = st.selectbox("Feedback", ["TrÃ¨s satisfait","Satisfait","Moyen","Insatisfait"])
                        note = st.number_input("Note (1-5)", min_value=1, max_value=5, value=5)
                        ok = st.form_submit_button("ğŸ’¾ Enregistrer la participation")
                        if ok:
                            nid = generate_id("PAR", df_parts, "ID_Participation")
                            row = {"ID_Participation":nid,"ID":sel_id,"ID_Ã‰vÃ©nement":ide,"RÃ´le":role,"Inscription":"","ArrivÃ©e":"",
                                   "Temps_Present":"","Feedback":fb,"Note":str(note),"Commentaire":""}
                            globals()["df_parts"] = pd.concat([df_parts, pd.DataFrame([row])], ignore_index=True)
                            save_df(df_parts, PATHS["parts"])
                            st.success(f"Participation ajoutÃ©e ({nid}).")
            with tabs[2]:
                with st.form("add_pay"):
                    if df_events.empty:
                        st.warning("CrÃ©ez d'abord un Ã©vÃ©nement.")
                    else:
                        ide = st.selectbox("Ã‰vÃ©nement", df_events["ID_Ã‰vÃ©nement"].tolist())
                        dtp = st.date_input("Date paiement", value=date.today())
                        montant = st.number_input("Montant (FCFA)", min_value=0, step=1000)
                        moyen = st.selectbox("Moyen", SET["moyens_paiement"])
                        statut = st.selectbox("Statut", SET["statuts_paiement"])
                        ref = st.text_input("RÃ©fÃ©rence")
                        ok = st.form_submit_button("ğŸ’¾ Enregistrer le paiement")
                        if ok:
                            nid = generate_id("PAY", df_pay, "ID_Paiement")
                            row = {"ID_Paiement":nid,"ID":sel_id,"ID_Ã‰vÃ©nement":ide,"Date_Paiement":dtp.isoformat(),"Montant":str(montant),
                                   "Moyen":moyen,"Statut":statut,"RÃ©fÃ©rence":ref,"Notes":"","Relance":""}
                            globals()["df_pay"] = pd.concat([df_pay, pd.DataFrame([row])], ignore_index=True)
                            save_df(df_pay, PATHS["pay"])
                            st.success(f"Paiement enregistrÃ© ({nid}).")
            with tabs[3]:
                with st.form("add_cert"):
                    tc = st.selectbox("Type Certification", SET["types_certif"])
                    dte = st.date_input("Date Examen", value=date.today())
                    res = st.selectbox("RÃ©sultat", ["RÃ©ussi","Ã‰chouÃ©","En cours","ReportÃ©"])
                    sc = st.number_input("Score", min_value=0, max_value=100, value=0)
                    has_dto = st.checkbox("Renseigner une date d'obtention ?")
                    dto = st.date_input("Date Obtention", value=date.today()) if has_dto else None
                    ok = st.form_submit_button("ğŸ’¾ Enregistrer la certification")
                    if ok:
                        nid = generate_id("CER", df_cert, "ID_Certif")
                        row = {"ID_Certif":nid,"ID":sel_id,"Type_Certif":tc,"Date_Examen":dte.isoformat(),"RÃ©sultat":res,"Score":str(sc),
                               "Date_Obtention":dto.isoformat() if dto else "","ValiditÃ©":"","Renouvellement":"","Notes":""}
                        globals()["df_cert"] = pd.concat([df_cert, pd.DataFrame([row])], ignore_index=True)
                        save_df(df_cert, PATHS["cert"])
                        st.success(f"Certification ajoutÃ©e ({nid}).")
            with tabs[4]:
                st.markdown("#### Vue 360Â°")
                if not df_inter.empty:
                    st.write("**Interactions**")
                    st.dataframe(df_inter[df_inter["ID"]==sel_id][["Date","Canal","Objet","RÃ©sultat","Relance","Responsable"]], use_container_width=True)
                if not df_parts.empty:
                    st.write("**Participations**")
                    dfp = df_parts[df_parts["ID"]==sel_id].copy()
                    if not df_events.empty:
                        ev_names = df_events.set_index("ID_Ã‰vÃ©nement")["Nom_Ã‰vÃ©nement"]
                        dfp["Ã‰vÃ©nement"] = dfp["ID_Ã‰vÃ©nement"].map(ev_names)
                    st.dataframe(dfp[["Ã‰vÃ©nement","RÃ´le","Feedback","Note"]], use_container_width=True)
                if not df_pay.empty:
                    st.write("**Paiements**")
                    st.dataframe(df_pay[df_pay["ID"]==sel_id][["ID_Ã‰vÃ©nement","Date_Paiement","Montant","Moyen","Statut","RÃ©fÃ©rence"]], use_container_width=True)
                if not df_cert.empty:
                    st.write("**Certifications**")
                    st.dataframe(df_cert[df_cert["ID"]==sel_id][["Type_Certif","Date_Examen","RÃ©sultat","Score","Date_Obtention"]], use_container_width=True)

# --- Pages Ã‰vÃ©nements, Rapports, Admin ---
# Tu peux me demander la suite ou complÃ©ter en fonction si tu veux.

# --------------------------------------------
# Suite app.py - pages Ã‰vÃ©nements, Rapports, Admin
# --------------------------------------------

# ---------------------- PAGE Ã‰VÃ‰NEMENTS ----------------------

if page == "Ã‰vÃ©nements":
    st.title("ğŸ“… Ã‰vÃ©nements")
    
    with st.expander("â• CrÃ©er un nouvel Ã©vÃ©nement", expanded=False):
        with st.form("new_event"):
            c1, c2, c3 = st.columns(3)
            nom = c1.text_input("Nom de l'Ã©vÃ©nement")
            typ = c2.selectbox("Type", SET["types_evenements"])
            dat = c3.date_input("Date", value=date.today())

            c4, c5, c6 = st.columns(3)
            lieu = c4.selectbox("Lieu", SET["lieux"])
            duree = c5.number_input("DurÃ©e (h)", min_value=0.0, step=0.5, value=2.0)
            formateur = c6.text_input("Formateur(s)")

            obj = st.text_area("Objectif")

            couts = st.columns(5)
            c_salle = couts[0].number_input("CoÃ»t salle", min_value=0.0, step=1000.0)
            c_form = couts[1].number_input("CoÃ»t formateur", min_value=0.0, step=1000.0)
            c_log = couts[2].number_input("CoÃ»t logistique", min_value=0.0, step=1000.0)
            c_pub = couts[3].number_input("CoÃ»t pub", min_value=0.0, step=1000.0)
            c_aut = couts[4].number_input("Autres coÃ»ts", min_value=0.0, step=1000.0)

            notes = st.text_area("Notes")
            ok = st.form_submit_button("ğŸ’¾ CrÃ©er l'Ã©vÃ©nement")

            if ok:
                new_id = generate_id("EVT", df_events, "ID_Ã‰vÃ©nement")
                row = {
                    "ID_Ã‰vÃ©nement": new_id, "Nom_Ã‰vÃ©nement": nom, "Type": typ, "Date": dat.isoformat(),
                    "DurÃ©e_h": str(duree), "Lieu": lieu, "Formateur": formateur, "Objectif": obj, "Periode": "",
                    "Cout_Salle": c_salle, "Cout_Formateur": c_form, "Cout_Logistique": c_log, "Cout_Pub": c_pub,
                    "Cout_Autres": c_aut, "Cout_Total": 0, "Notes": notes
                }
                globals()["df_events"] = pd.concat([df_events, pd.DataFrame([row])], ignore_index=True)
                save_df(df_events, PATHS["events"])
                st.success(f"Ã‰vÃ©nement crÃ©Ã© ({new_id}).")

    # Ã‰dition, Duplication, Suppression avec filtre
    filt = st.text_input("Filtre rapide (nom, type, lieu, notesâ€¦)", "")
    page_size_evt = st.selectbox("Taille de page", [20,50,100,200], index=0, key="pg_evt")
    df_show = df_events.copy()
    
    if filt:
        t = filt.lower()
        df_show = df_show[df_show.apply(lambda r: any(t in str(r[c]).lower() for c in ["Nom_Ã‰vÃ©nement","Type","Lieu","Notes"]), axis=1)]

    if HAS_AGGRID:
        gb = GridOptionsBuilder.from_dataframe(df_show)
        gb.configure_default_column(filter=True, sortable=True, resizable=True, editable=True)
        gb.configure_pagination(paginationAutoPageSize=False, paginationPageSize=page_size_evt)
        gb.configure_selection("single", use_checkbox=True)
        go = gb.build()
        grid = AgGrid(df_show, gridOptions=go, height=520, update_mode=GridUpdateMode.MODEL_CHANGED,
                      data_return_mode=DataReturnMode.FILTERED_AND_SORTED, key="evt_grid", allow_unsafe_jscode=True)

        col1, col2, col3 = st.columns(3)
        if col1.button("ğŸ’¾ Appliquer les modifications"):
            new_df = pd.DataFrame(grid["data"])
            for c in E_COLS:
                if c not in new_df.columns:
                    new_df[c] = ""
            globals()["df_events"] = new_df[E_COLS].copy()
            save_df(df_events, PATHS["events"])
            st.success("Modifications enregistrÃ©es.")
        if col2.button("ğŸ—‘ï¸ Supprimer l'Ã©vÃ©nement sÃ©lectionnÃ©"):
            if grid.get("selected_rows"):
                del_id = grid["selected_rows"][0].get("ID_Ã‰vÃ©nement")
                globals()["df_events"] = df_events[df_events["ID_Ã‰vÃ©nement"] != del_id]
                save_df(df_events, PATHS["events"])
                st.success(f"Ã‰vÃ©nement supprimÃ© ({del_id}).")
            else:
                st.warning("SÃ©lectionnez une ligne dans la grille pour supprimer.")
        if col3.button("ğŸ§¬ Dupliquer l'Ã©vÃ©nement sÃ©lectionnÃ©"):
            if grid.get("selected_rows"):
                src = grid["selected_rows"][0]
                new_id = generate_id("EVT", df_events, "ID_Ã‰vÃ©nement")
                clone = {k: src.get(k, "") for k in E_COLS}
                clone["ID_Ã‰vÃ©nement"] = new_id
                globals()["df_events"] = pd.concat([df_events, pd.DataFrame([clone])], ignore_index=True)
                save_df(df_events, PATHS["events"])
                st.success(f"Ã‰vÃ©nement dupliquÃ© sous l'ID {new_id}.")
            else:
                st.warning("SÃ©lectionnez une ligne dans la grille pour dupliquer.")
    else:
        st.dataframe(df_show, use_container_width=True)
        st.info("Installez `streamlit-aggrid` pour Ã©diter/dupliquer directement dans la grille.")


# ---------------------- PAGE RAPPORTS ----------------------

elif page == "Rapports":
    st.title("ğŸ“‘ Rapports & KPI â€” IIBA Cameroun")

    # ---------- Helpers sÃ»rs pour le filtrage pÃ©riode ----------
    def _safe_parse_series(s: pd.Series) -> pd.Series:
        # Convertit chaque cellule en date (ou None) sans exception
        return s.map(lambda x: parse_date(x) if pd.notna(x) and str(x).strip() != "" else None)

    def _build_mask_from_dates(d: pd.Series, year_sel: str, month_sel: str) -> pd.Series:
        # d contient des objets date/None ; renvoie un masque boolÃ©en sans NaN
        mask = pd.Series(True, index=d.index)
        if year_sel != "Toutes":
            y = int(year_sel)
            mask = mask & d.map(lambda x: isinstance(x, (datetime, date)) and x.year == y)
        if month_sel != "Tous":
            m = int(month_sel)
            mask = mask & d.map(lambda x: isinstance(x, (datetime, date)) and x.month == m)
        return mask.fillna(False)

    def filtered_tables_for_period(year_sel: str, month_sel: str):
        """
        Retourne des sous-ensembles filtrÃ©s par pÃ©riode:
        - dfe2 : Ã‰vÃ©nements (filtrÃ© sur Date)
        - dfp2 : Participations (filtrÃ©es via la date de l'Ã©vÃ©nement liÃ©)
        - dfpay2: Paiements (filtrÃ©s sur Date_Paiement)
        - dfcert2: Certifications (Date_Obtention OU Date_Examen)
        """
        # 1) Ã‰VÃ‰NEMENTS
        if df_events.empty:
            dfe2 = df_events.copy()
        else:
            ev_dates = _safe_parse_series(df_events["Date"])
            mask_e = _build_mask_from_dates(ev_dates, year_sel, month_sel)
            dfe2 = df_events[mask_e].copy()

        # 2) PARTICIPATIONS (via date de l'Ã©vÃ©nement)
        if df_parts.empty:
            dfp2 = df_parts.copy()
        else:
            dfp2 = df_parts.copy()
            if not df_events.empty:
                ev_dates_map = df_events.set_index("ID_Ã‰vÃ©nement")["Date"].map(parse_date)
                dfp2["_d_evt"] = dfp2["ID_Ã‰vÃ©nement"].map(ev_dates_map)  # date (ou None)
                mask_p = _build_mask_from_dates(dfp2["_d_evt"], year_sel, month_sel)
                dfp2 = dfp2[mask_p].copy()
            else:
                dfp2 = dfp2.iloc[0:0].copy()

        # 3) PAIEMENTS
        if df_pay.empty:
            dfpay2 = df_pay.copy()
        else:
            pay_dates = _safe_parse_series(df_pay["Date_Paiement"])
            mask_pay = _build_mask_from_dates(pay_dates, year_sel, month_sel)
            dfpay2 = df_pay[mask_pay].copy()

        # 4) CERTIFICATIONS (Obtention OU Examen)
        if df_cert.empty:
            dfcert2 = df_cert.copy()
        else:
            obt = _safe_parse_series(df_cert["Date_Obtention"]) if "Date_Obtention" in df_cert.columns else pd.Series([None]*len(df_cert), index=df_cert.index)
            exa = _safe_parse_series(df_cert["Date_Examen"])    if "Date_Examen"    in df_cert.columns    else pd.Series([None]*len(df_cert), index=df_cert.index)
            mask_c = _build_mask_from_dates(obt, year_sel, month_sel) | _build_mask_from_dates(exa, year_sel, month_sel)
            dfcert2 = df_cert[mask_c.fillna(False)].copy()

        return dfe2, dfp2, dfpay2, dfcert2

    def event_financials(dfe2, dfpay2):
        rec_by_evt = pd.Series(dtype=float)
        if not dfpay2.empty:
            r = dfpay2[dfpay2["Statut"] == "RÃ©glÃ©"].copy()
            r["Montant"] = pd.to_numeric(r["Montant"], errors='coerce').fillna(0)
            rec_by_evt = r.groupby("ID_Ã‰vÃ©nement")["Montant"].sum()
        ev = dfe2 if not dfe2.empty else df_events.copy()
        if ev.empty:
            return pd.DataFrame(columns=["ID_Ã‰vÃ©nement", "Nom_Ã‰vÃ©nement", "Type", "Date", "CoÃ»t_Total", "Recette", "BÃ©nÃ©fice"])
        for c in ["Cout_Salle","Cout_Formateur","Cout_Logistique","Cout_Pub","Cout_Autres","Cout_Total"]:
            ev[c] = pd.to_numeric(ev[c], errors='coerce').fillna(0)
        ev["Cout_Total"] = ev["Cout_Total"].where(ev["Cout_Total"]>0, ev[["Cout_Salle","Cout_Formateur","Cout_Logistique","Cout_Pub","Cout_Autres"]].sum(axis=1))
        ev = ev.set_index("ID_Ã‰vÃ©nement")
        rep = pd.DataFrame({
            "Nom_Ã‰vÃ©nement": ev["Nom_Ã‰vÃ©nement"],
            "Type": ev["Type"],
            "Date": ev["Date"],
            "CoÃ»t_Total": ev["Cout_Total"]
        })
        rep["Recette"] = rec_by_evt.reindex(rep.index, fill_value=0)
        rep["BÃ©nÃ©fice"] = rep["Recette"] - rep["CoÃ»t_Total"]
        return rep.reset_index()

    # --- Filtrage des tables selon les sÃ©lecteurs latÃ©raux ---
    dfe2, dfp2, dfpay2, dfcert2 = filtered_tables_for_period(annee, mois)
    dfc2 = df_contacts.copy()

    # --- KPI de base ---
    total_contacts = len(dfc2)
    prospects_actifs = len(dfc2[(dfc2["Type"] == "Prospect") & (dfc2["Statut"] == "Actif")])
    membres = len(dfc2[dfc2["Type"] == "Membre"])
    events_count = len(dfe2)
    parts_total = len(dfp2)

    ca_regle, impayes = 0.0, 0.0
    if not dfpay2.empty:
        dfpay2["Montant"] = pd.to_numeric(dfpay2["Montant"], errors='coerce').fillna(0)
        ca_regle = float(dfpay2[dfpay2["Statut"] == "RÃ©glÃ©"]["Montant"].sum())
        impayes = float(dfpay2[dfpay2["Statut"] != "RÃ©glÃ©"]["Montant"].sum())
    taux_conv = (membres / max(1, len(dfc2[dfc2["Type"] == "Prospect"]))) * 100

    # Affichage KPIs dynamiques (en fonction de PARAMS["kpi_enabled"])
    kpis = {
        "contacts_total": ("ğŸ‘¥ Total Contacts", total_contacts),
        "prospects_actifs": ("ğŸ§² Prospects Actifs", prospects_actifs),
        "membres": ("ğŸ† Membres", membres),
        "events_count": ("ğŸ“… Ã‰vÃ©nements", events_count),
        "participations_total": ("ğŸŸ Participations", parts_total),
        "ca_regle": ("ğŸ’° CA payÃ©", f"{int(ca_regle):,} FCFA".replace(",", " ")),
        "impayes": ("âŒ ImpayÃ©s", f"{int(impayes):,} FCFA".replace(",", " ")),
        "taux_conv": ("ğŸ”„ Taux conversion", f"{taux_conv:.1f}%")
    }
    enabled = [x.strip() for x in PARAMS.get("kpi_enabled","").split(",") if x.strip() in kpis] or list(kpis.keys())
    cols = st.columns(max(1, len(enabled)))
    for i, k in enumerate(enabled):
        cols[i].metric(kpis[k][0], kpis[k][1])

    # --- Finance Ã©vÃ©nementielle ---
    ev_fin = event_financials(dfe2, dfpay2)

    # --- Graphe CA/CoÃ»t/BÃ©nÃ©fice par Ã©vÃ©nement ---
    if alt and not ev_fin.empty:
        chart1 = alt.Chart(
            ev_fin.melt(id_vars=["Nom_Ã‰vÃ©nement"], value_vars=["Recette","CoÃ»t_Total","BÃ©nÃ©fice"])
        ).mark_bar().encode(
            x=alt.X("Nom_Ã‰vÃ©nement:N", sort="-y", title="Ã‰vÃ©nement"),
            y=alt.Y('value:Q', title='Montant (FCFA)'),
            color=alt.Color('variable:N', title='Indicateur'),
            tooltip=['Nom_Ã‰vÃ©nement', 'variable', 'value']
        ).properties(height=300, title='CA vs CoÃ»t vs BÃ©nÃ©fice par Ã©vÃ©nement')
        st.altair_chart(chart1, use_container_width=True)

    # --- Participants par mois (via date d'Ã©vÃ©nement liÃ©e) ---
    if not dfp2.empty:
        if "_d_evt" in dfp2.columns:
            _m = pd.to_datetime(dfp2["_d_evt"], errors="coerce")
            dfp2["_mois"] = _m.dt.to_period("M").astype(str)
            agg = dfp2.dropna(subset=["_mois"]).groupby("_mois")["ID_Participation"].count().reset_index()
            if alt and not agg.empty:
                chart2 = alt.Chart(agg).mark_line(point=True).encode(
                    x=alt.X('_mois:N', title='Mois'),
                    y=alt.Y('ID_Participation:Q', title='Participations')
                ).properties(height=250, title="Participants par mois")
                st.altair_chart(chart2, use_container_width=True)

    # --- Satisfaction moyenne par type dâ€™Ã©vÃ©nement ---
    if not dfp2.empty and not df_events.empty:
        # map du Type (depuis la table complÃ¨te d'Ã©vÃ©nements) vers dfp2
        type_map = df_events.set_index('ID_Ã‰vÃ©nement')["Type"]
        dfp2 = dfp2.copy()
        dfp2["Type"] = dfp2["ID_Ã‰vÃ©nement"].map(type_map)
        # Note peut Ãªtre texte â†’ numÃ©rique sÃ»re
        if "Note" in dfp2.columns:
            dfp2["Note"] = pd.to_numeric(dfp2["Note"], errors='coerce')
        agg_satis = dfp2.dropna(subset=["Type","Note"]).groupby('Type')["Note"].mean().reset_index()
        if alt and not agg_satis.empty:
            chart3 = alt.Chart(agg_satis).mark_bar().encode(
                x=alt.X('Type:N', title="Type d'Ã©vÃ©nement"),
                y=alt.Y('Note:Q', title="Note moyenne"),
                tooltip=['Type', 'Note']
            ).properties(height=250, title="Satisfaction moyenne par type d'Ã©vÃ©nement")
            st.altair_chart(chart3, use_container_width=True)

    # --- Objectifs vs RÃ©el (Contacts + Participations + CA) ---
    st.header("ğŸ¯ Objectifs vs RÃ©el")
    def get_target(k):
        try:
            return float(PARAMS.get(k, "0"))
        except:
            return 0.0
    y = datetime.now().year
    df_targets = pd.DataFrame([
        ("contacts_total",       get_target(f'kpi_target_contacts_total_year_{y}'), total_contacts),
        ("participations_total", get_target(f'kpi_target_participations_total_year_{y}'), parts_total),
        ("ca_regle",             get_target(f'kpi_target_ca_regle_year_{y}'), ca_regle),
    ], columns=['KPI','Objectif','RÃ©el'])
    df_targets['Ã‰cart'] = df_targets['RÃ©el'] - df_targets['Objectif']
    st.dataframe(df_targets, use_container_width=True)

    # --- Export Excel du rapport de base ---
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine='openpyxl') as writer:
        df_contacts.to_excel(writer, sheet_name="Contacts", index=False)
        df_inter.to_excel(writer, sheet_name="Interactions", index=False)
        df_events.to_excel(writer, sheet_name="Ã‰vÃ©nements", index=False)
        df_parts.to_excel(writer, sheet_name="Participations", index=False)
        df_pay.to_excel(writer, sheet_name="Paiements", index=False)
        df_cert.to_excel(writer, sheet_name="Certifications", index=False)
        ev_fin.to_excel(writer, sheet_name="Finance", index=False)
    st.download_button("â¬‡ Export Rapport Excel", buf.getvalue(), "rapport_iiba_cameroon.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    st.markdown("---")
    st.header("ğŸ“Š Rapports AvancÃ©s & Analyse StratÃ©gique")

    # === PrÃ©paration des donnÃ©es enrichies (pour onglets & exports) ===
    dfc_enriched = df_contacts.merge(aggregates_for_contacts(), on="ID", how="left")
    # forcer numÃ©rique sÃ»r
    if "Score_Engagement" in dfc_enriched.columns:
        dfc_enriched['Score_Engagement'] = pd.to_numeric(dfc_enriched['Score_Engagement'], errors='coerce').fillna(0)

    # KPIs enrichis utilisÃ©s aussi dans export Markdown
    total_ba = len(dfc_enriched)
    certifies = len(dfc_enriched[dfc_enriched.get("A_certification", False) == True])
    taux_certif = (certifies / total_ba * 100) if total_ba > 0 else 0
    secteur_counts = dfc_enriched["Secteur"].value_counts(dropna=True)
    top_secteurs = secteur_counts.head(4)
    diversite_sectorielle = int(secteur_counts.shape[0])
    # salaire estimÃ© (paramÃ©trable possible; ici rÃ¨gle simple)
    def estimate_salary(row):
        base_salary = {
            "Banque": 800000, "TÃ©lÃ©com": 750000, "IT": 700000,
            "Ã‰ducation": 500000, "SantÃ©": 600000, "ONG": 450000,
            "Industrie": 650000, "Public": 550000, "Autre": 500000
        }
        multiplier = 1.3 if row.get("A_certification", False) else 1.0
        return base_salary.get(row.get("Secteur","Autre"), 500000) * multiplier
    if total_ba > 0:
        dfc_enriched["Salaire_Estime"] = dfc_enriched.apply(estimate_salary, axis=1)
        salaire_moyen = int(dfc_enriched["Salaire_Estime"].mean())
    else:
        salaire_moyen = 0

    taux_participation = float(dfc_enriched.get("Participations", pd.Series(dtype=float)).mean() or 0)
    ca_total = float(dfc_enriched.get("CA_rÃ©glÃ©", pd.Series(dtype=float)).sum() or 0)
    prospects_chauds = len(dfc_enriched[dfc_enriched.get("Proba_conversion","") == "Chaud"])

    # Onglets
    tab_exec, tab_profil, tab_swot, tab_bsc = st.tabs([
        "ğŸ¯ Executive Summary",
        "ğŸ‘¤ Profil BA Camerounais",
        "âš–ï¸ SWOT Analysis",
        "ğŸ“ˆ Balanced Scorecard"
    ])

    with tab_exec:
        st.subheader("ğŸ“‹ SynthÃ¨se ExÃ©cutive - IIBA Cameroun")

        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ğŸ‘¥ Total BA", total_ba)
        col2.metric("ğŸ“ CertifiÃ©s", f"{taux_certif:.1f}%")
        col3.metric("ğŸ’° Salaire Moyen", f"{salaire_moyen:,} FCFA")
        col4.metric("ğŸ¢ Secteurs", diversite_sectorielle)

        st.subheader("ğŸ† Top Ã‰vÃ©nements par Performance")
        if not ev_fin.empty:
            top_events = ev_fin.nlargest(5, "BÃ©nÃ©fice")[["Nom_Ã‰vÃ©nement", "Recette", "CoÃ»t_Total", "BÃ©nÃ©fice"]]
            st.dataframe(top_events, use_container_width=True)
        else:
            st.info("Pas de donnÃ©es financiÃ¨res d'Ã©vÃ©nements sur la pÃ©riode.")

        st.subheader("ğŸ¯ Segmentation des Contacts")
        segments = dfc_enriched["Proba_conversion"].value_counts()
        csg1, csg2 = st.columns(2)
        with csg1:
            if total_ba > 0 and not segments.empty:
                for segment, count in segments.items():
                    pct = (count / total_ba * 100)
                    st.write(f"â€¢ {segment}: {count} ({pct:.1f}%)")
            else:
                st.write("Aucune donnÃ©e de segmentation.")
        with csg2:
            if alt and not segments.empty:
                chart_data = pd.DataFrame({'Segment': segments.index, 'Count': segments.values})
                pie_chart = alt.Chart(chart_data).mark_arc().encode(
                    theta=alt.Theta(field="Count", type="quantitative"),
                    color=alt.Color(field="Segment", type="nominal"),
                    tooltip=['Segment', 'Count']
                ).properties(width=220, height=220)
                st.altair_chart(pie_chart, use_container_width=True)

    with tab_profil:
        st.subheader("ğŸ‘¤ Profil Type du BA Camerounais")

        col_demo1, col_demo2 = st.columns(2)
        with col_demo1:
            st.write("**ğŸ“Š RÃ©partition par Genre**")
            genre_counts = dfc_enriched["Genre"].value_counts()
            if total_ba > 0 and not genre_counts.empty:
                for genre, count in genre_counts.items():
                    pct = (count / total_ba * 100)
                    st.write(f"â€¢ {genre}: {count} ({pct:.1f}%)")
            else:
                st.write("Aucune donnÃ©e de genre.")

            st.write("**ğŸ™ï¸ RÃ©partition GÃ©ographique (Top 5)**")
            ville_counts = dfc_enriched["Ville"].value_counts().head(5)
            if total_ba > 0 and not ville_counts.empty:
                for ville, count in ville_counts.items():
                    pct = (count / total_ba * 100)
                    st.write(f"â€¢ {ville}: {count} ({pct:.1f}%)")
            else:
                st.write("Aucune donnÃ©e de ville.")

        with col_demo2:
            st.write("**ğŸ¢ Secteurs Dominants**")
            if total_ba > 0 and not top_secteurs.empty:
                for secteur, count in top_secteurs.items():
                    pct = (count / total_ba * 100)
                    st.write(f"â€¢ {secteur}: {count} ({pct:.1f}%)")
            else:
                st.write("Aucune donnÃ©e de secteur.")

            st.write("**ğŸ’¼ Types de Profils**")
            type_counts = dfc_enriched["Type"].value_counts()
            if total_ba > 0 and not type_counts.empty:
                for typ, count in type_counts.items():
                    pct = (count / total_ba * 100)
                    st.write(f"â€¢ {typ}: {count} ({pct:.1f}%)")
            else:
                st.write("Aucune donnÃ©e de type de profil.")

        st.subheader("ğŸ“ˆ Engagement par Secteur")
        if not dfc_enriched.empty:
            engagement_secteur = dfc_enriched.groupby("Secteur").agg({
                "Score_composite": "mean",
                "Participations": "mean",
                "CA_rÃ©glÃ©": "sum"
            }).round(2)
            engagement_secteur.columns = ["Score Moyen", "Participations Moy", "CA Total"]
            st.dataframe(engagement_secteur, use_container_width=True)
        else:
            engagement_secteur = pd.DataFrame()

        st.subheader("ğŸŒ Comparaison Standards Internationaux")
        ba_experience_ratio = (len(dfc_enriched[dfc_enriched.get("Score_Engagement", 0) >= 50]) / total_ba * 100) if total_ba > 0 else 0
        formation_continue = (len(dfc_enriched[dfc_enriched.get("Participations", 0) >= 2]) / total_ba * 100) if total_ba > 0 else 0
        kpi_standards = pd.DataFrame({
            "KPI": [
                "Taux de certification",
                "Formation continue",
                "ExpÃ©rience mÃ©tier",
                "DiversitÃ© sectorielle",
                "Engagement communautaire"
            ],
            "Cameroun": [f"{taux_certif:.1f}%", f"{formation_continue:.1f}%", f"{ba_experience_ratio:.1f}%",
                        f"{diversite_sectorielle} secteurs", f"{dfc_enriched.get('Participations', pd.Series(dtype=float)).mean():.1f} events/BA"],
            "Standard IIBA": ["25-35%", "60-70%", "70-80%", "8-10 secteurs", "2-3 events/an"]
        })
        st.dataframe(kpi_standards, use_container_width=True)

    with tab_swot:
        st.subheader("âš–ï¸ Analyse SWOT - IIBA Cameroun")
        col_sw, col_ot = st.columns(2)

        with col_sw:
            st.markdown("### ğŸ’ª **FORCES**")
            st.write(f"""
            â€¢ **DiversitÃ© sectorielle**: {diversite_sectorielle} secteurs reprÃ©sentÃ©s  
            â€¢ **Engagement communautaire**: {taux_participation:.1f} participations moy./BA  
            â€¢ **Base financiÃ¨re**: {ca_total:,.0f} FCFA de revenus  
            â€¢ **Pipeline prospects**: {prospects_chauds} prospects chauds  
            â€¢ **Croissance digitale**: Adoption d'outils en ligne  
            """)

            st.markdown("### âš ï¸ **FAIBLESSES**")
            st.write(f"""
            â€¢ **Taux de certification**: {taux_certif:.1f}% (vs 30% standard)  
            â€¢ **Concentration gÃ©ographique**: Focus Douala/YaoundÃ©  
            â€¢ **Formations avancÃ©es limitÃ©es**  
            â€¢ **Standardisation des pratiques Ã  renforcer**  
            â€¢ **VisibilitÃ© internationale faible**  
            """)

        with col_ot:
            st.markdown("### ğŸš€ **OPPORTUNITÃ‰S**")
            st.write("""
            â€¢ Transformation digitale : demande croissante BA  
            â€¢ Partenariats entreprises : Top-20 identifiÃ©es  
            â€¢ Certification IIBA : programme de dÃ©veloppement  
            â€¢ Expansion rÃ©gionale : Afrique Centrale  
            â€¢ Formations spÃ©cialisÃ©es : IA, Data, Agile  
            """)

            st.markdown("### â›” **MENACES**")
            st.write("""
            â€¢ Concurrence de consultants internationaux  
            â€¢ Fuite des cerveaux vers l'Ã©tranger  
            â€¢ Ã‰conomie incertaine (budgets formation)  
            â€¢ Manque de reconnaissance du mÃ©tier BA  
            â€¢ Technologie Ã©voluant rapidement  
            """)

        st.subheader("ğŸ¯ Plan d'Actions StratÃ©giques")
        actions_df = pd.DataFrame({
            "Axe": ["Formation", "Certification", "Partenariats", "Expansion", "Communication"],
            "Action": [
                "DÃ©velopper programme formation continue",
                "Accompagner vers certifications IIBA",
                "Formaliser accords entreprises Top-20",
                "Ouvrir antennes rÃ©gionales",
                "Renforcer visibilitÃ© et marketing"
            ],
            "PrioritÃ©": ["Ã‰levÃ©e", "Ã‰levÃ©e", "Moyenne", "Faible", "Moyenne"],
            "Ã‰chÃ©ance": ["6 mois", "12 mois", "9 mois", "24 mois", "Continu"]
        })
        st.dataframe(actions_df, use_container_width=True)

    with tab_bsc:
        st.subheader("ğŸ“ˆ Balanced Scorecard - IIBA Cameroun")
        tab_fin, tab_client, tab_proc, tab_app = st.tabs(["ğŸ’° FinanciÃ¨re", "ğŸ‘¥ Client", "âš™ï¸ Processus", "ğŸ“š Apprentissage"])

        with tab_fin:
            st.write("### ğŸ’° Perspective FinanciÃ¨re")
            col_f1, col_f2, col_f3 = st.columns(3)
            croissance_ca = 15  # TODO: calculer Ã  partir de l'historique si dispo
            # marge sur la pÃ©riode filtrÃ©e (ev_fin)
            if not ev_fin.empty and ev_fin["Recette"].sum() > 0:
                marge_benefice = (ev_fin["BÃ©nÃ©fice"].sum() / ev_fin["Recette"].sum() * 100)
            else:
                marge_benefice = 0.0
            col_f1.metric("ğŸ’µ CA Total", f"{ca_total:,.0f} FCFA")
            col_f2.metric("ğŸ“ˆ Croissance CA", f"{croissance_ca}%", help="Objectif: +20%/an")
            col_f3.metric("ğŸ“Š Marge BÃ©nÃ©fice", f"{marge_benefice:.1f}%", help="Objectif: 25%")

            fin_data = pd.DataFrame({
                "Indicateur": ["Revenus formations", "Revenus certifications", "Revenus Ã©vÃ©nements", "CoÃ»ts opÃ©rationnels"],
                "RÃ©el": [f"{ca_total*0.6:.0f}", f"{ca_total*0.2:.0f}", f"{ca_total*0.2:.0f}", f"{ev_fin['CoÃ»t_Total'].sum() if not ev_fin.empty else 0:.0f}"],
                "Objectif": ["3M", "1M", "1M", "3.5M"],
                "Ã‰cart": ["Ã€ calculer", "Ã€ calculer", "Ã€ calculer", "Ã€ calculer"]
            })
            st.dataframe(fin_data, use_container_width=True)

        with tab_client:
            st.write("### ğŸ‘¥ Perspective Client")
            col_c1, col_c2, col_c3 = st.columns(3)
            satisfaction_moy = float(dfc_enriched[dfc_enriched.get("A_certification", False) == True].get("Score_Engagement", pd.Series(dtype=float)).mean() or 0)
            denom_ret = len(dfc_enriched[dfc_enriched["Type"].isin(["Membre", "Prospect"])])
            retention = (len(dfc_enriched[dfc_enriched["Type"] == "Membre"]) / denom_ret * 100) if denom_ret > 0 else 0
            col_c1.metric("ğŸ˜Š Satisfaction", f"{satisfaction_moy:.1f}/100", help="Score engagement (certifiÃ©s)")
            col_c2.metric("ğŸ”„ RÃ©tention", f"{retention:.1f}%", help="Taux prospectâ†’membre")
            col_c3.metric("ğŸ“ˆ NPS EstimÃ©", "65", help="Net Promoter Score estimÃ©")

            client_data = pd.DataFrame({
                "Segment": ["Prospects Chauds", "Prospects TiÃ¨des", "Prospects Froids", "Membres Actifs"],
                "Nombre": [
                    len(dfc_enriched[dfc_enriched.get("Proba_conversion","") == "Chaud"]),
                    len(dfc_enriched[dfc_enriched.get("Proba_conversion","") == "TiÃ¨de"]),
                    len(dfc_enriched[dfc_enriched.get("Proba_conversion","") == "Froid"]),
                    len(dfc_enriched[dfc_enriched["Type"] == "Membre"])
                ],
            })
            client_data["% Total"] = (client_data["Nombre"] / max(1, client_data["Nombre"].sum()) * 100).round(1)
            st.dataframe(client_data, use_container_width=True)

        with tab_proc:
            st.write("### âš™ï¸ Perspective Processus Internes")
            col_p1, col_p2, col_p3 = st.columns(3)
            denom_prosp = len(dfc_enriched[dfc_enriched["Type"] == "Prospect"])
            efficacite_conv = (prospects_chauds / denom_prosp * 100) if denom_prosp > 0 else 0
            temps_reponse = 2.5  # placeholder
            col_p1.metric("âš¡ EfficacitÃ© Conversion", f"{efficacite_conv:.1f}%")
            col_p2.metric("â±ï¸ Temps RÃ©ponse", f"{temps_reponse} jours")
            col_p3.metric("ğŸ¯ Taux Participation", f"{taux_participation:.1f}")

            proc_data = pd.DataFrame({
                "Processus": ["Acquisition prospects", "Conversion membres", "DÃ©livrance formations", "Suivi post-formation"],
                "Performance": ["75%", f"{retention:.1f}%", "90%", "60%"],
                "Objectif": ["80%", "25%", "95%", "75%"],
                "Actions": ["AmÃ©liorer ciblage", "Renforcer follow-up", "Optimiser contenu", "SystÃ©matiser enquÃªtes"]
            })
            st.dataframe(proc_data, use_container_width=True)

        with tab_app:
            st.write("### ğŸ“š Perspective Apprentissage & Croissance")
            col_a1, col_a2, col_a3 = st.columns(3)
            col_a1.metric("ğŸ“ Taux Certification", f"{taux_certif:.1f}%")
            col_a2.metric("ğŸ“– Formation Continue", f"{formation_continue:.1f}%")
            col_a3.metric("ğŸ”„ Innovation", "3 projets", help="Nouveaux programmes/an")

            comp_data = pd.DataFrame({
                "CompÃ©tence": ["Business Analysis", "AgilitÃ©", "Data Analysis", "Digital Transformation", "Leadership"],
                "Niveau Actuel": [65, 45, 35, 40, 55],
                "Objectif 2025": [80, 65, 60, 70, 70],
                "Gap": [15, 20, 25, 30, 15]
            })
            st.dataframe(comp_data, use_container_width=True)

    # --- Export Markdown consolidÃ© (utilise variables dÃ©jÃ  calculÃ©es ci-dessus) ---
    st.markdown("---")
    col_export1, col_export2 = st.columns(2)

    with col_export1:
        if st.button("ğŸ“„ GÃ©nÃ©rer Rapport Markdown Complet"):
            # Variables sÃ»res pour le rendu
            try:
                # calcule marge_benefice comme dans l'onglet financier
                if not ev_fin.empty and ev_fin["Recette"].sum() > 0:
                    marge_benefice = (ev_fin["BÃ©nÃ©fice"].sum() / ev_fin["Recette"].sum() * 100)
                else:
                    marge_benefice = 0.0
                genre_counts = dfc_enriched["Genre"].value_counts()
                rapport_md = f"""
# Rapport StratÃ©gique IIBA Cameroun {datetime.now().year}

## Executive Summary
- **Total BA**: {total_ba}
- **Taux Certification**: {taux_certif:.1f}%
- **CA RÃ©alisÃ©**: {ca_total:,.0f} FCFA
- **Secteurs**: {diversite_sectorielle}

## Profil Type BA Camerounais
### DÃ©mographie
- RÃ©partition par genre: {dict(genre_counts)}
- Secteurs dominants: {dict(top_secteurs)}
- Localisation: Concentration Douala/YaoundÃ©

## Analyse SWOT
### Forces
- DiversitÃ© sectorielle ({diversite_sectorielle} secteurs)
- Engagement communautaire Ã©levÃ©
- Base financiÃ¨re solide

### OpportunitÃ©s  
- Transformation digitale
- Expansion rÃ©gionale
- Partenariats entreprises

## Balanced Scorecard
### FinanciÃ¨re
- CA: {ca_total:,.0f} FCFA
- Marge: {marge_benefice:.1f}%

### Client
- Satisfaction: {float(dfc_enriched[dfc_enriched.get("A_certification", False) == True].get("Score_Engagement", pd.Series(dtype=float)).mean() or 0):.1f}/100
- RÃ©tention: {((len(dfc_enriched[dfc_enriched["Type"] == "Membre"]) / max(1, len(dfc_enriched[dfc_enriched["Type"].isin(["Membre","Prospect"])]))) * 100):.1f}%

Rapport gÃ©nÃ©rÃ© le {datetime.now().strftime('%Y-%m-%d %H:%M')}
"""
                st.download_button(
                    "â¬‡ï¸ TÃ©lÃ©charger Rapport.md",
                    rapport_md,
                    file_name=f"Rapport_IIBA_Cameroun_{datetime.now().strftime('%Y%m%d')}.md",
                    mime="text/markdown"
                )
            except Exception as e:
                st.error(f"Erreur gÃ©nÃ©ration Markdown : {e}")

    with col_export2:
        # Export Excel complet des analyses avancÃ©es
        buf_advanced = io.BytesIO()
        with pd.ExcelWriter(buf_advanced, engine="openpyxl") as writer:
            dfc_enriched.to_excel(writer, sheet_name="Contacts_Enrichis", index=False)
            # engagement_secteur peut ne pas exister si dfc_enriched est vide
            try:
                engagement_secteur.to_excel(writer, sheet_name="Engagement_Secteur")
            except Exception:
                pd.DataFrame().to_excel(writer, sheet_name="Engagement_Secteur", index=False)
            try:
                kpi_standards.to_excel(writer, sheet_name="KPI_Standards", index=False)
            except Exception:
                pd.DataFrame().to_excel(writer, sheet_name="KPI_Standards", index=False)
            try:
                actions_df.to_excel(writer, sheet_name="Plan_Actions", index=False)
            except Exception:
                pd.DataFrame().to_excel(writer, sheet_name="Plan_Actions", index=False)

        st.download_button(
            "ğŸ“Š Export Analyses Excel",
            buf_advanced.getvalue(),
            file_name=f"Analyses_IIBA_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )


# ---------------------- PAGE ADMIN â€” Migration & Import/Export ----------------------

elif page == "Admin":
    st.title("âš™ï¸ Admin â€” ParamÃ¨tres, Migration & Maintenance (centralisÃ©s dans parametres.csv)")

    # PARAMETRES LISTES DEROULANTES
    st.markdown("### Listes dÃ©roulantes (stockÃ©es dans parametres.csv)")
    with st.form("lists_form"):
        def show_line(name, label):
            raw = PARAMS.get(f"list_{name}", DEFAULT_LISTS.get(name, ""))
            return st.text_input(label, raw)
        genres = show_line("genres","Genres (sÃ©parÃ©s par |)")
        types_contact = show_line("types_contact","Types de contact (|)")
        statuts_engagement = show_line("statuts_engagement","Statuts d'engagement (|)")
        secteurs = show_line("secteurs","Secteurs (|)")
        pays = show_line("pays","Pays (|)")
        villes = show_line("villes","Villes (|)")
        sources = show_line("sources","Sources (|)")
        canaux = show_line("canaux","Canaux (|)")
        resultats_inter = show_line("resultats_inter","RÃ©sultats d'interaction (|)")
        types_evenements = show_line("types_evenements","Types d'Ã©vÃ©nements (|)")
        lieux = show_line("lieux","Lieux (|)")
        statuts_paiement = show_line("statuts_paiement","Statuts paiement (|)")
        moyens_paiement = show_line("moyens_paiement","Moyens paiement (|)")
        types_certif = show_line("types_certif","Types certification (|)")
        entreprises_cibles = show_line("entreprises_cibles","Entreprises cibles (Top-20) (|)")
        ok1 = st.form_submit_button("ğŸ’¾ Enregistrer les listes")
        if ok1:
            PARAMS.update({
                "list_genres": genres, "list_types_contact": types_contact, "list_statuts_engagement": statuts_engagement,
                "list_secteurs": secteurs, "list_pays": pays, "list_villes": villes, "list_sources": sources,
                "list_canaux": canaux, "list_resultats_inter": resultats_inter, "list_types_evenements": types_evenements,
                "list_lieux": lieux, "list_statuts_paiement": statuts_paiement, "list_moyens_paiement": moyens_paiement,
                "list_types_certif": types_certif, "list_entreprises_cibles": entreprises_cibles,
            })
            save_params(PARAMS)
            st.success("Listes enregistrÃ©es dans parametres.csv â€” rechargez la page si nÃ©cessaire.")

    # PARAMETRES SCORING ET AFFICHAGE
    st.markdown("### RÃ¨gles de scoring & d'affichage (parametres.csv)")
    with st.form("rules_form"):
        c1,c2,c3,c4 = st.columns(4)
        vip_thr = c1.number_input("Seuil VIP (FCFA)", min_value=0.0, step=50000.0, value=float(PARAMS.get("vip_threshold","500000")))
        w_int = c2.number_input("Poids Interaction", min_value=0.0, step=0.5, value=float(PARAMS.get("score_w_interaction","1")))
        w_part = c3.number_input("Poids Participation", min_value=0.0, step=0.5, value=float(PARAMS.get("score_w_participation","1")))
        w_pay = c4.number_input("Poids Paiement rÃ©glÃ©", min_value=0.0, step=0.5, value=float(PARAMS.get("score_w_payment_regle","2")))
        c5,c6,c7 = st.columns(3)
        lookback = c5.number_input("FenÃªtre interactions rÃ©centes (jours)", min_value=1, step=1, value=int(PARAMS.get("interactions_lookback_days","90")))
        hot_int_min = c6.number_input("Interactions rÃ©centes min (chaud)", min_value=0, step=1, value=int(PARAMS.get("rule_hot_interactions_recent_min","3")))
        hot_part_min = c7.number_input("Participations min (chaud)", min_value=0, step=1, value=int(PARAMS.get("rule_hot_participations_min","1")))
        hot_partiel = st.checkbox("Paiement partiel = prospect chaud", value=PARAMS.get("rule_hot_payment_partial_counts_as_hot","1") in ("1","true","True"))

        st.write("**Colonnes de la grille CRM (ordre, sÃ©parÃ©es par des virgules)**")
        grid_crm = st.text_input("CRM â†’ Colonnes", PARAMS.get("grid_crm_columns",""))
        st.caption("Colonnes disponibles : " + ", ".join(sorted(list(set(C_COLS + I_COLS + E_COLS + P_COLS + PAY_COLS + CERT_COLS + ['Interactions','Participations','CA_rÃ©glÃ©','ImpayÃ©','Resp_principal','A_animÃ©_ou_invitÃ©','Score_composite','Proba_conversion','Tags','Dernier_contact','Interactions_recent'])))))

        st.write("**KPI visibles (sÃ©parÃ©s par des virgules)**")
        st.caption("ClÃ©s supportÃ©es : contacts_total, prospects_actifs, membres, events_count, participations_total, ca_regle, impayes, taux_conversion")
        kpi_enabled = st.text_input("KPI activÃ©s", PARAMS.get("kpi_enabled",""))

        st.write("**Objectifs annuels/mensuels (format clÃ©=valeur)**")
        st.caption("Ex. kpi_target_contacts_total_year_2025=1000 ; kpi_target_participations_total_month_202506=120")
        targets_text = st.text_area("Cibles (une par ligne)", "\n".join([f"{k}={v}" for k,v in PARAMS.items() if k.startswith("kpi_target_")]))

        ok2 = st.form_submit_button("ğŸ’¾ Enregistrer (parametres.csv)")
        if ok2:
            PARAMS.update({
                "vip_threshold": str(vip_thr),
                "score_w_interaction": str(w_int),
                "score_w_participation": str(w_part),
                "score_w_payment_regle": str(w_pay),
                "interactions_lookback_days": str(int(lookback)),
                "rule_hot_interactions_recent_min": str(int(hot_int_min)),
                "rule_hot_participations_min": str(int(hot_part_min)),
                "rule_hot_payment_partial_counts_as_hot": "1" if hot_partiel else "0",
                "grid_crm_columns": grid_crm,
                "kpi_enabled": kpi_enabled,
            })
            for line in targets_text.splitlines():
                if "=" in line:
                    key, val = line.split("=",1)
                    key = key.strip()
                    val = val.strip()
                    if key:
                        PARAMS[key] = val
            save_params(PARAMS)
            st.success("ParamÃ¨tres enregistrÃ©s dans parametres.csv â€” les nouvelles listes seront prises en compte au prochain rafraÃ®chissement.")

    # PARAMETRES Rapports AvancÃ©s
    # Dans la section des paramÃ¨tres Admin, ajouter:
    st.markdown("---")
    st.header("ğŸ“Š ParamÃ¨tres Rapports AvancÃ©s")
    
    with st.form("advanced_reports_params"):
        st.subheader("ğŸ¯ Seuils et Objectifs")
        
        col_p1, col_p2 = st.columns(2)
        
        with col_p1:
            # Seuils de segmentation
            seuil_ba_expert = st.number_input(
                "Score BA Expert (seuil)", 
                min_value=0, max_value=100, 
                value=int(PARAMS.get("seuil_ba_expert", "70"))
            )
            seuil_formation_continue = st.number_input(
                "Participations min. formation continue", 
                min_value=0, 
                value=int(PARAMS.get("seuil_formation_continue", "2"))
            )
            objectif_certification = st.number_input(
                "Objectif taux certification (%)", 
                min_value=0, max_value=100, 
                value=int(PARAMS.get("objectif_certification", "30"))
            )
        
        with col_p2:
            # Estimations salariales par secteur
            salaire_banque = st.number_input(
                "Salaire moyen Banque (FCFA)", 
                min_value=0, step=50000,
                value=int(PARAMS.get("salaire_banque", "800000"))
            )
            salaire_telecom = st.number_input(
                "Salaire moyen TÃ©lÃ©com (FCFA)", 
                min_value=0, step=50000,
                value=int(PARAMS.get("salaire_telecom", "750000"))
            )
            multiplicateur_certif = st.number_input(
                "Multiplicateur salaire certifiÃ©", 
                min_value=1.0, max_value=2.0, step=0.1,
                value=float(PARAMS.get("multiplicateur_certif", "1.3"))
            )
        
        # Objectifs BSC
        st.subheader("ğŸ“ˆ Objectifs Balanced Scorecard")
        col_bsc1, col_bsc2 = st.columns(2)
        
        with col_bsc1:
            objectif_croissance_ca = st.number_input(
                "Objectif croissance CA (%/an)", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_croissance_ca", "20"))
            )
            objectif_marge = st.number_input(
                "Objectif marge bÃ©nÃ©fice (%)", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_marge", "25"))
            )
        
        with col_bsc2:
            objectif_retention = st.number_input(
                "Objectif taux rÃ©tention (%)", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_retention", "80"))
            )
            objectif_nps = st.number_input(
                "Objectif NPS", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_nps", "70"))
            )
        
        if st.form_submit_button("ğŸ’¾ Enregistrer ParamÃ¨tres AvancÃ©s"):
            PARAMS.update({
                "seuil_ba_expert": str(seuil_ba_expert),
                "seuil_formation_continue": str(seuil_formation_continue),
                "objectif_certification": str(objectif_certification),
                "salaire_banque": str(salaire_banque),
                "salaire_telecom": str(salaire_telecom),
                "multiplicateur_certif": str(multiplicateur_certif),
                "objectif_croissance_ca": str(objectif_croissance_ca),
                "objectif_marge": str(objectif_marge),
                "objectif_retention": str(objectif_retention),
                "objectif_nps": str(objectif_nps)
            })
            save_params(PARAMS)
            st.success("âœ… ParamÃ¨tres avancÃ©s enregistrÃ©s!")
    

    # PARAMETRES Migration â€” Import/Export
    st.markdown("---")
    st.header("ğŸ“¦ Migration â€” Import/Export Global & Multi-onglets")

    mode_mig = st.radio("Mode de migration", ["Import Excel par Table (.xlsx)", "Import Excel global (.xlsx)", "Import Excel multi-onglets (.xlsx)", "Import CSV global"], horizontal=True)

    if mode_mig == "Import Excel global (.xlsx)":
        up = st.file_uploader("Fichier Excel global (.xlsx)", type=["xlsx"], key="xlsx_up")
        st.caption("Feuille **Global** (ou 1Ã¨re) avec colonne **__TABLE__**.")
        if st.button("Importer l'Excel global") and up is not None:
            log = {"timestamp": datetime.now().isoformat(), "import_type": "excel_global", "counts": {}, "errors": [], "collisions": {}}
            try:
                xls = pd.ExcelFile(up)
                sheet = "Global" if "Global" in xls.sheet_names else xls.sheet_names[0]
                gdf = pd.read_excel(xls, sheet_name=sheet, dtype=str)
                if "__TABLE__" not in gdf.columns:
                    raise ValueError("Colonne '__TABLE__' manquante.")
                cols_global = ["__TABLE__"] + sorted(set(sum(ALL_SCHEMAS.values(), [])))
                for c in cols_global:
                    if c not in gdf.columns:
                        gdf[c] = ""
                # Contacts
                sub_c = gdf[gdf["__TABLE__"] == "contacts"].copy().fillna("")
                sub_c["Top20"] = sub_c["SociÃ©tÃ©"].fillna("").apply(lambda x: x in SET["entreprises_cibles"])

                def dedupe_contacts(df):
                    df = df.copy()
                    rejects = []
                    seen = set()
                    keep = []
                    def norm(s):
                        return str(s).strip().lower()
                    def email_ok2(s):
                        if not s or str(s).strip() == "" or str(s).lower() == "nan":
                            return True
                        return bool(re.match(r"^[^@\s]+@[^@\s]+\.[^@\s]+$", str(s).strip()))
                    for _, r in df.iterrows():
                        if not email_ok2(r.get("Email", "")):
                            rr = r.to_dict()
                            rr["_Raison"] = "Email invalide"
                            rejects.append(rr)
                            continue
                        if r.get("Email", ""):
                            key = ("email", norm(r["Email"]))
                        elif r.get("TÃ©lÃ©phone", ""):
                            key = ("tel", norm(r["TÃ©lÃ©phone"]))
                        else:
                            key = ("nps", (norm(r.get("Nom", "")), norm(r.get("PrÃ©nom", "")), norm(r.get("SociÃ©tÃ©", ""))))
                        if key in seen:
                            rr = r.to_dict()
                            rr["_Raison"] = "Doublon (fichier)"
                            rejects.append(rr)
                            continue
                        seen.add(key)
                        keep.append(r)
                    return pd.DataFrame(keep, columns=C_COLS), pd.DataFrame(rejects)

                valid_c, rejects_c = dedupe_contacts(sub_c)
                base = df_contacts.copy()
                collisions = []
                if "ID" in valid_c.columns and not valid_c.empty:
                    incoming = set(x for x in valid_c["ID"].astype(str) if x and x.lower() != "nan")
                    existing = set(base["ID"].astype(str))
                    collisions = sorted(list(incoming & existing))
                    if collisions:
                        base = base[~base["ID"].isin(collisions)]
                patt = re.compile(r"^CNT_(\d+)$")
                base_max = 0
                for x in base["ID"].dropna().astype(str):
                    m = patt.match(x.strip())
                    if m:
                        try:
                            base_max = max(base_max, int(m.group(1)))
                        except:
                            pass
                next_id = base_max + 1
                new_rows=[]
                for _, r in valid_c.iterrows():
                    rid = r["ID"]
                    if not isinstance(rid, str) or rid.strip() == "" or rid.strip().lower() == "nan":
                        rid = f"CNT_{str(next_id).zfill(3)}"
                        next_id += 1
                    rr = r.to_dict()
                    rr["ID"] = rid
                    new_rows.append(rr)
                base = pd.concat([base, pd.DataFrame(new_rows, columns=C_COLS)], ignore_index=True)
                save_df(base, PATHS["contacts"])
                globals()["df_contacts"] = base
                log["counts"]["contacts"] = len(new_rows)
                log["collisions"]["contacts"] = collisions
                if not rejects_c.empty:
                    st.warning(f"Lignes contacts rejetÃ©es : {len(rejects_c)}")
                    st.dataframe(rejects_c, use_container_width=True)

                # Fonction pour enregistrer subsets
                def save_subset(tbl, cols, path, prefix):
                    sub = gdf[gdf["__TABLE__"] == tbl].copy()
                    sub = sub[cols].fillna("")
                    id_col = cols[0]
                    base_df = ensure_df(path, cols)
                    incoming = set(x for x in sub[id_col].astype(str) if x and x.lower() != "nan")
                    existing = set(base_df[id_col].astype(str))
                    coll = sorted(list(incoming & existing))
                    if coll:
                        base_df = base_df[~base_df[id_col].isin(coll)]
                    patt = re.compile(rf"^{prefix}_(\d+)$")
                    base_max = 0
                    for x in base_df[id_col].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    gen = base_max + 1
                    new_rows = []
                    for _, r in sub.iterrows():
                        cur = r[id_col]
                        if not isinstance(cur, str) or cur.strip() == "" or cur.strip().lower() == "nan":
                            cur = f"{prefix}_{str(gen).zfill(3)}"
                            gen += 1
                        rr = r.to_dict()
                        rr[id_col] = cur
                        new_rows.append(rr)
                    out = pd.concat([base_df, pd.DataFrame(new_rows, columns=cols)], ignore_index=True)
                    save_df(out, path)
                    globals()["df_" + ("inter" if tbl == "interactions" else "events" if tbl == "evenements" else "parts" if tbl == "participations" else "pay" if tbl == "paiements" else "cert")] = out
                    log["counts"][tbl] = len(new_rows)
                    log["collisions"][tbl] = coll

                for spec in [("interactions", I_COLS, PATHS["inter"], "INT"),
                             ("evenements", E_COLS, PATHS["events"], "EVT"),
                             ("participations", P_COLS, PATHS["parts"], "PAR"),
                             ("paiements", PAY_COLS, PATHS["pay"], "PAY"),
                             ("certifications", CERT_COLS, PATHS["cert"], "CER")]:
                    cnt, coll = save_subset(*spec)

                st.success("Import Excel global terminÃ©.")
                st.json(log)
                log_event("import_excel_global", log)
            except Exception as e:
                st.error(f"Erreur d'import Excel global : {e}")
                log_event("error_import_excel_global", {"error": str(e)})

        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="openpyxl") as w:
            gcols = ["__TABLE__"] + sorted(set(sum(ALL_SCHEMAS.values(), [])))
            pd.DataFrame(columns=gcols).to_excel(w, index=False, sheet_name="Global")
        st.download_button("â¬‡ï¸ ModÃ¨le Global (xlsx)", buf.getvalue(), file_name="IIBA_global_template.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    elif mode_mig == "Import Excel par Table (.xlsx)":
        st.subheader("Import Excel par table (1 onglet par table)")
        fichier_multi = st.file_uploader(
            "Classeur Excel (.xlsx) avec un onglet par table : contacts, interactions, evenements, participations, paiements, certifications",
            type=["xlsx"], key="xlsx_par_table"
        )

        # ----------------------------------------------------------------------
        # 1) VALIDATEUR â€” AperÃ§u des onglets + colonnes + 5 premiÃ¨res lignes
        #     + Compteur global de lignes par onglet
        # ----------------------------------------------------------------------
        st.markdown("### ğŸ” Valider le classeur (avant import)")
        st.caption("Le validateur dÃ©tecte les onglets avec tolÃ©rance (accents/casse/alias), liste les colonnes attendues/dÃ©tectÃ©es/manquantes, montre un aperÃ§u (5 lignes) et calcule les compteurs globaux par table.")

        if st.button("ğŸ” Lancer la validation", disabled=(fichier_multi is None)):
            if fichier_multi is None:
                st.warning("Veuillez dâ€™abord sÃ©lectionner un fichier Excel (.xlsx).")
            else:
                try:
                    import unicodedata, re
                    xls = pd.ExcelFile(fichier_multi)

                    # Normalisation robuste des noms
                    def _norm(s: str) -> str:
                        s = unicodedata.normalize("NFD", str(s))
                        s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")  # supprime accents
                        return s.strip().lower()

                    # Map nom_normalisÃ© -> nom_rÃ©el
                    sheet_map = {_norm(n): n for n in xls.sheet_names}

                    # Alias acceptÃ©s
                    aliases = {
                        "contacts":        ["contacts", "contact"],
                        "interactions":    ["interactions", "interaction"],
                        "evenements":      ["evenements", "evenement", "Ã©vÃ©nements", "Ã©vÃ©nement", "events", "event"],
                        "participations":  ["participations", "participation"],
                        "paiements":       ["paiements", "paiement", "payments", "payment"],
                        "certifications":  ["certifications", "certification"],
                    }

                    expected_cols = {
                        "contacts": C_COLS,
                        "interactions": I_COLS,
                        "evenements": E_COLS,
                        "participations": P_COLS,
                        "paiements": PAY_COLS,
                        "certifications": CERT_COLS
                    }

                    # RÃ©sout lâ€™onglet rÃ©el dâ€™une table (alias + normalisation)
                    def resolve_sheet_name(table_key: str):
                        for alias in aliases[table_key]:
                            k = _norm(alias)
                            if k in sheet_map:
                                return sheet_map[k]
                        return None

                    # Compteurs globaux pour le rÃ©capitulatif
                    recap_rows = []   # chaque item: dict(table, feuille, nb_lignes, nb_missing, nb_extra)
                    overall_ok = True

                    for t in ["contacts","interactions","evenements","participations","paiements","certifications"]:
                        real = resolve_sheet_name(t)
                        with st.expander(f"ğŸ“„ Table **{t}** â€” " + (f"âœ… Feuille trouvÃ©e : *{real}*" if real else "âŒ Feuille non trouvÃ©e"), expanded=False):
                            if not real:
                                st.error(f"Onglet manquant pour **{t}**. Alias acceptÃ©s : {', '.join(aliases[t])}")
                                overall_ok = False
                                # Alimente le rÃ©cap mÃªme si manquant
                                recap_rows.append({
                                    "Table": t, "Feuille": "â€”",
                                    "Lignes dÃ©tectÃ©es": 0,
                                    "Colonnes manquantes": len(expected_cols[t]),
                                    "Colonnes supplÃ©mentaires": 0
                                })
                                continue

                            # Lit lâ€™onglet, calcule manquantes/extra, montre un head()
                            df_in = pd.read_excel(xls, sheet_name=real, dtype=str).fillna("")
                            cols_expected = expected_cols[t]
                            cols_detected = list(df_in.columns)
                            missing = [c for c in cols_expected if c not in cols_detected]
                            extra   = [c for c in cols_detected if c not in cols_expected]

                            st.write("**Colonnes attendues** :", ", ".join(cols_expected))
                            st.write("**Colonnes dÃ©tectÃ©es** :", ", ".join(cols_detected) if cols_detected else "_(aucune)_")

                            if missing:
                                st.warning(f"Colonnes **manquantes** ({len(missing)}) : {', '.join(missing)}")
                                overall_ok = False
                            else:
                                st.success("Aucune colonne manquante.")

                            if extra:
                                st.info(f"Colonnes supplÃ©mentaires (ignorÃ©es Ã  lâ€™import) : {', '.join(extra)}")

                            # AperÃ§u
                            st.write("**AperÃ§u des 5 premiÃ¨res lignes**")
                            st.dataframe(df_in.head(5), use_container_width=True)

                            # Alimente le rÃ©capitulatif global
                            recap_rows.append({
                                "Table": t,
                                "Feuille": real,
                                "Lignes dÃ©tectÃ©es": int(len(df_in)),
                                "Colonnes manquantes": int(len(missing)),
                                "Colonnes supplÃ©mentaires": int(len(extra)),
                            })

                    # RÃ©sumÃ© global + compteur agrÃ©gÃ©
                    st.markdown("---")
                    st.subheader("ğŸ“Š RÃ©capitulatif global de la validation")
                    if recap_rows:
                        df_recap = pd.DataFrame(recap_rows)
                        # Totaux
                        tot_lignes = int(df_recap["Lignes dÃ©tectÃ©es"].sum())
                        st.dataframe(df_recap, use_container_width=True)
                        st.info(f"**Total lignes dÃ©tectÃ©es (tous onglets)** : {tot_lignes:,}".replace(",", " "))
                    else:
                        st.info("Aucune donnÃ©e lue.")

                    if overall_ok:
                        st.success("Validation terminÃ©e âœ… â€” Tous les onglets requis sont prÃ©sents et possÃ¨dent leurs colonnes clÃ©s.")
                    else:
                        st.error("Validation terminÃ©e âš ï¸ â€” Corrigez les erreurs ci-dessus avant dâ€™importer (onglets/colonnes manquants).")

                except Exception as e:
                    st.error(f"Erreur de validation : {e}")

        # ----------------------------------------------------------------------
        # 2) IMPORT â€” robuste (alias/normalisation + ID auto + append)
        # ----------------------------------------------------------------------
        st.markdown("### â¬‡ï¸ Importer maintenant")
        if st.button("ğŸ“¥ Importer Excel par table", disabled=(fichier_multi is None)):
            if fichier_multi is None:
                st.warning("Veuillez dâ€™abord sÃ©lectionner un fichier Excel (.xlsx).")
            else:
                log = {"ts": datetime.now().isoformat(), "type": "excel_par_table", "counts": {}, "errors": [], "matched_sheets": {}}
                try:
                    import unicodedata, re
                    xls = pd.ExcelFile(fichier_multi)

                    def _norm(s: str) -> str:
                        s = unicodedata.normalize("NFD", str(s))
                        s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
                        return s.strip().lower()

                    sheet_map = {_norm(n): n for n in xls.sheet_names}

                    aliases = {
                        "contacts":        ["contacts", "contact"],
                        "interactions":    ["interactions", "interaction"],
                        "evenements":      ["evenements", "evenement", "Ã©vÃ©nements", "Ã©vÃ©nement", "events", "event"],
                        "participations":  ["participations", "participation"],
                        "paiements":       ["paiements", "paiement", "payments", "payment"],
                        "certifications":  ["certifications", "certification"],
                    }

                    expected_cols = {
                        "contacts": C_COLS,
                        "interactions": I_COLS,
                        "evenements": E_COLS,
                        "participations": P_COLS,
                        "paiements": PAY_COLS,
                        "certifications": CERT_COLS
                    }

                    def resolve_sheet_name(table_key: str):
                        for alias in aliases[table_key]:
                            k = _norm(alias)
                            if k in sheet_map:
                                return sheet_map[k]
                        return None

                    def import_sheet(table_key: str):
                        real = resolve_sheet_name(table_key)
                        if not real:
                            log["errors"].append(f"Feuille manquante pour '{table_key}' (alias: {aliases[table_key]})")
                            return

                        cols = expected_cols[table_key]
                        df_in = pd.read_excel(xls, sheet_name=real, dtype=str).fillna("")
                        # Assure toutes les colonnes
                        for c in cols:
                            if c not in df_in.columns:
                                df_in[c] = ""
                        df_in = df_in[cols]

                        # Chemins / prÃ©fix
                        path_key = (
                            "events" if table_key == "evenements" else
                            "inter"  if table_key == "interactions" else
                            "parts"  if table_key == "participations" else
                            "pay"    if table_key == "paiements" else
                            "cert"   if table_key == "certifications" else
                            "contacts"
                        )
                        prefix = {"contacts":"CNT","interactions":"INT","evenements":"EVT",
                                  "participations":"PAR","paiements":"PAY","certifications":"CER"}[table_key]

                        path = PATHS[path_key]
                        df_base = ensure_df(path, cols)

                        # DÃ©dup par ID + attribution ID auto en collision/absence
                        id_col = cols[0]
                        exist_ids = set(df_base[id_col].astype(str).tolist())
                        patt = re.compile(rf"^{prefix}_(\d+)$")
                        maxn = 0
                        for vid in exist_ids:
                            m = patt.match(str(vid))
                            if m:
                                try:
                                    maxn = max(maxn, int(m.group(1)))
                                except:
                                    pass
                        next_num = maxn + 1

                        new_rows = []
                        for _, row in df_in.iterrows():
                            rid = str(row[id_col]).strip()
                            if (not rid) or rid.lower() == "nan" or rid in exist_ids:
                                rid = f"{prefix}_{str(next_num).zfill(3)}"
                                next_num += 1
                            r = row.to_dict()
                            r[id_col] = rid
                            new_rows.append(r)

                        if new_rows:
                            df_out = pd.concat([df_base, pd.DataFrame(new_rows, columns=cols)], ignore_index=True)
                            save_df(df_out, path)
                            mem_key = (
                                "events" if table_key == "evenements" else
                                "inter"  if table_key == "interactions" else
                                "parts"  if table_key == "participations" else
                                "pay"    if table_key == "paiements" else
                                "cert"   if table_key == "certifications" else
                                "contacts"
                            )
                            globals()[f"df_{mem_key}"] = df_out
                            log["counts"][table_key] = len(new_rows)
                            log["matched_sheets"][table_key] = real
                        else:
                            log["counts"][table_key] = 0
                            log["matched_sheets"][table_key] = real

                    for t in ["contacts","interactions","evenements","participations","paiements","certifications"]:
                        import_sheet(t)

                    st.success("Import par table terminÃ©.")
                    st.json(log)
                    log_event("import_excel_par_table", log)

                except Exception as e:
                    st.error(f"Erreur lors de l'import par table : {e}")
                    log_event("error_import_excel_par_table", {"error": str(e)})

        # ----------------------------------------------------------------------
        # 3) Export Excel par Table (backup)
        # ----------------------------------------------------------------------
        st.divider()
        st.caption("Exporter les donnÃ©es existantes au format multi-onglets (sÃ©curisation/backup).")

        df_contacts_exp = ensure_df(PATHS["contacts"], C_COLS)
        df_inter_exp    = ensure_df(PATHS["inter"],    I_COLS)
        df_events_exp   = ensure_df(PATHS["events"],   E_COLS)
        df_parts_exp    = ensure_df(PATHS["parts"],    P_COLS)
        df_pay_exp      = ensure_df(PATHS["pay"],      PAY_COLS)
        df_cert_exp     = ensure_df(PATHS["cert"],     CERT_COLS)

        buf_export_multi = io.BytesIO()
        with pd.ExcelWriter(buf_export_multi, engine="openpyxl") as writer:
            df_contacts_exp.to_excel(writer, sheet_name="contacts", index=False)
            df_inter_exp.to_excel(writer,    sheet_name="interactions", index=False)
            df_events_exp.to_excel(writer,   sheet_name="evenements", index=False)
            df_parts_exp.to_excel(writer,    sheet_name="participations", index=False)
            df_pay_exp.to_excel(writer,      sheet_name="paiements", index=False)
            df_cert_exp.to_excel(writer,     sheet_name="certifications", index=False)

        st.download_button(
            "â¬‡ï¸ Exporter Excel par Table (backup)",
            buf_export_multi.getvalue(),
            file_name=f"IIBA_export_multisheets_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="dl_export_multisheets"
        )


    elif mode_mig == "Import Excel multi-onglets (.xlsx)":
        up = st.file_uploader("Classeur Excel (6 feuilles : contacts, interactions, evenements, participations, paiements, certifications)",
                             type=["xlsx"], key="xlsx_multi")
        if st.button("Importer l'Excel multi-onglets") and up is not None:
            log = {"timestamp": datetime.now().isoformat(), "import_type": "excel_multisheets", "counts": {}, "errors": [], "collisions": {}}
            try:
                xls = pd.ExcelFile(up)

                def norm(s):
                    return ''.join(c for c in unicodedata.normalize('NFD', str(s)) if unicodedata.category(c) != 'Mn').lower().strip()

                sheets = {norm(n): n for n in xls.sheet_names}
                aliases = {
                    "contacts": ["contacts", "contact"],
                    "interactions": ["interactions", "interaction"],
                    "evenements": ["evenements", "Ã©vÃ©nements", "events"],
                    "participations": ["participations", "participation"],
                    "paiements": ["paiements", "paiement", "payments"],
                    "certifications": ["certifications", "certification"]
                }
                found = {}
                for tbl, names in aliases.items():
                    for n in names:
                        k = norm(n)
                        if k in sheets:
                            found[tbl] = sheets[k]
                            break

                if "contacts" in found:
                    gdf = pd.read_excel(xls, sheet_name=found["contacts"], dtype=str).fillna("")
                    for c in C_COLS:
                        if c not in gdf.columns:
                            gdf[c] = ""
                    sub_c = gdf[C_COLS].fillna("")
                    sub_c["Top20"] = sub_c["SociÃ©tÃ©"].fillna("").apply(lambda x: x in SET["entreprises_cibles"])

                    seen = set()
                    keep = []
                    for _, r in sub_c.iterrows():
                        key = r.get("Email", "") or r.get("TÃ©lÃ©phone", "") or (r.get("Nom", ""), r.get("PrÃ©nom", ""), r.get("SociÃ©tÃ©", ""))
                        if key in seen:
                            continue
                        seen.add(key)
                        keep.append(r)
                    valid_c = pd.DataFrame(keep, columns=C_COLS)
                    base = df_contacts.copy()
                    collisions = []
                    if "ID" in valid_c.columns and not valid_c.empty:
                        incoming = set(x for x in valid_c["ID"].astype(str) if x and x.lower() != "nan")
                        existing = set(base["ID"].astype(str))
                        collisions = sorted(list(incoming & existing))
                        if collisions:
                            base = base[~base["ID"].isin(collisions)]
                    patt = re.compile(r"^CNT_(\d+)$")
                    base_max = 0
                    for x in base["ID"].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    next_id = base_max + 1
                    new_rows = []
                    for _, r in valid_c.iterrows():
                        rid = r["ID"]
                        if not isinstance(rid, str) or rid.strip() == "" or rid.strip().lower() == "nan":
                            rid = f"CNT_{str(next_id).zfill(3)}"
                            next_id += 1
                        rr = r.to_dict()
                        rr["ID"] = rid
                        new_rows.append(rr)
                    out = pd.concat([base, pd.DataFrame(new_rows, columns=C_COLS)], ignore_index=True)
                    save_df(out, PATHS["contacts"])
                    globals()["df_contacts"] = out
                    log["counts"]["contacts"] = len(new_rows)
                    log["collisions"]["contacts"] = collisions

                def save_sheet(tbl, cols, path, prefix):
                    if tbl not in found:
                        return 0, []
                    sdf = pd.read_excel(xls, sheet_name=found[tbl], dtype=str).fillna("")
                    for c in cols:
                        if c not in sdf.columns:
                            sdf[c] = ""
                    sdf = sdf[cols]
                    id_col = cols[0]
                    base_df = ensure_df(path, cols)
                    incoming = set(x for x in sdf[id_col].astype(str) if x and x.lower() != "nan")
                    existing = set(base_df[id_col].astype(str))
                    coll = sorted(list(incoming & existing))
                    if coll:
                        base_df = base_df[~base_df[id_col].isin(coll)]
                    patt = re.compile(rf"^{prefix}_(\d+)$")
                    base_max = 0
                    for x in base_df[id_col].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    gen = base_max + 1
                    new_rows = []
                    for _, r in sdf.iterrows():
                        cur = r[id_col]
                        if not isinstance(cur, str) or cur.strip() == "" or cur.strip().lower() == "nan":
                            cur = f"{prefix}_{str(gen).zfill(3)}"
                            gen += 1
                        rr = r.to_dict()
                        rr[id_col] = cur
                        new_rows.append(rr)
                    out = pd.concat([base_df, pd.DataFrame(new_rows, columns=cols)], ignore_index=True)
                    save_df(out, path)
                    globals()["df_" + ("inter" if tbl == "interactions" else 
                                      "events" if tbl == "evenements" else 
                                      "parts" if tbl == "participations" else 
                                      "pay" if tbl == "paiements" else "cert")] = out
                    return len(new_rows), coll

                for spec in [("interactions", I_COLS, PATHS["inter"], "INT"),
                             ("evenements", E_COLS, PATHS["events"], "EVT"),
                             ("participations", P_COLS, PATHS["parts"], "PAR"),
                             ("paiements", PAY_COLS, PATHS["pay"], "PAY"),
                             ("certifications", CERT_COLS, PATHS["cert"], "CER")]:
                    cnt, coll = save_sheet(*spec)
                    log["counts"][spec[0]] = cnt
                    log["collisions"][spec] = coll

                st.success("Import Excel multi-onglets terminÃ©.")
                st.json(log)
                log_event("import_excel_multisheets", log)
            except Exception as e:
                st.error(f"Erreur d'import multi-onglets: {e}")
                log_event("error_import_excel_multisheets", {"error": str(e)})

        bufm = io.BytesIO()
        with pd.ExcelWriter(bufm, engine="openpyxl") as w:
            pd.DataFrame(columns=C_COLS).to_excel(w, index=False, sheet_name="contacts")
            pd.DataFrame(columns=I_COLS).to_excel(w, index=False, sheet_name="interactions")
            pd.DataFrame(columns=E_COLS).to_excel(w, index=False, sheet_name="evenements")
            pd.DataFrame(columns=P_COLS).to_excel(w, index=False, sheet_name="participations")
            pd.DataFrame(columns=PAY_COLS).to_excel(w, index=False, sheet_name="paiements")
            pd.DataFrame(columns=CERT_COLS).to_excel(w, index=False, sheet_name="certifications")
        st.download_button("â¬‡ï¸ ModÃ¨le Multi-onglets (xlsx)", bufm.getvalue(), file_name="IIBA_multisheets_template.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    elif mode_mig == "Import CSV global":
        up = st.file_uploader("CSV global (colonne __TABLE__)", type=["csv"], key="g_up")
        if st.button("Importer le CSV global") and up is not None:
            try:
                gdf = pd.read_csv(up, dtype=str, encoding="utf-8")
                if "__TABLE__" not in gdf.columns:
                    raise ValueError("Colonne __TABLE__ manquante.")
                def save_subset(tbl, cols, path, prefix):
                    sub = gdf[gdf["__TABLE__"] == tbl].copy()
                    for c in cols:
                        if c not in sub.columns:
                            sub[c] = ""
                    sub = sub[cols].fillna("")
                    id_col = cols[0]
                    base_df = ensure_df(path, cols)
                    incoming = set(x for x in sub[id_col].astype(str) if x and x.lower() != "nan")
                    existing = set(base_df[id_col].astype(str))
                    coll = sorted(list(incoming & existing))
                    if coll:
                        base_df = base_df[~base_df[id_col].isin(coll)]
                    patt = re.compile(rf"^{prefix}_(\d+)$")
                    base_max = 0
                    for x in base_df[id_col].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    gen = base_max + 1
                    ids = []
                    for _, r in sub.iterrows():
                        rid = r[id_col]
                        if not isinstance(rid, str) or rid.strip() == "" or rid.strip().lower() == "nan":
                            ids.append(f"{prefix}_{str(gen).zfill(3)}")
                            gen += 1
                        else:
                            ids.append(rid.strip())
                    sub[id_col] = ids
                    out = pd.concat([base_df, sub], ignore_index=True)
                    save_df(out, path)
                    globals()["df_" + ("contacts" if tbl == "contacts" else "inter" if tbl == "interactions" else "events" if tbl == "evenements" else "parts" if tbl == "participations" else "pay" if tbl == "paiements" else "cert")] = out
                save_subset("contacts", C_COLS, PATHS["contacts"], "CNT")
                save_subset("interactions", I_COLS, PATHS["inter"], "INT")
                save_subset("evenements", E_COLS, PATHS["events"], "EVT")
                save_subset("participations", P_COLS, PATHS["parts"], "PAR")
                save_subset("paiements", PAY_COLS, PATHS["pay"], "PAY")
                save_subset("certifications", CERT_COLS, PATHS["cert"], "CER")
                st.success("Import CSV global terminÃ©.")
            except Exception as e:
                st.error(f"Erreur d'import CSV global : {e}")

    # ... code existant load_and_compute_kpis() ...

    st.markdown("---")
    st.header("ğŸ”§ Maintenance Base de DonnÃ©es")
    
    col_reset, col_purge = st.columns(2)
    
    with col_reset:
        st.subheader("ğŸ—‘ï¸ RÃ©initialisation ComplÃ¨te")
        st.warning("âš ï¸ Cette action supprime TOUTES les donnÃ©es et recrÃ©e les fichiers vides.")
        
        confirm_reset = st.text_input(
            "Tapez 'RESET' pour confirmer:",
            placeholder="RESET"
        )
        
        if st.button("ğŸ’£ RÃ‰INITIALISER LA BASE", type="secondary"):
            if confirm_reset == "RESET":
                try:
                    # Suppression de tous les fichiers CSV
                    for path in PATHS.values():
                        if path.exists():
                            path.unlink()
                    
                    # RecrÃ©ation des fichiers vides
                    for table, cols in ALL_SCHEMAS.items():
                        empty_df = pd.DataFrame(columns=cols)
                        save_df(empty_df, PATHS[table])
                    
                    # RecrÃ©ation parametres.csv
                    df_params = pd.DataFrame({
                        "key": list(ALL_DEFAULTS.keys()), 
                        "value": list(ALL_DEFAULTS.values())
                    })
                    df_params.to_csv(PATHS["params"], index=False, encoding="utf-8")
                    
                    # Journalisation
                    log_event("reset_database", {
                        "action": "RÃ©initialisation complÃ¨te",
                        "tables_recreated": list(ALL_SCHEMAS.keys()),
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    st.success("âœ… Base de donnÃ©es rÃ©initialisÃ©e avec succÃ¨s!")
                    st.info("ğŸ”„ Rechargez la page pour voir les modifications.")
                    
                except Exception as e:
                    st.error(f"âŒ Erreur lors de la rÃ©initialisation: {e}")
                    log_event("error_reset_database", {"error": str(e)})
            else:
                st.error("âŒ Veuillez taper 'RESET' pour confirmer.")
    
    with col_purge:
        st.subheader("ğŸ¯ Purge d'un Identifiant")
        st.info("Supprime un contact, Ã©vÃ©nement, interaction, etc. par son ID")
        
        purge_id = st.text_input(
            "ID Ã  supprimer (ex: CNT_001, EVT_005, INT_023):",
            placeholder="CNT_001"
        )
        
        purge_type = st.selectbox(
            "Type d'entitÃ©:",
            ["Auto-dÃ©tection", "Contact", "Ã‰vÃ©nement", "Interaction", "Participation", "Paiement", "Certification"]
        )
        
        if st.button("ğŸ—‘ï¸ PURGER CET ID", type="secondary"):
            if purge_id:
                try:
                    deleted_count = 0
                    deleted_from = []
                    
                    if purge_type == "Auto-dÃ©tection":
                        # DÃ©tection automatique basÃ©e sur le prÃ©fixe
                        if purge_id.startswith("CNT_"):
                            purge_type = "Contact"
                        elif purge_id.startswith("EVT_"):
                            purge_type = "Ã‰vÃ©nement"
                        elif purge_id.startswith("INT_"):
                            purge_type = "Interaction"
                        elif purge_id.startswith("PAR_"):
                            purge_type = "Participation"
                        elif purge_id.startswith("PAY_"):
                            purge_type = "Paiement"
                        elif purge_id.startswith("CER_"):
                            purge_type = "Certification"
                    
                    # Suppression selon le type
                    if purge_type == "Contact":
                        # Suppression en cascade: contact + toutes ses relations
                        original_len = len(df_contacts)
                        globals()["df_contacts"] = df_contacts[df_contacts["ID"] != purge_id]
                        deleted_count += original_len - len(df_contacts)
                        if deleted_count > 0:
                            save_df(df_contacts, PATHS["contacts"])
                            deleted_from.append("contacts")
                        
                        # Suppression interactions liÃ©es
                        original_len = len(df_inter)
                        globals()["df_inter"] = df_inter[df_inter["ID"] != purge_id]
                        inter_deleted = original_len - len(df_inter)
                        if inter_deleted > 0:
                            save_df(df_inter, PATHS["inter"])
                            deleted_from.append(f"interactions ({inter_deleted})")
                        
                        # Suppression participations liÃ©es
                        original_len = len(df_parts)
                        globals()["df_parts"] = df_parts[df_parts["ID"] != purge_id]
                        part_deleted = original_len - len(df_parts)
                        if part_deleted > 0:
                            save_df(df_parts, PATHS["parts"])
                            deleted_from.append(f"participations ({part_deleted})")
                        
                        # Suppression paiements liÃ©s
                        original_len = len(df_pay)
                        globals()["df_pay"] = df_pay[df_pay["ID"] != purge_id]
                        pay_deleted = original_len - len(df_pay)
                        if pay_deleted > 0:
                            save_df(df_pay, PATHS["pay"])
                            deleted_from.append(f"paiements ({pay_deleted})")
                        
                        # Suppression certifications liÃ©es
                        original_len = len(df_cert)
                        globals()["df_cert"] = df_cert[df_cert["ID"] != purge_id]
                        cert_deleted = original_len - len(df_cert)
                        if cert_deleted > 0:
                            save_df(df_cert, PATHS["cert"])
                            deleted_from.append(f"certifications ({cert_deleted})")
                    
                    elif purge_type == "Ã‰vÃ©nement":
                        # Suppression Ã©vÃ©nement + participations + paiements liÃ©s
                        original_len = len(df_events)
                        globals()["df_events"] = df_events[df_events["ID_Ã‰vÃ©nement"] != purge_id]
                        deleted_count += original_len - len(df_events)
                        if deleted_count > 0:
                            save_df(df_events, PATHS["events"])
                            deleted_from.append("evenements")
                        
                        # Suppression participations Ã  cet Ã©vÃ©nement
                        original_len = len(df_parts)
                        globals()["df_parts"] = df_parts[df_parts["ID_Ã‰vÃ©nement"] != purge_id]
                        part_deleted = original_len - len(df_parts)
                        if part_deleted > 0:
                            save_df(df_parts, PATHS["parts"])
                            deleted_from.append(f"participations ({part_deleted})")
                        
                        # Suppression paiements Ã  cet Ã©vÃ©nement
                        original_len = len(df_pay)
                        globals()["df_pay"] = df_pay[df_pay["ID_Ã‰vÃ©nement"] != purge_id]
                        pay_deleted = original_len - len(df_pay)
                        if pay_deleted > 0:
                            save_df(df_pay, PATHS["pay"])
                            deleted_from.append(f"paiements ({pay_deleted})")
                    
                    elif purge_type == "Interaction":
                        original_len = len(df_inter)
                        globals()["df_inter"] = df_inter[df_inter["ID_Interaction"] != purge_id]
                        deleted_count += original_len - len(df_inter)
                        if deleted_count > 0:
                            save_df(df_inter, PATHS["inter"])
                            deleted_from.append("interactions")
                    
                    elif purge_type == "Participation":
                        original_len = len(df_parts)
                        globals()["df_parts"] = df_parts[df_parts["ID_Participation"] != purge_id]
                        deleted_count += original_len - len(df_parts)
                        if deleted_count > 0:
                            save_df(df_parts, PATHS["parts"])
                            deleted_from.append("participations")
                    
                    elif purge_type == "Paiement":
                        original_len = len(df_pay)
                        globals()["df_pay"] = df_pay[df_pay["ID_Paiement"] != purge_id]
                        deleted_count += original_len - len(df_pay)
                        if deleted_count > 0:
                            save_df(df_pay, PATHS["pay"])
                            deleted_from.append("paiements")
                    
                    elif purge_type == "Certification":
                        original_len = len(df_cert)
                        globals()["df_cert"] = df_cert[df_cert["ID_Certif"] != purge_id]
                        deleted_count += original_len - len(df_cert)
                        if deleted_count > 0:
                            save_df(df_cert, PATHS["cert"])
                            deleted_from.append("certifications")
                    
                    # Journalisation
                    log_event("purge_id", {
                        "purged_id": purge_id,
                        "type": purge_type,
                        "deleted_count": deleted_count,
                        "tables_affected": deleted_from,
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    if deleted_count > 0 or deleted_from:
                        st.success(f"âœ… ID '{purge_id}' purgÃ© avec succÃ¨s!")
                        st.info(f"ğŸ“Š Suppressions: {', '.join(deleted_from)}")
                        st.info("ğŸ”„ Rechargez la page pour voir les modifications.")
                    else:
                        st.warning(f"âš ï¸ ID '{purge_id}' introuvable dans la base.")
                
                except Exception as e:
                    st.error(f"âŒ Erreur lors de la purge: {e}")
                    log_event("error_purge_id", {"purge_id": purge_id, "error": str(e)})
            else:
                st.error("âŒ Veuillez saisir un ID Ã  purger.")
 
