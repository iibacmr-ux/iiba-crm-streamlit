# Streamlit CRM IIBA Cameroun - app.py corrigÃ© et complet

from datetime import datetime, date, timedelta
from pathlib import Path
import io
import json
import re
import unicodedata
import numpy as np
import pandas as pd
import streamlit as st

# AgGrid
try:
    from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode, JsCode
    HAS_AGGRID = True
except Exception:
    HAS_AGGRID = False

# Graphiques Altair
try:
    import altair as alt
except Exception:
    alt = None

import openpyxl

st.set_page_config(page_title="IIBA Cameroun â€” CRM", page_icon="ğŸ“Š", layout="wide")

# ----------- Paths et schÃ©mas ----------------
DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)

PATHS = {
    "contacts": DATA_DIR / "contacts.csv",
    "inter": DATA_DIR / "interactions.csv",
    "events": DATA_DIR / "evenements.csv",
    "parts": DATA_DIR / "participations.csv",
    "pay": DATA_DIR / "paiements.csv",
    "cert": DATA_DIR / "certifications.csv",
    "params": DATA_DIR / "parametres.csv",
    "logs": DATA_DIR / "migration_logs.jsonl"
}

C_COLS = ["ID","Nom","PrÃ©nom","Genre","Titre","SociÃ©tÃ©","Secteur","Email","TÃ©lÃ©phone","LinkedIn",
          "Ville","Pays","Type","Source","Statut","Score_Engagement","Date_Creation","Notes","Top20"]
I_COLS = ["ID_Interaction","ID","Date","Canal","Objet","RÃ©sumÃ©","RÃ©sultat","Prochaine_Action","Relance","Responsable"]
E_COLS = ["ID_Ã‰vÃ©nement","Nom_Ã‰vÃ©nement","Type","Date","DurÃ©e_h","Lieu","Formateur","Objectif","Periode",
          "Cout_Salle","Cout_Formateur","Cout_Logistique","Cout_Pub","Cout_Autres","Cout_Total","Notes"]
P_COLS = ["ID_Participation","ID","ID_Ã‰vÃ©nement","RÃ´le","Inscription","ArrivÃ©e","Temps_Present","Feedback","Note","Commentaire"]
PAY_COLS = ["ID_Paiement","ID","ID_Ã‰vÃ©nement","Date_Paiement","Montant","Moyen","Statut","RÃ©fÃ©rence","Notes","Relance"]
CERT_COLS = ["ID_Certif","ID","Type_Certif","Date_Examen","RÃ©sultat","Score","Date_Obtention","ValiditÃ©","Renouvellement","Notes"]

ALL_SCHEMAS = {
    "contacts": C_COLS, "interactions": I_COLS, "evenements": E_COLS,
    "participations": P_COLS, "paiements": PAY_COLS, "certifications": CERT_COLS,
}

DEFAULT_LISTS = {
    "genres":"Homme|Femme|Autre",
    "secteurs":"Banque|TÃ©lÃ©com|IT|Ã‰ducation|SantÃ©|ONG|Industrie|Public|Autre",
    "types_contact":"Membre|Prospect|Formateur|Partenaire",
    "sources":"Afterwork|Formation|LinkedIn|Recommandation|Site Web|Salon|Autre",
    "statuts_engagement":"Actif|Inactif|Ã€ relancer",
    "canaux":"Appel|Email|WhatsApp|Zoom|PrÃ©sentiel|Autre",
    "villes":"Douala|YaoundÃ©|Limbe|Bafoussam|Garoua|Autres",
    "pays":"Cameroun|CÃ´te d'Ivoire|SÃ©nÃ©gal|France|Canada|Autres",
    "types_evenements":"Formation|Groupe d'Ã©tude|BA MEET UP|Webinaire|ConfÃ©rence|Certification",
    "lieux":"PrÃ©sentiel|Zoom|Hybride",
    "resultats_inter":"Positif|NÃ©gatif|Ã€ suivre|Sans suite",
    "statuts_paiement":"RÃ©glÃ©|Partiel|Non payÃ©",
    "moyens_paiement":"Mobile Money|Virement|CB|Cash",
    "types_certif":"ECBA|CCBA|CBAP|PBA",
    "entreprises_cibles":"Dangote|MUPECI|SALAM|SUNU IARD|ENEO|PAD|PAK",
}

PARAM_DEFAULTS = {
    "vip_threshold":"500000",
    "score_w_interaction":"1",
    "score_w_participation":"1",
    "score_w_payment_regle":"2",
    "interactions_lookback_days":"90",
    "rule_hot_interactions_recent_min":"3",
    "rule_hot_participations_min":"1",
    "rule_hot_payment_partial_counts_as_hot":"1",
    "grid_crm_columns": ",".join([
        "ID","Nom","PrÃ©nom","SociÃ©tÃ©","Type","Statut","Email",
        "Interactions","Participations","CA_rÃ©glÃ©","ImpayÃ©","Resp_principal","A_animÃ©_ou_invitÃ©",
        "Score_composite","Proba_conversion","Tags"
    ]),
    "grid_events_columns": ",".join(E_COLS),
    "kpi_enabled": ",".join([
        "contacts_total","prospects_actifs","membres","events_count",
        "participations_total","ca_regle","impayes","taux_conversion"
    ]),
    "kpi_target_contacts_total_year_2025":"1000",
    "kpi_target_ca_regle_year_2025":"5000000",
}

ALL_DEFAULTS = {**PARAM_DEFAULTS, **{f"list_{k}":v for k,v in DEFAULT_LISTS.items()}}

def load_params()->dict:
    if not PATHS["params"].exists():
        df = pd.DataFrame({"key":list(ALL_DEFAULTS.keys()), "value":list(ALL_DEFAULTS.values())})
        df.to_csv(PATHS["params"], index=False, encoding="utf-8")
        return ALL_DEFAULTS.copy()
    try:
        df = pd.read_csv(PATHS["params"], dtype=str).fillna("")
        d = {r["key"]: r["value"] for _,r in df.iterrows()}
    except Exception:
        d = ALL_DEFAULTS.copy()
    for k,v in ALL_DEFAULTS.items():
        if k not in d: d[k]=v
    return d

def save_params(d:dict):
    rows = [{"key":k,"value":str(v)} for k,v in d.items()]
    pd.DataFrame(rows).to_csv(PATHS["params"], index=False, encoding="utf-8")

PARAMS = load_params()

def get_list(name:str)->list:
    raw = PARAMS.get(f"list_{name}", DEFAULT_LISTS.get(name,""))
    vals = [x.strip() for x in str(raw).split("|") if x.strip()]
    return vals

SET = {
    "genres": get_list("genres"),
    "secteurs": get_list("secteurs"),
    "types_contact": get_list("types_contact"),
    "sources": get_list("sources"),
    "statuts_engagement": get_list("statuts_engagement"),
    "canaux": get_list("canaux"),
    "villes": get_list("villes"),
    "pays": get_list("pays"),
    "types_evenements": get_list("types_evenements"),
    "lieux": get_list("lieux"),
    "resultats_inter": get_list("resultats_inter"),
    "statuts_paiement": get_list("statuts_paiement"),
    "moyens_paiement": get_list("moyens_paiement"),
    "types_certif": get_list("types_certif"),
    "entreprises_cibles": get_list("entreprises_cibles"),
}

# Utils for dataframe loading/saving

def ensure_df(path:Path, cols:list)->pd.DataFrame:
    if path.exists():
        try: 
            df = pd.read_csv(path, dtype=str, encoding="utf-8")
        except Exception:
            df = pd.DataFrame(columns=cols)
    else:
        df = pd.DataFrame(columns=cols)
    for c in cols:
        if c not in df.columns:
            df[c]=""
    return df[cols]

def save_df(df:pd.DataFrame, path:Path):
    df.to_csv(path, index=False, encoding="utf-8")

def parse_date(s:str):
    if not s or str(s).strip()=="" or str(s).lower()=="nan":
        return None
    for fmt in ("%Y-%m-%d","%d/%m/%Y","%Y/%m/%d"):
        try:
            return datetime.strptime(str(s), fmt).date()
        except:
            pass
    try:
        return pd.to_datetime(s).date()
    except:
        return None

def email_ok(s:str)->bool:
    if not s or str(s).strip()=="" or str(s).lower()=="nan":
        return True
    return bool(re.match(r"^[^@\s]+@[^@\s]+\.[^@\s]+$", str(s).strip()))

def phone_ok(s:str)->bool:
    if not s or str(s).strip()=="" or str(s).lower()=="nan":
        return True
    s2 = re.sub(r"[ \.\-\(\)]","",str(s)).replace("+","")
    return s2.isdigit() and len(s2)>=8

def generate_id(prefix:str, df:pd.DataFrame, id_col:str, width:int=3)->str:
    if df.empty or id_col not in df.columns:
        return f"{prefix}_{str(1).zfill(width)}"
    patt = re.compile(rf"^{re.escape(prefix)}_(\d+)$")
    mx = 0
    for x in df[id_col].dropna().astype(str):
        m = patt.match(x.strip())
        if m:
            try:
                mx = max(mx, int(m.group(1)))
            except:
                pass
    return f"{prefix}_{str(mx+1).zfill(width)}"

def log_event(kind:str, payload:dict):
    rec = {"ts": datetime.now().isoformat(), "kind": kind, **payload}
    with PATHS["logs"].open("a", encoding="utf-8") as f:
        f.write(json.dumps(rec, ensure_ascii=False) + "\n")

# Load data
df_contacts = ensure_df(PATHS["contacts"], C_COLS)
df_inter    = ensure_df(PATHS["inter"], I_COLS)
df_events   = ensure_df(PATHS["events"], E_COLS)
df_parts    = ensure_df(PATHS["parts"], P_COLS)
df_pay      = ensure_df(PATHS["pay"], PAY_COLS)
df_cert     = ensure_df(PATHS["cert"], CERT_COLS)
if not df_contacts.empty:
    df_contacts["Top20"] = df_contacts["SociÃ©tÃ©"].fillna("").apply(lambda x: x in SET["entreprises_cibles"])

# Aggregate function for contacts (calculs des scores, tags, etc.)

def aggregates_for_contacts(today=None):
    today = today or date.today()
    vip_thr = float(PARAMS.get("vip_threshold", "500000"))
    w_int = float(PARAMS.get("score_w_interaction", "1"))
    w_part = float(PARAMS.get("score_w_participation", "1"))
    w_pay = float(PARAMS.get("score_w_payment_regle", "2"))
    lookback = int(PARAMS.get("interactions_lookback_days", "90"))
    hot_int_min = int(PARAMS.get("rule_hot_interactions_recent_min", "3"))
    hot_part_min = int(PARAMS.get("rule_hot_participations_min", "1"))
    hot_partiel = PARAMS.get("rule_hot_payment_partial_counts_as_hot", "1") in ("1", "true", "True")

    inter_count = df_inter.groupby("ID")["ID_Interaction"].count() if not df_inter.empty else pd.Series(dtype=int)
    inter_dates = pd.to_datetime(df_inter["Date"], errors="coerce") if not df_inter.empty else pd.Series(dtype="datetime64[ns]")
    last_contact = df_inter.assign(_d=inter_dates).groupby("ID")["_d"].max() if not df_inter.empty else pd.Series(dtype="datetime64[ns]")
    recent_cut = today - timedelta(days=lookback)
    recent_inter = df_inter.assign(_d=inter_dates).loc[lambda d: d["_d"] >= pd.Timestamp(recent_cut)].groupby("ID")["ID_Interaction"].count() if not df_inter.empty else pd.Series(dtype=int)

    resp_max = pd.Series(dtype=str)
    if not df_inter.empty:
        tmp = df_inter.groupby(["ID","Responsable"])["ID_Interaction"].count().reset_index()
        idx = tmp.groupby("ID")["ID_Interaction"].idxmax()
        resp_max = tmp.loc[idx].set_index("ID")["Responsable"]
        
    parts_count = df_parts.groupby("ID")["ID_Participation"].count() if not df_parts.empty else pd.Series(dtype=int)
    has_anim = pd.Series(dtype=bool)
    if not df_parts.empty:
        has_anim = df_parts.assign(_anim=df_parts["RÃ´le"].isin(["Animateur","InvitÃ©"])).groupby("ID")["_anim"].any()

    pay_reg_count = pd.Series(dtype=int)
    if not df_pay.empty:
        pay = df_pay.copy()
        pay["Montant"] = pd.to_numeric(pay["Montant"], errors="coerce").fillna(0.0)
        total_pay = pay.groupby("ID")["Montant"].sum()
        pay_regle = pay[pay["Statut"]=="RÃ©glÃ©"].groupby("ID")["Montant"].sum()
        pay_impaye = pay[pay["Statut"]!="RÃ©glÃ©"].groupby("ID")["Montant"].sum()
        pay_reg_count = pay[pay["Statut"]=="RÃ©glÃ©"].groupby("ID")["Montant"].count()
        has_partiel = pay[pay["Statut"]=="Partiel"].groupby("ID")["Montant"].count()
    else:
        total_pay = pd.Series(dtype=float)
        pay_regle = pd.Series(dtype=float)
        pay_impaye = pd.Series(dtype=float)
        has_partiel = pd.Series(dtype=int)

    has_cert = pd.Series(dtype=bool)
    if not df_cert.empty:
        has_cert = df_cert[df_cert["RÃ©sultat"]=="RÃ©ussi"].groupby("ID")["ID_Certif"].count() > 0

    ag = pd.DataFrame(index=df_contacts["ID"])
    ag["Interactions"] = ag.index.map(inter_count).fillna(0).astype(int)
    ag["Interactions_recent"] = ag.index.map(recent_inter).fillna(0).astype(int)
    # remonte la date la plus rÃ©cente de contact, gÃ¨re les valeurs manquantes
    ag["Dernier_contact"] = ag.index.map(last_contact)  # sÃ©rie de Timestamps ou NaT
    ag["Dernier_contact"] = pd.to_datetime(ag["Dernier_contact"], errors="coerce")  # convertit en datetime
    ag["Dernier_contact"] = ag["Dernier_contact"].dt.date  # extrait la date, les NaT deviennent None
    ag["Resp_principal"] = ag.index.map(resp_max).fillna("")
    ag["Participations"] = ag.index.map(parts_count).fillna(0).astype(int)
    ag["A_animÃ©_ou_invitÃ©"] = ag.index.map(has_anim).fillna(False)
    ag["CA_total"] = ag.index.map(total_pay).fillna(0.0)
    ag["CA_rÃ©glÃ©"] = ag.index.map(pay_regle).fillna(0.0)
    ag["ImpayÃ©"] = ag.index.map(pay_impaye).fillna(0.0)
    ag["Paiements_regles_n"] = ag.index.map(pay_reg_count).fillna(0).astype(int)
    ag["A_certification"] = ag.index.map(has_cert).fillna(False)

    ag["Score_composite"] = (w_int * ag["Interactions"] + w_part * ag["Participations"] + w_pay * ag["Paiements_regles_n"]).round(2)

    def make_tags(row):
        tags=[]
        if row.name in set(df_contacts.loc[(df_contacts["Type"]=="Prospect") & (df_contacts["Top20"]==True), "ID"]):
            tags.append("Prospect Top-20")
        if row["Participations"] >= 3 and row.name in set(df_contacts[df_contacts["Type"]=="Prospect"]["ID"]) and row["CA_rÃ©glÃ©"] <= 0:
            tags.append("RÃ©gulier-non-converti")
        if row["A_animÃ©_ou_invitÃ©"] or row["Participations"] >= 4:
            tags.append("Futur formateur")
        if row["A_certification"]:
            tags.append("Ambassadeur (certifiÃ©)")
        if row["CA_rÃ©glÃ©"] >= vip_thr:
            tags.append("VIP (CA Ã©levÃ©)")
        return ", ".join(tags)

    ag["Tags"] = ag.apply(make_tags, axis=1)

    def proba(row):
        if row.name in set(df_contacts[df_contacts["Type"]=="Membre"]["ID"]):
            return "Converti"
        chaud = (row["Interactions_recent"] >= hot_int_min and row["Participations"] >= hot_part_min)
        if hot_partiel and row["ImpayÃ©"] > 0 and row["CA_rÃ©glÃ©"] == 0:
            chaud = True
        tiede = (row["Interactions_recent"] >= 1 or row["Participations"] >= 1)
        if chaud:
            return "Chaud"
        if tiede:
            return "TiÃ¨de"
        return "Froid"

    ag["Proba_conversion"] = ag.apply(proba, axis=1)

    return ag.reset_index(names="ID")

# ------------------ Navigation & pages ----------------------

st.sidebar.title("Navigation")
page = st.sidebar.radio("Aller Ã ", ["CRM (Grille centrale)","Ã‰vÃ©nements","Rapports","Admin"], index=0)
this_year = datetime.now().year
annee = st.sidebar.selectbox("AnnÃ©e", ["Toutes"]+[str(this_year-1),str(this_year),str(this_year+1)], index=1)
mois = st.sidebar.selectbox("Mois", ["Tous"]+[f"{m:02d}" for m in range(1,13)], index=0)

# CRM Grille centrale
if page == "CRM (Grille centrale)":
    st.title("ğŸ‘¥ CRM â€” Grille centrale (Contacts)")
    colf1, colf2, colf3, colf4 = st.columns([2,1,1,1])
    q = colf1.text_input("Recherche (nom, sociÃ©tÃ©, email)â€¦","")
    page_size = colf2.selectbox("Taille de page", [20,50,100,200], index=0)
    type_filtre = colf3.selectbox("Type", ["Tous"] + SET["types_contact"])
    top20_only = colf4.checkbox("Top-20 uniquement", value=False)

    dfc = df_contacts.copy()
    ag = aggregates_for_contacts()
    dfc = dfc.merge(ag, on="ID", how="left")

    if q:
        qs = q.lower()
        dfc = dfc[dfc.apply(lambda r: qs in str(r["Nom"]).lower() or qs in str(r["PrÃ©nom"]).lower()
                          or qs in str(r["SociÃ©tÃ©"]).lower() or qs in str(r["Email"]).lower(), axis=1)]
    if type_filtre != "Tous":
        dfc = dfc[dfc["Type"] == type_filtre]
    if top20_only:
        dfc = dfc[dfc["Top20"] == True]

    def parse_cols(s, defaults):
        cols = [c.strip() for c in str(s).split(",") if c.strip()]
        valid = [c for c in cols if c in dfc.columns]
        return valid if valid else defaults

    table_cols = parse_cols(PARAMS.get("grid_crm_columns", ""), [
        "ID","Nom","PrÃ©nom","SociÃ©tÃ©","Type","Statut","Email",
        "Interactions","Participations","CA_rÃ©glÃ©","ImpayÃ©","Resp_principal","A_animÃ©_ou_invitÃ©",
        "Score_composite","Proba_conversion","Tags"
    ])

    def _label_contact(row):
        return f"{row['ID']} â€” {row['PrÃ©nom']} {row['Nom']} â€” {row['SociÃ©tÃ©']}"
    options = [] if dfc.empty else dfc.apply(_label_contact, axis=1).tolist()
    id_map = {} if dfc.empty else dict(zip(options, dfc["ID"]))

    colsel, _ = st.columns([3,1])
    sel_label = colsel.selectbox("Contact sÃ©lectionnÃ© (sÃ©lecteur maÃ®tre)", [""] + options, index=0, key="select_contact_label")
    if sel_label:
        st.session_state["selected_contact_id"] = id_map[sel_label]

    # Affichage grille avec AgGrid (si installÃ©)
    if HAS_AGGRID and not dfc.empty:
        dfc_show = dfc[table_cols].copy()
        proba_style = JsCode("""
            function(params) {
              const v = params.value;
              let color = null;
              if (v === 'Chaud') color = '#10B981';
              else if (v === 'TiÃ¨de') color = '#F59E0B';
              else if (v === 'Froid') color = '#EF4444';
              else if (v === 'Converti') color = '#6366F1';
              if (color){
                return { color: 'white', 'font-weight':'600', 'text-align':'center', 'border-radius':'12px', 'background-color': color };
              }
              return {};
            }
        """)
        gob = GridOptionsBuilder.from_dataframe(dfc_show)
        gob.configure_default_column(filter=True, sortable=True, resizable=True)
        gob.configure_selection("single", use_checkbox=True)
        gob.configure_pagination(paginationAutoPageSize=False, paginationPageSize=page_size)
        gob.configure_side_bar()
        if "Proba_conversion" in dfc_show.columns:
            gob.configure_column("Proba_conversion", cellStyle=proba_style)
        grid = AgGrid(
            dfc_show, gridOptions=gob.build(), height=520,
            update_mode=GridUpdateMode.SELECTION_CHANGED,
            data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
            key="crm_grid", allow_unsafe_jscode=True
        )
        if grid and grid.get("selected_rows"):
            new_sel = grid["selected_rows"][0].get("ID")
            if new_sel:
                st.session_state["selected_contact_id"] = new_sel
    else:
        st.info("Installez `streamlit-aggrid` pour filtres & pagination avancÃ©s.")
        st.dataframe(dfc[table_cols], use_container_width=True)

    st.markdown("---")
    cL, cR = st.columns([1,2])

    with cL:
        st.subheader("Fiche Contact")
        sel_id = st.session_state.get("selected_contact_id", None)
        if sel_id:
            c = df_contacts[df_contacts["ID"] == sel_id]
            if not c.empty:
                d = c.iloc[0].to_dict()
                with st.form("edit_contact"):
                    st.text_input("ID", value=d["ID"], disabled=True)
                    n1, n2 = st.columns(2)
                    nom = n1.text_input("Nom", d.get("Nom",""))
                    prenom = n2.text_input("PrÃ©nom", d.get("PrÃ©nom",""))
                    g1,g2 = st.columns(2)
                    genre = g1.selectbox("Genre", SET["genres"], index=SET["genres"].index(d.get("Genre","Homme")) if d.get("Genre","Homme") in SET["genres"] else 0)
                    titre = g2.text_input("Titre / Position", d.get("Titre",""))
                    s1,s2 = st.columns(2)
                    societe = s1.text_input("SociÃ©tÃ©", d.get("SociÃ©tÃ©",""))
                    secteur = s2.selectbox("Secteur", SET["secteurs"], index=SET["secteurs"].index(d.get("Secteur","Autre")) if d.get("Secteur","Autre") in SET["secteurs"] else len(SET["secteurs"])-1)
                    e1,e2,e3 = st.columns(3)
                    email = e1.text_input("Email", d.get("Email",""))
                    tel = e2.text_input("TÃ©lÃ©phone", d.get("TÃ©lÃ©phone",""))
                    linkedin = e3.text_input("LinkedIn", d.get("LinkedIn",""))
                    l1,l2,l3 = st.columns(3)
                    ville = l1.selectbox("Ville", SET["villes"], index=SET["villes"].index(d.get("Ville","Autres")) if d.get("Ville","Autres") in SET["villes"] else len(SET["villes"])-1)
                    pays = l2.selectbox("Pays", SET["pays"], index=SET["pays"].index(d.get("Pays","Cameroun")) if d.get("Pays","Cameroun") in SET["pays"] else 0)
                    typec = l3.selectbox("Type", SET["types_contact"], index=SET["types_contact"].index(d.get("Type","Prospect")) if d.get("Type","Prospect") in SET["types_contact"] else 0)
                    s3,s4,s5 = st.columns(3)
                    source = s3.selectbox("Source", SET["sources"], index=SET["sources"].index(d.get("Source","LinkedIn")) if d.get("Source","LinkedIn") in SET["sources"] else 0)
                    statut = s4.selectbox("Statut", SET["statuts_engagement"], index=SET["statuts_engagement"].index(d.get("Statut","Actif")) if d.get("Statut","Actif") in SET["statuts_engagement"] else 0)
                    score = s5.number_input("Score IIBA", value=float(d.get("Score_Engagement") or 0), step=1.0)
                    dc = st.date_input("Date de crÃ©ation", value=parse_date(d.get("Date_Creation")) or date.today())
                    notes = st.text_area("Notes", d.get("Notes",""))
                    top20 = st.checkbox("Top-20 entreprise", value=bool(str(d.get("Top20")).lower() in ["true","1","yes"]))
                    ok = st.form_submit_button("ğŸ’¾ Enregistrer le contact")
                    if ok:
                        if not email_ok(email):
                            st.error("Email invalide.")
                            st.stop()
                        if not phone_ok(tel):
                            st.error("TÃ©lÃ©phone invalide.")
                            st.stop()
                        idx = df_contacts.index[df_contacts["ID"] == sel_id][0]
                        new_row = {"ID":sel_id,"Nom":nom,"PrÃ©nom":prenom,"Genre":genre,"Titre":titre,"SociÃ©tÃ©":societe,"Secteur":secteur,
                                   "Email":email,"TÃ©lÃ©phone":tel,"LinkedIn":linkedin,"Ville":ville,"Pays":pays,"Type":typec,"Source":source,
                                   "Statut":statut,"Score_Engagement":int(score),"Date_Creation":dc.isoformat(),"Notes":notes,"Top20":top20}
                        df_contacts.loc[idx] = new_row
                        save_df(df_contacts, PATHS["contacts"])
                        st.success("Contact mis Ã  jour.")
                st.markdown("---")
                with st.expander("â• Ajouter ce contact Ã  un **nouvel Ã©vÃ©nement**"):
                    with st.form("quick_evt"):
                        c1,c2 = st.columns(2)
                        nom_ev = c1.text_input("Nom de l'Ã©vÃ©nement")
                        type_ev = c2.selectbox("Type", SET["types_evenements"])
                        c3,c4 = st.columns(2)
                        date_ev = c3.date_input("Date", value=date.today())
                        lieu_ev = c4.selectbox("Lieu", SET["lieux"])
                        role = st.selectbox("RÃ´le du contact", ["Participant","Animateur","InvitÃ©"])
                        ok2 = st.form_submit_button("ğŸ’¾ CrÃ©er l'Ã©vÃ©nement **et** inscrire ce contact")
                        if ok2:
                            new_eid = generate_id("EVT", df_events, "ID_Ã‰vÃ©nement")
                            rowe = {"ID_Ã‰vÃ©nement":new_eid,"Nom_Ã‰vÃ©nement":nom_ev,"Type":type_ev,"Date":date_ev.isoformat(),
                                    "DurÃ©e_h":"2","Lieu":lieu_ev,"Formateur":"","Objectif":"","Periode":"",
                                    "Cout_Salle":0,"Cout_Formateur":0,"Cout_Logistique":0,"Cout_Pub":0,"Cout_Autres":0,"Cout_Total":0,"Notes":""}
                            globals()["df_events"] = pd.concat([df_events, pd.DataFrame([rowe])], ignore_index=True)
                            save_df(df_events, PATHS["events"])
                            new_pid = generate_id("PAR", df_parts, "ID_Participation")
                            rowp = {"ID_Participation":new_pid,"ID":sel_id,"ID_Ã‰vÃ©nement":new_eid,"RÃ´le":role,
                                    "Inscription":"","ArrivÃ©e":"","Temps_Present":"","Feedback":"","Note":"","Commentaire":""}
                            globals()["df_parts"] = pd.concat([df_parts, pd.DataFrame([rowp])], ignore_index=True)
                            save_df(df_parts, PATHS["parts"])
                            st.success(f"Ã‰vÃ©nement crÃ©Ã© ({new_eid}) et contact inscrit ({new_pid}).")
            else:
                st.warning("ID introuvable (rafraÃ®chissez la page).")
        else:
            st.info("SÃ©lectionnez un contact via la grille ou le sÃ©lecteur maÃ®tre.")
    with cR:
        st.subheader("Actions liÃ©es au contact sÃ©lectionnÃ©")
        sel_id = st.session_state.get("selected_contact_id")
        if not sel_id:
            st.info("SÃ©lectionnez un contact pour crÃ©er une interaction, participation, paiement ou certification.")
        else:
            tabs = st.tabs(["â• Interaction","â• Participation","â• Paiement","â• Certification","ğŸ“‘ Vue 360Â°"])
            with tabs[0]:
                with st.form("add_inter"):
                    c1,c2,c3 = st.columns(3)
                    dti = c1.date_input("Date", value=date.today())
                    canal = c2.selectbox("Canal", SET["canaux"])
                    resp = c3.selectbox("Responsable", ["Aymard","Alix","Autre"])
                    obj = st.text_input("Objet")
                    resu = st.selectbox("RÃ©sultat", SET["resultats_inter"])
                    resume = st.text_area("RÃ©sumÃ©")
                    add_rel = st.checkbox("Planifier une relance ?")
                    rel = st.date_input("Relance", value=date.today()) if add_rel else None
                    ok = st.form_submit_button("ğŸ’¾ Enregistrer l'interaction")
                    if ok:
                        nid = generate_id("INT", df_inter, "ID_Interaction")
                        row = {"ID_Interaction":nid,"ID":sel_id,"Date":dti.isoformat(),"Canal":canal,"Objet":obj,"RÃ©sumÃ©":resume,
                               "RÃ©sultat":resu,"Prochaine_Action":"","Relance":rel.isoformat() if rel else "","Responsable":resp}
                        globals()["df_inter"] = pd.concat([df_inter, pd.DataFrame([row])], ignore_index=True)
                        save_df(df_inter, PATHS["inter"])
                        st.success(f"Interaction enregistrÃ©e ({nid}).")
            with tabs[1]:
                with st.form("add_part"):
                    if df_events.empty:
                        st.warning("CrÃ©ez d'abord un Ã©vÃ©nement.")
                    else:
                        ide = st.selectbox("Ã‰vÃ©nement", df_events["ID_Ã‰vÃ©nement"].tolist())
                        role = st.selectbox("RÃ´le", ["Participant","Animateur","InvitÃ©"])
                        fb = st.selectbox("Feedback", ["TrÃ¨s satisfait","Satisfait","Moyen","Insatisfait"])
                        note = st.number_input("Note (1-5)", min_value=1, max_value=5, value=5)
                        ok = st.form_submit_button("ğŸ’¾ Enregistrer la participation")
                        if ok:
                            nid = generate_id("PAR", df_parts, "ID_Participation")
                            row = {"ID_Participation":nid,"ID":sel_id,"ID_Ã‰vÃ©nement":ide,"RÃ´le":role,"Inscription":"","ArrivÃ©e":"",
                                   "Temps_Present":"","Feedback":fb,"Note":str(note),"Commentaire":""}
                            globals()["df_parts"] = pd.concat([df_parts, pd.DataFrame([row])], ignore_index=True)
                            save_df(df_parts, PATHS["parts"])
                            st.success(f"Participation ajoutÃ©e ({nid}).")
            with tabs[2]:
                with st.form("add_pay"):
                    if df_events.empty:
                        st.warning("CrÃ©ez d'abord un Ã©vÃ©nement.")
                    else:
                        ide = st.selectbox("Ã‰vÃ©nement", df_events["ID_Ã‰vÃ©nement"].tolist())
                        dtp = st.date_input("Date paiement", value=date.today())
                        montant = st.number_input("Montant (FCFA)", min_value=0, step=1000)
                        moyen = st.selectbox("Moyen", SET["moyens_paiement"])
                        statut = st.selectbox("Statut", SET["statuts_paiement"])
                        ref = st.text_input("RÃ©fÃ©rence")
                        ok = st.form_submit_button("ğŸ’¾ Enregistrer le paiement")
                        if ok:
                            nid = generate_id("PAY", df_pay, "ID_Paiement")
                            row = {"ID_Paiement":nid,"ID":sel_id,"ID_Ã‰vÃ©nement":ide,"Date_Paiement":dtp.isoformat(),"Montant":str(montant),
                                   "Moyen":moyen,"Statut":statut,"RÃ©fÃ©rence":ref,"Notes":"","Relance":""}
                            globals()["df_pay"] = pd.concat([df_pay, pd.DataFrame([row])], ignore_index=True)
                            save_df(df_pay, PATHS["pay"])
                            st.success(f"Paiement enregistrÃ© ({nid}).")
            with tabs[3]:
                with st.form("add_cert"):
                    tc = st.selectbox("Type Certification", SET["types_certif"])
                    dte = st.date_input("Date Examen", value=date.today())
                    res = st.selectbox("RÃ©sultat", ["RÃ©ussi","Ã‰chouÃ©","En cours","ReportÃ©"])
                    sc = st.number_input("Score", min_value=0, max_value=100, value=0)
                    has_dto = st.checkbox("Renseigner une date d'obtention ?")
                    dto = st.date_input("Date Obtention", value=date.today()) if has_dto else None
                    ok = st.form_submit_button("ğŸ’¾ Enregistrer la certification")
                    if ok:
                        nid = generate_id("CER", df_cert, "ID_Certif")
                        row = {"ID_Certif":nid,"ID":sel_id,"Type_Certif":tc,"Date_Examen":dte.isoformat(),"RÃ©sultat":res,"Score":str(sc),
                               "Date_Obtention":dto.isoformat() if dto else "","ValiditÃ©":"","Renouvellement":"","Notes":""}
                        globals()["df_cert"] = pd.concat([df_cert, pd.DataFrame([row])], ignore_index=True)
                        save_df(df_cert, PATHS["cert"])
                        st.success(f"Certification ajoutÃ©e ({nid}).")
            with tabs[4]:
                st.markdown("#### Vue 360Â°")
                if not df_inter.empty:
                    st.write("**Interactions**")
                    st.dataframe(df_inter[df_inter["ID"]==sel_id][["Date","Canal","Objet","RÃ©sultat","Relance","Responsable"]], use_container_width=True)
                if not df_parts.empty:
                    st.write("**Participations**")
                    dfp = df_parts[df_parts["ID"]==sel_id].copy()
                    if not df_events.empty:
                        ev_names = df_events.set_index("ID_Ã‰vÃ©nement")["Nom_Ã‰vÃ©nement"]
                        dfp["Ã‰vÃ©nement"] = dfp["ID_Ã‰vÃ©nement"].map(ev_names)
                    st.dataframe(dfp[["Ã‰vÃ©nement","RÃ´le","Feedback","Note"]], use_container_width=True)
                if not df_pay.empty:
                    st.write("**Paiements**")
                    st.dataframe(df_pay[df_pay["ID"]==sel_id][["ID_Ã‰vÃ©nement","Date_Paiement","Montant","Moyen","Statut","RÃ©fÃ©rence"]], use_container_width=True)
                if not df_cert.empty:
                    st.write("**Certifications**")
                    st.dataframe(df_cert[df_cert["ID"]==sel_id][["Type_Certif","Date_Examen","RÃ©sultat","Score","Date_Obtention"]], use_container_width=True)

# --- Pages Ã‰vÃ©nements, Rapports, Admin ---
# Tu peux me demander la suite ou complÃ©ter en fonction si tu veux.

# --------------------------------------------
# Suite app.py - pages Ã‰vÃ©nements, Rapports, Admin
# --------------------------------------------

# ---------------------- PAGE Ã‰VÃ‰NEMENTS ----------------------

if page == "Ã‰vÃ©nements":
    st.title("ğŸ“… Ã‰vÃ©nements")
    
    with st.expander("â• CrÃ©er un nouvel Ã©vÃ©nement", expanded=False):
        with st.form("new_event"):
            c1, c2, c3 = st.columns(3)
            nom = c1.text_input("Nom de l'Ã©vÃ©nement")
            typ = c2.selectbox("Type", SET["types_evenements"])
            dat = c3.date_input("Date", value=date.today())

            c4, c5, c6 = st.columns(3)
            lieu = c4.selectbox("Lieu", SET["lieux"])
            duree = c5.number_input("DurÃ©e (h)", min_value=0.0, step=0.5, value=2.0)
            formateur = c6.text_input("Formateur(s)")

            obj = st.text_area("Objectif")

            couts = st.columns(5)
            c_salle = couts[0].number_input("CoÃ»t salle", min_value=0.0, step=1000.0)
            c_form = couts[1].number_input("CoÃ»t formateur", min_value=0.0, step=1000.0)
            c_log = couts[2].number_input("CoÃ»t logistique", min_value=0.0, step=1000.0)
            c_pub = couts[3].number_input("CoÃ»t pub", min_value=0.0, step=1000.0)
            c_aut = couts[4].number_input("Autres coÃ»ts", min_value=0.0, step=1000.0)

            notes = st.text_area("Notes")
            ok = st.form_submit_button("ğŸ’¾ CrÃ©er l'Ã©vÃ©nement")

            if ok:
                new_id = generate_id("EVT", df_events, "ID_Ã‰vÃ©nement")
                row = {
                    "ID_Ã‰vÃ©nement": new_id, "Nom_Ã‰vÃ©nement": nom, "Type": typ, "Date": dat.isoformat(),
                    "DurÃ©e_h": str(duree), "Lieu": lieu, "Formateur": formateur, "Objectif": obj, "Periode": "",
                    "Cout_Salle": c_salle, "Cout_Formateur": c_form, "Cout_Logistique": c_log, "Cout_Pub": c_pub,
                    "Cout_Autres": c_aut, "Cout_Total": 0, "Notes": notes
                }
                globals()["df_events"] = pd.concat([df_events, pd.DataFrame([row])], ignore_index=True)
                save_df(df_events, PATHS["events"])
                st.success(f"Ã‰vÃ©nement crÃ©Ã© ({new_id}).")

    # Ã‰dition, Duplication, Suppression avec filtre
    filt = st.text_input("Filtre rapide (nom, type, lieu, notesâ€¦)", "")
    page_size_evt = st.selectbox("Taille de page", [20,50,100,200], index=0, key="pg_evt")
    df_show = df_events.copy()
    
    if filt:
        t = filt.lower()
        df_show = df_show[df_show.apply(lambda r: any(t in str(r[c]).lower() for c in ["Nom_Ã‰vÃ©nement","Type","Lieu","Notes"]), axis=1)]

    if HAS_AGGRID:
        gb = GridOptionsBuilder.from_dataframe(df_show)
        gb.configure_default_column(filter=True, sortable=True, resizable=True, editable=True)
        gb.configure_pagination(paginationAutoPageSize=False, paginationPageSize=page_size_evt)
        gb.configure_selection("single", use_checkbox=True)
        go = gb.build()
        grid = AgGrid(df_show, gridOptions=go, height=520, update_mode=GridUpdateMode.MODEL_CHANGED,
                      data_return_mode=DataReturnMode.FILTERED_AND_SORTED, key="evt_grid", allow_unsafe_jscode=True)

        col1, col2, col3 = st.columns(3)
        if col1.button("ğŸ’¾ Appliquer les modifications"):
            new_df = pd.DataFrame(grid["data"])
            for c in E_COLS:
                if c not in new_df.columns:
                    new_df[c] = ""
            globals()["df_events"] = new_df[E_COLS].copy()
            save_df(df_events, PATHS["events"])
            st.success("Modifications enregistrÃ©es.")
        if col2.button("ğŸ—‘ï¸ Supprimer l'Ã©vÃ©nement sÃ©lectionnÃ©"):
            if grid.get("selected_rows"):
                del_id = grid["selected_rows"][0].get("ID_Ã‰vÃ©nement")
                globals()["df_events"] = df_events[df_events["ID_Ã‰vÃ©nement"] != del_id]
                save_df(df_events, PATHS["events"])
                st.success(f"Ã‰vÃ©nement supprimÃ© ({del_id}).")
            else:
                st.warning("SÃ©lectionnez une ligne dans la grille pour supprimer.")
        if col3.button("ğŸ§¬ Dupliquer l'Ã©vÃ©nement sÃ©lectionnÃ©"):
            if grid.get("selected_rows"):
                src = grid["selected_rows"][0]
                new_id = generate_id("EVT", df_events, "ID_Ã‰vÃ©nement")
                clone = {k: src.get(k, "") for k in E_COLS}
                clone["ID_Ã‰vÃ©nement"] = new_id
                globals()["df_events"] = pd.concat([df_events, pd.DataFrame([clone])], ignore_index=True)
                save_df(df_events, PATHS["events"])
                st.success(f"Ã‰vÃ©nement dupliquÃ© sous l'ID {new_id}.")
            else:
                st.warning("SÃ©lectionnez une ligne dans la grille pour dupliquer.")
    else:
        st.dataframe(df_show, use_container_width=True)
        st.info("Installez `streamlit-aggrid` pour Ã©diter/dupliquer directement dans la grille.")


# ---------------------- PAGE RAPPORTS ----------------------

elif page == "Rapports":
    st.title("ğŸ“‘ Rapports & KPI â€” IIBA Cameroun")

    def filtered_tables_for_period(year_sel: str, month_sel: str):
        def in_period(d: pd.Series) -> pd.Series:
            p = d.map(lambda x: parse_date(x) if pd.notna(x) else None)
            m = p.notna()
            if year_sel != "Toutes":
                y = int(year_sel)
                m = m & p.map(lambda x: x and x.year == y)
            if month_sel != "Tous":
                mm = int(month_sel)
                m = m & p.map(lambda x: x and x.month == mm)
            return m.fillna(False)

        dfe2 = df_events[in_period(df_events["Date"])].copy() if not df_events.empty else df_events.copy()
        dfp2 = df_parts.copy()
        if not df_events.empty and not df_parts.empty:
            evd = df_events.set_index("ID_Ã‰vÃ©nement")["Date"].map(parse_date)
            dfp2["_d"] = dfp2["ID_Ã‰vÃ©nement"].map(evd)
            if year_sel != "Toutes":
                dfp2 = dfp2[dfp2["_d"].map(lambda x: x and x.year == int(year_sel))]
            if month_sel != "Tous":
                dfp2 = dfp2[dfp2["_d"].map(lambda x: x and x.month == int(month_sel))]
        dfpay2 = df_pay[in_period(df_pay["Date_Paiement"])].copy() if not df_pay.empty else df_pay.copy()
        dfcert2 = df_cert[in_period(df_cert["Date_Obtention"]) | in_period(df_cert["Date_Examen"])].copy() if not df_cert.empty else df_cert.copy()
        return dfe2, dfp2, dfpay2, dfcert2

    def event_financials(dfe2: pd.DataFrame, dfpay2: pd.DataFrame) -> pd.DataFrame:
        rec_by_evt = pd.Series(dtype=float)
        if not dfpay2.empty:
            r = dfpay2[dfpay2["Statut"] == "RÃ©glÃ©"].copy()
            r["Montant"] = pd.to_numeric(r["Montant"], errors="coerce").fillna(0.0)
            rec_by_evt = r.groupby("ID_Ã‰vÃ©nement")["Montant"].sum()

        ev = df_events.copy() if dfe2.empty else dfe2.copy()
        for c in ["Cout_Salle", "Cout_Formateur", "Cout_Logistique", "Cout_Pub", "Cout_Autres", "Cout_Total"]:
            ev[c] = pd.to_numeric(ev[c], errors="coerce").fillna(0.0)
        ev["Cout_Total"] = np.where(
            ev["Cout_Total"] > 0,
            ev["Cout_Total"],
            ev[["Cout_Salle", "Cout_Formateur", "Cout_Logistique", "Cout_Pub", "Cout_Autres"]].sum(axis=1)
        )
        ev = ev.set_index("ID_Ã‰vÃ©nement")
        rep = pd.DataFrame({
            "Nom_Ã‰vÃ©nement": ev["Nom_Ã‰vÃ©nement"],
            "Type": ev["Type"],
            "Date": ev["Date"],
            "CoÃ»t_Total": ev["Cout_Total"]
        })
        rep["Recette"] = rec_by_evt.fillna(0.0)
        rep["BÃ©nÃ©fice"] = rep["Recette"] - rep["CoÃ»t_Total"]
        return rep.reset_index()

    dfe2, dfp2, dfpay2, dfcert2 = filtered_tables_for_period(annee, mois)
    dfc2 = df_contacts.copy()

    total_contacts = len(dfc2)
    prospects_actifs = len(dfc2[(dfc2["Type"] == "Prospect") & (dfc2["Statut"] == "Actif")])
    membres = len(dfc2[dfc2["Type"] == "Membre"])
    events_count = len(dfe2) if not dfe2.empty else 0
    parts_total = len(dfp2) if not dfp2.empty else 0

    ca_regle = impayes = 0.0
    if not dfpay2.empty:
        dfpay2["Montant"] = pd.to_numeric(dfpay2["Montant"], errors="coerce").fillna(0.0)
        ca_regle = float(dfpay2[dfpay2["Statut"] == "RÃ©glÃ©"]["Montant"].sum())
        impayes = float(dfpay2[dfpay2["Statut"] != "RÃ©glÃ©"]["Montant"].sum())

    prospects_total = len(dfc2[dfc2["Type"] == "Prospect"])
    prospects_convertis = len(dfc2[dfc2["Type"] == "Membre"])
    taux_conv = (prospects_convertis / prospects_total * 100) if prospects_total else 0.0

    kpis = {
        "contacts_total": ("ğŸ‘¥ Contacts", total_contacts),
        "prospects_actifs": ("ğŸ§² Prospects actifs", prospects_actifs),
        "membres": ("ğŸ† Membres", membres),
        "events_count": ("ğŸ“… Ã‰vÃ©nements", events_count),
        "participations_total": ("ğŸŸï¸ Participations", parts_total),
        "ca_regle": ("ğŸ’° CA rÃ©glÃ©", f"{int(ca_regle):,} FCFA".replace(",", " ")),
        "impayes": ("â›” ImpayÃ©s", f"{int(impayes):,} FCFA".replace(",", " ")),
        "taux_conversion": ("ğŸ” Taux de conversion", f"{taux_conv:.1f}%"),
    }
    enabled = [
        x.strip() for x in str(PARAMS.get("kpi_enabled", "")).split(",")
        if x.strip() and x.strip() in kpis
    ]
    cols = st.columns(max(1, len(enabled)))
    for i, k in enumerate(enabled):
        cols[i].metric(kpis[k][0], kpis[k][1])

    ev_fin = event_financials(dfe2, dfpay2)
    if alt and not ev_fin.empty:
        st.subheader("ğŸ’¹ CA vs CoÃ»t par Ã©vÃ©nement (et BÃ©nÃ©fice)")
        ev_fin_melt = ev_fin.melt(
            id_vars=["ID_Ã‰vÃ©nement", "Nom_Ã‰vÃ©nement"],
            value_vars=["Recette", "CoÃ»t_Total", "BÃ©nÃ©fice"],
            var_name="Metric", value_name="Montant"
        )
        chart = alt.Chart(ev_fin_melt).mark_bar().encode(
            x=alt.X("Nom_Ã‰vÃ©nement:N", sort="-y"),
            y=alt.Y("Montant:Q"),
            color="Metric:N",
            tooltip=["Nom_Ã‰vÃ©nement", "Metric", "Montant"]
        ).properties(height=320).interactive()
        st.altair_chart(chart, use_container_width=True)

    if not dfp2.empty:
        st.subheader("ğŸ‘¥ Participants par mois")
        dfp2["_d"] = dfp2.get("_d")
        if "_d" not in dfp2 or dfp2["_d"].isna().all():
            evd = df_events.set_index("ID_Ã‰vÃ©nement")["Date"].map(parse_date)
            dfp2["_d"] = dfp2["ID_Ã‰vÃ©nement"].map(evd)
        dfp2["_mois"] = pd.to_datetime(dfp2["_d"]).dt.to_period("M").astype(str)
        agg = dfp2.groupby("_mois")["ID_Participation"].count().reset_index(name="Participants")
        if alt:
            line = alt.Chart(agg).mark_line(point=True).encode(
                x="__mois:N", y="Participants:Q"
            ).transform_calculate(__mois="datum._mois")
            st.altair_chart(line.properties(height=280), use_container_width=True)
        else:
            st.dataframe(agg)

    if not df_parts.empty and not df_events.empty:
        st.subheader("ğŸ˜Š Satisfaction moyenne par type d'Ã©vÃ©nement")
        dfp = df_parts.copy()
        dfp["Note"] = pd.to_numeric(dfp["Note"], errors="coerce")
        types = df_events.set_index("ID_Ã‰vÃ©nement")["Type"]
        dfp["Type"] = dfp["ID_Ã‰vÃ©nement"].map(types)
        ag = dfp.groupby("Type")["Note"].mean().reset_index()
        if alt:
            bar = alt.Chart(ag).mark_bar().encode(
                x="Type:N", y="Note:Q", tooltip=["Type", "Note"]
            )
            st.altair_chart(bar.properties(height=280), use_container_width=True)
        else:
            st.dataframe(ag)

    st.markdown("---")
    st.subheader("ğŸ¯ Objectifs vs RÃ©el")

    def get_target(key):
        try:
            return float(PARAMS.get(key, "0") or 0)
        except:
            return 0

    y = datetime.now().year
    goals = [
        ("contacts_total", total_contacts),
        ("ca_regle", ca_regle),
        ("participations_total", parts_total),
    ]
    rows = []
    for k, val in goals:
        tgt = get_target(f"kpi_target_{k}_year_{y}")
        delta = val - tgt
        rows.append({"KPI": k, "Objectif": tgt, "RÃ©el": val, "Ã‰cart": delta})
    if rows:
        st.dataframe(pd.DataFrame(rows), use_container_width=True)

    # Export rapport Excel complet
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df_contacts.to_excel(writer, index=False, sheet_name="contacts")
        df_inter.to_excel(writer, index=False, sheet_name="interactions")
        df_events.to_excel(writer, index=False, sheet_name="evenements")
        df_parts.to_excel(writer, index=False, sheet_name="participations")
        df_pay.to_excel(writer, index=False, sheet_name="paiements")
        df_cert.to_excel(writer, index=False, sheet_name="certifications")
        ev_fin.to_excel(writer, index=False, sheet_name="finance_events")
    st.download_button(
        "â¬‡ï¸ Exporter le rapport (Excel)",
        buf.getvalue(),
        file_name="IIBA_rapport.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    
    st.markdown("---")
    st.header("ğŸ“Š Rapports AvancÃ©s & Analyse StratÃ©gique")
    
    # Onglets pour les diffÃ©rents rapports
    tab_exec, tab_profil, tab_swot, tab_bsc = st.tabs([
        "ğŸ¯ Executive Summary", 
        "ğŸ‘¤ Profil BA Camerounais", 
        "âš–ï¸ SWOT Analysis", 
        "ğŸ“ˆ Balanced Scorecard"
    ])
    
    # PrÃ©paration des donnÃ©es enrichies
    dfc_enriched = df_contacts.merge(aggregates_for_contacts(), on="ID", how="left")
    
    with tab_exec:
        st.subheader("ğŸ“‹ SynthÃ¨se ExÃ©cutive - IIBA Cameroun")
        
        # KPIs clÃ©s inspirÃ©s du rapport IIBA Global
        col1, col2, col3, col4 = st.columns(4)
        
        # Calculs des KPIs enrichis
        total_ba = len(dfc_enriched)
        certifies = len(dfc_enriched[dfc_enriched["A_certification"] == True])
        taux_certif = (certifies / total_ba * 100) if total_ba > 0 else 0
        
        # RÃ©partition par secteur (Top 4)
        secteur_counts = dfc_enriched["Secteur"].value_counts()
        top_secteurs = secteur_counts.head(4)
        
        # Calcul du salaire moyen (estimation basÃ©e sur le secteur et certification)
        def estimate_salary(row):
            base_salary = {
                "Banque": 800000, "TÃ©lÃ©com": 750000, "IT": 700000,
                "Ã‰ducation": 500000, "SantÃ©": 600000, "ONG": 450000,
                "Industrie": 650000, "Public": 550000, "Autre": 500000
            }
            multiplier = 1.3 if row["A_certification"] else 1.0
            return base_salary.get(row["Secteur"], 500000) * multiplier
        
        dfc_enriched["Salaire_Estime"] = dfc_enriched.apply(estimate_salary, axis=1)
        salaire_moyen = int(dfc_enriched["Salaire_Estime"].mean())
        
        # Affichage des mÃ©triques
        col1.metric("ğŸ‘¥ Total BA", total_ba, help="Nombre total de Business Analysts")
        col2.metric("ğŸ“ CertifiÃ©s", f"{taux_certif:.1f}%", help="Pourcentage de BA certifiÃ©s")
        col3.metric("ğŸ’° Salaire Moyen", f"{salaire_moyen:,} FCFA", help="Salaire moyen estimÃ©")
        col4.metric("ğŸ¢ Secteurs", len(secteur_counts), help="Nombre de secteurs reprÃ©sentÃ©s")
        
        # Top Ã©vÃ©nements par bÃ©nÃ©fice
        st.subheader("ğŸ† Top Ã‰vÃ©nements par Performance")
        if not ev_fin.empty:
            top_events = ev_fin.nlargest(5, "BÃ©nÃ©fice")[["Nom_Ã‰vÃ©nement", "Recette", "CoÃ»t_Total", "BÃ©nÃ©fice"]]
            st.dataframe(top_events, use_container_width=True)
        
        # Segmentation des contacts
        st.subheader("ğŸ¯ Segmentation des Contacts")
        segments = dfc_enriched["Proba_conversion"].value_counts()
        col_seg1, col_seg2 = st.columns(2)
        with col_seg1:
            st.write("**RÃ©partition par potentiel:**")
            for segment, count in segments.items():
                pct = (count / total_ba * 100) if total_ba > 0 else 0
                st.write(f"â€¢ {segment}: {count} ({pct:.1f}%)")
        
        with col_seg2:
            # Graphique de rÃ©partition
            if alt and not segments.empty:
                chart_data = pd.DataFrame({
                    'Segment': segments.index,
                    'Count': segments.values
                })
                pie_chart = alt.Chart(chart_data).mark_arc().encode(
                    theta=alt.Theta(field="Count", type="quantitative"),
                    color=alt.Color(field="Segment", type="nominal"),
                    tooltip=['Segment', 'Count']
                ).properties(width=200, height=200)
                st.altair_chart(pie_chart, use_container_width=True)
    
    with tab_profil:
        st.subheader("ğŸ‘¤ Profil Type du BA Camerounais")
        
        # DonnÃ©es dÃ©mographiques
        col_demo1, col_demo2 = st.columns(2)
        
        with col_demo1:
            st.write("**ğŸ“Š RÃ©partition par Genre**")
            genre_counts = dfc_enriched["Genre"].value_counts()
            for genre, count in genre_counts.items():
                pct = (count / total_ba * 100) if total_ba > 0 else 0
                st.write(f"â€¢ {genre}: {count} ({pct:.1f}%)")
            
            st.write("**ğŸ™ï¸ RÃ©partition GÃ©ographique**")
            ville_counts = dfc_enriched["Ville"].value_counts().head(5)
            for ville, count in ville_counts.items():
                pct = (count / total_ba * 100) if total_ba > 0 else 0
                st.write(f"â€¢ {ville}: {count} ({pct:.1f}%)")
        
        with col_demo2:
            st.write("**ğŸ¢ Secteurs Dominants**")
            for secteur, count in top_secteurs.items():
                pct = (count / total_ba * 100) if total_ba > 0 else 0
                st.write(f"â€¢ {secteur}: {count} ({pct:.1f}%)")
            
            st.write("**ğŸ’¼ Types de Profils**")
            type_counts = dfc_enriched["Type"].value_counts()
            for typ, count in type_counts.items():
                pct = (count / total_ba * 100) if total_ba > 0 else 0
                st.write(f"â€¢ {typ}: {count} ({pct:.1f}%)")
        
        # Analyse d'engagement par secteur
        st.subheader("ğŸ“ˆ Engagement par Secteur")
        if not dfc_enriched.empty:
            engagement_secteur = dfc_enriched.groupby("Secteur").agg({
                "Score_composite": "mean",
                "Participations": "mean",
                "CA_rÃ©glÃ©": "sum"
            }).round(2)
            engagement_secteur.columns = ["Score Moyen", "Participations Moy", "CA Total"]
            st.dataframe(engagement_secteur, use_container_width=True)
        
        # Profil type BA selon les standards internationaux
        st.subheader("ğŸŒ Comparaison Standards Internationaux")
        
        # Calculs basÃ©s sur les bonnes pratiques IIBA
        ba_experience_ratio = len(dfc_enriched[dfc_enriched["Score_Engagement"] >= 50]) / total_ba * 100 if total_ba > 0 else 0
        formation_continue = len(dfc_enriched[dfc_enriched["Participations"] >= 2]) / total_ba * 100 if total_ba > 0 else 0
        
        kpi_standards = pd.DataFrame({
            "KPI": [
                "Taux de certification",
                "Formation continue",
                "ExpÃ©rience mÃ©tier",
                "DiversitÃ© sectorielle",
                "Engagement communautaire"
            ],
            "Cameroun": [f"{taux_certif:.1f}%", f"{formation_continue:.1f}%", f"{ba_experience_ratio:.1f}%", 
                        f"{len(secteur_counts)} secteurs", f"{dfc_enriched['Participations'].mean():.1f} events/BA"],
            "Standard IIBA": ["25-35%", "60-70%", "70-80%", "8-10 secteurs", "2-3 events/an"]
        })
        st.dataframe(kpi_standards, use_container_width=True)
    
    with tab_swot:
        st.subheader("âš–ï¸ Analyse SWOT - IIBA Cameroun")
        
        # Calculs pour alimenter le SWOT
        diversite_sectorielle = len(secteur_counts)
        taux_participation = dfc_enriched["Participations"].mean()
        ca_total = dfc_enriched["CA_rÃ©glÃ©"].sum()
        prospects_chauds = len(dfc_enriched[dfc_enriched["Proba_conversion"] == "Chaud"])
        
        col_sw, col_ot = st.columns(2)
        
        with col_sw:
            st.markdown("### ğŸ’ª **FORCES**")
            st.write(f"""
            â€¢ **DiversitÃ© sectorielle**: {diversite_sectorielle} secteurs reprÃ©sentÃ©s
            â€¢ **Engagement communautaire**: {taux_participation:.1f} participations moyenne/BA
            â€¢ **Base financiÃ¨re**: {ca_total:,.0f} FCFA de revenus
            â€¢ **Pipeline prospects**: {prospects_chauds} prospects chauds
            â€¢ **Croissance digitale**: Adoption outils en ligne
            """)
            
            st.markdown("### âš ï¸ **FAIBLESSES**")
            st.write(f"""
            â€¢ **Taux de certification**: {taux_certif:.1f}% (vs 30% standard)
            â€¢ **Concentration gÃ©ographique**: Focus Douala/YaoundÃ©
            â€¢ **Formations avancÃ©es limitÃ©es**
            â€¢ **Standardisation pratiques Ã  renforcer**
            â€¢ **VisibilitÃ© internationale faible**
            """)
        
        with col_ot:
            st.markdown("### ğŸš€ **OPPORTUNITÃ‰S**")
            st.write("""
            â€¢ **Transformation digitale**: Demande croissante BA
            â€¢ **Partenariats entreprises**: Top-20 identifiÃ©es  
            â€¢ **Certification IIBA**: Programme de dÃ©veloppement
            â€¢ **Expansion rÃ©gionale**: Afrique Centrale
            â€¢ **Formations spÃ©cialisÃ©es**: IA, Data, Agile
            """)
            
            st.markdown("### â›” **MENACES**")
            st.write("""
            â€¢ **Concurrence consultants internationaux**
            â€¢ **Fuite des cerveaux vers l'Ã©tranger**
            â€¢ **Ã‰conomie incertaine**: Impact budgets formation
            â€¢ **Manque reconnaissance mÃ©tier BA**
            â€¢ **Technologie Ã©voluant rapidement**
            """)
        
        # Actions recommandÃ©es
        st.subheader("ğŸ¯ Plan d'Actions StratÃ©giques")
        actions_df = pd.DataFrame({
            "Axe": ["Formation", "Certification", "Partenariats", "Expansion", "Communication"],
            "Action": [
                "DÃ©velopper programme formation continue",
                "Accompagner vers certifications IIBA",
                "Formaliser accords entreprises Top-20",
                "Ouvrir antennes rÃ©gionales",
                "Renforcer visibilitÃ© et marketing"
            ],
            "PrioritÃ©": ["Ã‰levÃ©e", "Ã‰levÃ©e", "Moyenne", "Faible", "Moyenne"],
            "Ã‰chÃ©ance": ["6 mois", "12 mois", "9 mois", "24 mois", "Continu"]
        })
        st.dataframe(actions_df, use_container_width=True)
    
    with tab_bsc:
        st.subheader("ğŸ“ˆ Balanced Scorecard - IIBA Cameroun")
        
        # 4 perspectives du BSC
        tab_fin, tab_client, tab_proc, tab_app = st.tabs([
            "ğŸ’° FinanciÃ¨re", "ğŸ‘¥ Client", "âš™ï¸ Processus", "ğŸ“š Apprentissage"
        ])
        
        with tab_fin:
            st.write("### ğŸ’° Perspective FinanciÃ¨re")
            col_f1, col_f2, col_f3 = st.columns(3)
            
            croissance_ca = 15  # Ã€ calculer sur historique
            marge_benefice = (ev_fin["BÃ©nÃ©fice"].sum() / ev_fin["Recette"].sum() * 100) if not ev_fin.empty and ev_fin["Recette"].sum() > 0 else 0
            
            col_f1.metric("ğŸ’µ CA Total", f"{ca_total:,.0f} FCFA")
            col_f2.metric("ğŸ“ˆ Croissance CA", f"{croissance_ca}%", help="Objectif: +20%/an")
            col_f3.metric("ğŸ“Š Marge BÃ©nÃ©fice", f"{marge_benefice:.1f}%", help="Objectif: 25%")
            
            # Tableau dÃ©taillÃ© financier
            fin_data = pd.DataFrame({
                "Indicateur": ["Revenus formations", "Revenus certifications", "Revenus Ã©vÃ©nements", "CoÃ»ts opÃ©rationnels"],
                "RÃ©el": [f"{ca_total*0.6:.0f}", f"{ca_total*0.2:.0f}", f"{ca_total*0.2:.0f}", f"{ev_fin['CoÃ»t_Total'].sum():.0f}"],
                "Objectif": ["3M", "1M", "1M", "3.5M"],
                "Ã‰cart": ["Ã€ calculer", "Ã€ calculer", "Ã€ calculer", "Ã€ calculer"]
            })
            st.dataframe(fin_data, use_container_width=True)
        
        with tab_client:
            st.write("### ğŸ‘¥ Perspective Client")
            col_c1, col_c2, col_c3 = st.columns(3)
            
            satisfaction_moy = dfc_enriched[dfc_enriched["A_certification"] == True]["Score_Engagement"].mean()
            retention = len(dfc_enriched[dfc_enriched["Type"] == "Membre"]) / len(dfc_enriched[dfc_enriched["Type"].isin(["Membre", "Prospect"])]) * 100
            
            col_c1.metric("ğŸ˜Š Satisfaction", f"{satisfaction_moy:.1f}/100", help="Score engagement certifiÃ©s")
            col_c2.metric("ğŸ”„ RÃ©tention", f"{retention:.1f}%", help="Taux prospect->membre")
            col_c3.metric("ğŸ“ˆ NPS EstimÃ©", "65", help="Net Promoter Score estimÃ©")
            
            # Segmentation client
            client_data = pd.DataFrame({
                "Segment": ["Prospects Chauds", "Prospects TiÃ¨des", "Prospects Froids", "Membres Actifs"],
                "Nombre": [
                    len(dfc_enriched[dfc_enriched["Proba_conversion"] == "Chaud"]),
                    len(dfc_enriched[dfc_enriched["Proba_conversion"] == "TiÃ¨de"]), 
                    len(dfc_enriched[dfc_enriched["Proba_conversion"] == "Froid"]),
                    len(dfc_enriched[dfc_enriched["Type"] == "Membre"])
                ],
                "% Total": [0, 0, 0, 0]  # Ã€ calculer
            })
            client_data["% Total"] = (client_data["Nombre"] / client_data["Nombre"].sum() * 100).round(1)
            st.dataframe(client_data, use_container_width=True)
        
        with tab_proc:
            st.write("### âš™ï¸ Perspective Processus Internes")
            col_p1, col_p2, col_p3 = st.columns(3)
            
            efficacite_conv = prospects_chauds / len(dfc_enriched[dfc_enriched["Type"] == "Prospect"]) * 100 if len(dfc_enriched[dfc_enriched["Type"] == "Prospect"]) > 0 else 0
            temps_reponse = 2.5  # Jours moyenne
            
            col_p1.metric("âš¡ EfficacitÃ© Conversion", f"{efficacite_conv:.1f}%")
            col_p2.metric("â±ï¸ Temps RÃ©ponse", f"{temps_reponse} jours")
            col_p3.metric("ğŸ¯ Taux Participation", f"{taux_participation:.1f}")
            
            # Processus clÃ©s
            proc_data = pd.DataFrame({
                "Processus": ["Acquisition prospects", "Conversion membres", "DÃ©livrance formations", "Suivi post-formation"],
                "Performance": ["75%", f"{retention:.1f}%", "90%", "60%"],
                "Objectif": ["80%", "25%", "95%", "75%"],
                "Actions": ["AmÃ©liorer ciblage", "Renforcer follow-up", "Optimiser contenu", "SystÃ©matiser enquÃªtes"]
            })
            st.dataframe(proc_data, use_container_width=True)
        
        with tab_app:
            st.write("### ğŸ“š Perspective Apprentissage & Croissance")
            col_a1, col_a2, col_a3 = st.columns(3)
            
            col_a1.metric("ğŸ“ Taux Certification", f"{taux_certif:.1f}%")
            col_a2.metric("ğŸ“– Formation Continue", f"{formation_continue:.1f}%")
            col_a3.metric("ğŸ”„ Innovation", "3 projets", help="Nouveaux programmes/an")
            
            # DÃ©veloppement des compÃ©tences
            comp_data = pd.DataFrame({
                "CompÃ©tence": ["Business Analysis", "AgilitÃ©", "Data Analysis", "Digital Transformation", "Leadership"],
                "Niveau Actuel": [65, 45, 35, 40, 55],
                "Objectif 2025": [80, 65, 60, 70, 70],
                "Gap": [15, 20, 25, 30, 15]
            })
            st.dataframe(comp_data, use_container_width=True)
    
    # Export Markdown consolidÃ©
    st.markdown("---")
    col_export1, col_export2 = st.columns(2)
    
    with col_export1:
        if st.button("ğŸ“„ GÃ©nÃ©rer Rapport Markdown Complet"):
            # GÃ©nÃ©ration du rapport Markdown
            rapport_md = f"""
# Rapport StratÃ©gique IIBA Cameroun {datetime.now().year}

## Executive Summary
- **Total BA**: {total_ba}
- **Taux Certification**: {taux_certif:.1f}%
- **CA RÃ©alisÃ©**: {ca_total:,.0f} FCFA
- **Secteurs**: {diversite_sectorielle}

## Profil Type BA Camerounais
### DÃ©mographie
- RÃ©partition par genre: {dict(genre_counts)}
- Secteurs dominants: {dict(top_secteurs)}
- Localisation: Concentration Douala/YaoundÃ©

## Analyse SWOT
### Forces
- DiversitÃ© sectorielle ({diversite_sectorielle} secteurs)
- Engagement communautaire Ã©levÃ©
- Base financiÃ¨re solide

### OpportunitÃ©s  
- Transformation digitale
- Expansion rÃ©gionale
- Partenariats entreprises

## Balanced Scorecard
### FinanciÃ¨re
- CA: {ca_total:,.0f} FCFA
- Marge: {marge_benefice:.1f}%

### Client
- Satisfaction: {satisfaction_moy:.1f}/100
- RÃ©tention: {retention:.1f}%

Rapport gÃ©nÃ©rÃ© le {datetime.now().strftime('%Y-%m-%d %H:%M')}
"""
            
            st.download_button(
                "â¬‡ï¸ TÃ©lÃ©charger Rapport.md",
                rapport_md,
                file_name=f"Rapport_IIBA_Cameroun_{datetime.now().strftime('%Y%m%d')}.md",
                mime="text/markdown"
            )
    
    with col_export2:
        # Export Excel complet des analyses
        buf_advanced = io.BytesIO()
        with pd.ExcelWriter(buf_advanced, engine="openpyxl") as writer:
            # DonnÃ©es enrichies
            dfc_enriched.to_excel(writer, sheet_name="Contacts_Enrichis", index=False)
            engagement_secteur.to_excel(writer, sheet_name="Engagement_Secteur")
            kpi_standards.to_excel(writer, sheet_name="KPI_Standards", index=False)
            actions_df.to_excel(writer, sheet_name="Plan_Actions", index=False)
            
        st.download_button(
            "ğŸ“Š Export Analyses Excel",
            buf_advanced.getvalue(),
            file_name=f"Analyses_IIBA_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

# ---------------------- PAGE ADMIN â€” Migration & Import/Export ----------------------

elif page == "Admin":
    st.title("âš™ï¸ Admin â€” ParamÃ¨tres, Migration & Maintenance (centralisÃ©s dans parametres.csv)")

    # PARAMETRES LISTES DEROULANTES
    st.markdown("### Listes dÃ©roulantes (stockÃ©es dans parametres.csv)")
    with st.form("lists_form"):
        def show_line(name, label):
            raw = PARAMS.get(f"list_{name}", DEFAULT_LISTS.get(name, ""))
            return st.text_input(label, raw)
        genres = show_line("genres","Genres (sÃ©parÃ©s par |)")
        types_contact = show_line("types_contact","Types de contact (|)")
        statuts_engagement = show_line("statuts_engagement","Statuts d'engagement (|)")
        secteurs = show_line("secteurs","Secteurs (|)")
        pays = show_line("pays","Pays (|)")
        villes = show_line("villes","Villes (|)")
        sources = show_line("sources","Sources (|)")
        canaux = show_line("canaux","Canaux (|)")
        resultats_inter = show_line("resultats_inter","RÃ©sultats d'interaction (|)")
        types_evenements = show_line("types_evenements","Types d'Ã©vÃ©nements (|)")
        lieux = show_line("lieux","Lieux (|)")
        statuts_paiement = show_line("statuts_paiement","Statuts paiement (|)")
        moyens_paiement = show_line("moyens_paiement","Moyens paiement (|)")
        types_certif = show_line("types_certif","Types certification (|)")
        entreprises_cibles = show_line("entreprises_cibles","Entreprises cibles (Top-20) (|)")
        ok1 = st.form_submit_button("ğŸ’¾ Enregistrer les listes")
        if ok1:
            PARAMS.update({
                "list_genres": genres, "list_types_contact": types_contact, "list_statuts_engagement": statuts_engagement,
                "list_secteurs": secteurs, "list_pays": pays, "list_villes": villes, "list_sources": sources,
                "list_canaux": canaux, "list_resultats_inter": resultats_inter, "list_types_evenements": types_evenements,
                "list_lieux": lieux, "list_statuts_paiement": statuts_paiement, "list_moyens_paiement": moyens_paiement,
                "list_types_certif": types_certif, "list_entreprises_cibles": entreprises_cibles,
            })
            save_params(PARAMS)
            st.success("Listes enregistrÃ©es dans parametres.csv â€” rechargez la page si nÃ©cessaire.")

    # PARAMETRES SCORING ET AFFICHAGE
    st.markdown("### RÃ¨gles de scoring & d'affichage (parametres.csv)")
    with st.form("rules_form"):
        c1,c2,c3,c4 = st.columns(4)
        vip_thr = c1.number_input("Seuil VIP (FCFA)", min_value=0.0, step=50000.0, value=float(PARAMS.get("vip_threshold","500000")))
        w_int = c2.number_input("Poids Interaction", min_value=0.0, step=0.5, value=float(PARAMS.get("score_w_interaction","1")))
        w_part = c3.number_input("Poids Participation", min_value=0.0, step=0.5, value=float(PARAMS.get("score_w_participation","1")))
        w_pay = c4.number_input("Poids Paiement rÃ©glÃ©", min_value=0.0, step=0.5, value=float(PARAMS.get("score_w_payment_regle","2")))
        c5,c6,c7 = st.columns(3)
        lookback = c5.number_input("FenÃªtre interactions rÃ©centes (jours)", min_value=1, step=1, value=int(PARAMS.get("interactions_lookback_days","90")))
        hot_int_min = c6.number_input("Interactions rÃ©centes min (chaud)", min_value=0, step=1, value=int(PARAMS.get("rule_hot_interactions_recent_min","3")))
        hot_part_min = c7.number_input("Participations min (chaud)", min_value=0, step=1, value=int(PARAMS.get("rule_hot_participations_min","1")))
        hot_partiel = st.checkbox("Paiement partiel = prospect chaud", value=PARAMS.get("rule_hot_payment_partial_counts_as_hot","1") in ("1","true","True"))

        st.write("**Colonnes de la grille CRM (ordre, sÃ©parÃ©es par des virgules)**")
        grid_crm = st.text_input("CRM â†’ Colonnes", PARAMS.get("grid_crm_columns",""))
        st.caption("Colonnes disponibles : " + ", ".join(sorted(list(set(C_COLS + I_COLS + E_COLS + P_COLS + PAY_COLS + CERT_COLS + ['Interactions','Participations','CA_rÃ©glÃ©','ImpayÃ©','Resp_principal','A_animÃ©_ou_invitÃ©','Score_composite','Proba_conversion','Tags','Dernier_contact','Interactions_recent'])))))

        st.write("**KPI visibles (sÃ©parÃ©s par des virgules)**")
        st.caption("ClÃ©s supportÃ©es : contacts_total, prospects_actifs, membres, events_count, participations_total, ca_regle, impayes, taux_conversion")
        kpi_enabled = st.text_input("KPI activÃ©s", PARAMS.get("kpi_enabled",""))

        st.write("**Objectifs annuels/mensuels (format clÃ©=valeur)**")
        st.caption("Ex. kpi_target_contacts_total_year_2025=1000 ; kpi_target_participations_total_month_202506=120")
        targets_text = st.text_area("Cibles (une par ligne)", "\n".join([f"{k}={v}" for k,v in PARAMS.items() if k.startswith("kpi_target_")]))

        ok2 = st.form_submit_button("ğŸ’¾ Enregistrer (parametres.csv)")
        if ok2:
            PARAMS.update({
                "vip_threshold": str(vip_thr),
                "score_w_interaction": str(w_int),
                "score_w_participation": str(w_part),
                "score_w_payment_regle": str(w_pay),
                "interactions_lookback_days": str(int(lookback)),
                "rule_hot_interactions_recent_min": str(int(hot_int_min)),
                "rule_hot_participations_min": str(int(hot_part_min)),
                "rule_hot_payment_partial_counts_as_hot": "1" if hot_partiel else "0",
                "grid_crm_columns": grid_crm,
                "kpi_enabled": kpi_enabled,
            })
            for line in targets_text.splitlines():
                if "=" in line:
                    key, val = line.split("=",1)
                    key = key.strip()
                    val = val.strip()
                    if key:
                        PARAMS[key] = val
            save_params(PARAMS)
            st.success("ParamÃ¨tres enregistrÃ©s dans parametres.csv â€” les nouvelles listes seront prises en compte au prochain rafraÃ®chissement.")

    # PARAMETRES Rapports AvancÃ©s
    # Dans la section des paramÃ¨tres Admin, ajouter:
    st.markdown("---")
    st.header("ğŸ“Š ParamÃ¨tres Rapports AvancÃ©s")
    
    with st.form("advanced_reports_params"):
        st.subheader("ğŸ¯ Seuils et Objectifs")
        
        col_p1, col_p2 = st.columns(2)
        
        with col_p1:
            # Seuils de segmentation
            seuil_ba_expert = st.number_input(
                "Score BA Expert (seuil)", 
                min_value=0, max_value=100, 
                value=int(PARAMS.get("seuil_ba_expert", "70"))
            )
            seuil_formation_continue = st.number_input(
                "Participations min. formation continue", 
                min_value=0, 
                value=int(PARAMS.get("seuil_formation_continue", "2"))
            )
            objectif_certification = st.number_input(
                "Objectif taux certification (%)", 
                min_value=0, max_value=100, 
                value=int(PARAMS.get("objectif_certification", "30"))
            )
        
        with col_p2:
            # Estimations salariales par secteur
            salaire_banque = st.number_input(
                "Salaire moyen Banque (FCFA)", 
                min_value=0, step=50000,
                value=int(PARAMS.get("salaire_banque", "800000"))
            )
            salaire_telecom = st.number_input(
                "Salaire moyen TÃ©lÃ©com (FCFA)", 
                min_value=0, step=50000,
                value=int(PARAMS.get("salaire_telecom", "750000"))
            )
            multiplicateur_certif = st.number_input(
                "Multiplicateur salaire certifiÃ©", 
                min_value=1.0, max_value=2.0, step=0.1,
                value=float(PARAMS.get("multiplicateur_certif", "1.3"))
            )
        
        # Objectifs BSC
        st.subheader("ğŸ“ˆ Objectifs Balanced Scorecard")
        col_bsc1, col_bsc2 = st.columns(2)
        
        with col_bsc1:
            objectif_croissance_ca = st.number_input(
                "Objectif croissance CA (%/an)", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_croissance_ca", "20"))
            )
            objectif_marge = st.number_input(
                "Objectif marge bÃ©nÃ©fice (%)", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_marge", "25"))
            )
        
        with col_bsc2:
            objectif_retention = st.number_input(
                "Objectif taux rÃ©tention (%)", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_retention", "80"))
            )
            objectif_nps = st.number_input(
                "Objectif NPS", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_nps", "70"))
            )
        
        if st.form_submit_button("ğŸ’¾ Enregistrer ParamÃ¨tres AvancÃ©s"):
            PARAMS.update({
                "seuil_ba_expert": str(seuil_ba_expert),
                "seuil_formation_continue": str(seuil_formation_continue),
                "objectif_certification": str(objectif_certification),
                "salaire_banque": str(salaire_banque),
                "salaire_telecom": str(salaire_telecom),
                "multiplicateur_certif": str(multiplicateur_certif),
                "objectif_croissance_ca": str(objectif_croissance_ca),
                "objectif_marge": str(objectif_marge),
                "objectif_retention": str(objectif_retention),
                "objectif_nps": str(objectif_nps)
            })
            save_params(PARAMS)
            st.success("âœ… ParamÃ¨tres avancÃ©s enregistrÃ©s!")
    

    # PARAMETRES Migration â€” Import/Export
    st.markdown("---")
    st.header("ğŸ“¦ Migration â€” Import/Export Global & Multi-onglets")

    mode_mig = st.radio("Mode de migration", ["Import Excel global (.xlsx)", "Import Excel multi-onglets (.xlsx)", "Import CSV global", "Par table (CSV)"], horizontal=True)

    if mode_mig == "Import Excel global (.xlsx)":
        up = st.file_uploader("Fichier Excel global (.xlsx)", type=["xlsx"], key="xlsx_up")
        st.caption("Feuille **Global** (ou 1Ã¨re) avec colonne **__TABLE__**.")
        if st.button("Importer l'Excel global") and up is not None:
            log = {"timestamp": datetime.now().isoformat(), "import_type": "excel_global", "counts": {}, "errors": [], "collisions": {}}
            try:
                xls = pd.ExcelFile(up)
                sheet = "Global" if "Global" in xls.sheet_names else xls.sheet_names[0]
                gdf = pd.read_excel(xls, sheet_name=sheet, dtype=str)
                if "__TABLE__" not in gdf.columns:
                    raise ValueError("Colonne '__TABLE__' manquante.")
                cols_global = ["__TABLE__"] + sorted(set(sum(ALL_SCHEMAS.values(), [])))
                for c in cols_global:
                    if c not in gdf.columns:
                        gdf[c] = ""
                # Contacts
                sub_c = gdf[gdf["__TABLE__"] == "contacts"].copy().fillna("")
                sub_c["Top20"] = sub_c["SociÃ©tÃ©"].fillna("").apply(lambda x: x in SET["entreprises_cibles"])

                def dedupe_contacts(df):
                    df = df.copy()
                    rejects = []
                    seen = set()
                    keep = []
                    def norm(s):
                        return str(s).strip().lower()
                    def email_ok2(s):
                        if not s or str(s).strip() == "" or str(s).lower() == "nan":
                            return True
                        return bool(re.match(r"^[^@\s]+@[^@\s]+\.[^@\s]+$", str(s).strip()))
                    for _, r in df.iterrows():
                        if not email_ok2(r.get("Email", "")):
                            rr = r.to_dict()
                            rr["_Raison"] = "Email invalide"
                            rejects.append(rr)
                            continue
                        if r.get("Email", ""):
                            key = ("email", norm(r["Email"]))
                        elif r.get("TÃ©lÃ©phone", ""):
                            key = ("tel", norm(r["TÃ©lÃ©phone"]))
                        else:
                            key = ("nps", (norm(r.get("Nom", "")), norm(r.get("PrÃ©nom", "")), norm(r.get("SociÃ©tÃ©", ""))))
                        if key in seen:
                            rr = r.to_dict()
                            rr["_Raison"] = "Doublon (fichier)"
                            rejects.append(rr)
                            continue
                        seen.add(key)
                        keep.append(r)
                    return pd.DataFrame(keep, columns=C_COLS), pd.DataFrame(rejects)

                valid_c, rejects_c = dedupe_contacts(sub_c)
                base = df_contacts.copy()
                collisions = []
                if "ID" in valid_c.columns and not valid_c.empty:
                    incoming = set(x for x in valid_c["ID"].astype(str) if x and x.lower() != "nan")
                    existing = set(base["ID"].astype(str))
                    collisions = sorted(list(incoming & existing))
                    if collisions:
                        base = base[~base["ID"].isin(collisions)]
                patt = re.compile(r"^CNT_(\d+)$")
                base_max = 0
                for x in base["ID"].dropna().astype(str):
                    m = patt.match(x.strip())
                    if m:
                        try:
                            base_max = max(base_max, int(m.group(1)))
                        except:
                            pass
                next_id = base_max + 1
                new_rows=[]
                for _, r in valid_c.iterrows():
                    rid = r["ID"]
                    if not isinstance(rid, str) or rid.strip() == "" or rid.strip().lower() == "nan":
                        rid = f"CNT_{str(next_id).zfill(3)}"
                        next_id += 1
                    rr = r.to_dict()
                    rr["ID"] = rid
                    new_rows.append(rr)
                base = pd.concat([base, pd.DataFrame(new_rows, columns=C_COLS)], ignore_index=True)
                save_df(base, PATHS["contacts"])
                globals()["df_contacts"] = base
                log["counts"]["contacts"] = len(new_rows)
                log["collisions"]["contacts"] = collisions
                if not rejects_c.empty:
                    st.warning(f"Lignes contacts rejetÃ©es : {len(rejects_c)}")
                    st.dataframe(rejects_c, use_container_width=True)

                # Fonction pour enregistrer subsets
                def save_subset(tbl, cols, path, prefix):
                    sub = gdf[gdf["__TABLE__"] == tbl].copy()
                    sub = sub[cols].fillna("")
                    id_col = cols[0]
                    base_df = ensure_df(path, cols)
                    incoming = set(x for x in sub[id_col].astype(str) if x and x.lower() != "nan")
                    existing = set(base_df[id_col].astype(str))
                    coll = sorted(list(incoming & existing))
                    if coll:
                        base_df = base_df[~base_df[id_col].isin(coll)]
                    patt = re.compile(rf"^{prefix}_(\d+)$")
                    base_max = 0
                    for x in base_df[id_col].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    gen = base_max + 1
                    new_rows = []
                    for _, r in sub.iterrows():
                        cur = r[id_col]
                        if not isinstance(cur, str) or cur.strip() == "" or cur.strip().lower() == "nan":
                            cur = f"{prefix}_{str(gen).zfill(3)}"
                            gen += 1
                        rr = r.to_dict()
                        rr[id_col] = cur
                        new_rows.append(rr)
                    out = pd.concat([base_df, pd.DataFrame(new_rows, columns=cols)], ignore_index=True)
                    save_df(out, path)
                    globals()["df_" + ("inter" if tbl == "interactions" else "events" if tbl == "evenements" else "parts" if tbl == "participations" else "pay" if tbl == "paiements" else "cert")] = out
                    log["counts"][tbl] = len(new_rows)
                    log["collisions"][tbl] = coll

                for spec in [("interactions", I_COLS, PATHS["inter"], "INT"),
                             ("evenements", E_COLS, PATHS["events"], "EVT"),
                             ("participations", P_COLS, PATHS["parts"], "PAR"),
                             ("paiements", PAY_COLS, PATHS["pay"], "PAY"),
                             ("certifications", CERT_COLS, PATHS["cert"], "CER")]:
                    cnt, coll = save_subset(*spec)

                st.success("Import Excel global terminÃ©.")
                st.json(log)
                log_event("import_excel_global", log)
            except Exception as e:
                st.error(f"Erreur d'import Excel global : {e}")
                log_event("error_import_excel_global", {"error": str(e)})

        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="openpyxl") as w:
            gcols = ["__TABLE__"] + sorted(set(sum(ALL_SCHEMAS.values(), [])))
            pd.DataFrame(columns=gcols).to_excel(w, index=False, sheet_name="Global")
        st.download_button("â¬‡ï¸ ModÃ¨le Global (xlsx)", buf.getvalue(), file_name="IIBA_global_template.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    elif mode_mig == "Import Excel multi-onglets (.xlsx)":
        up = st.file_uploader("Classeur Excel (6 feuilles : contacts, interactions, evenements, participations, paiements, certifications)",
                             type=["xlsx"], key="xlsx_multi")
        if st.button("Importer l'Excel multi-onglets") and up is not None:
            log = {"timestamp": datetime.now().isoformat(), "import_type": "excel_multisheets", "counts": {}, "errors": [], "collisions": {}}
            try:
                xls = pd.ExcelFile(up)

                def norm(s):
                    return ''.join(c for c in unicodedata.normalize('NFD', str(s)) if unicodedata.category(c) != 'Mn').lower().strip()

                sheets = {norm(n): n for n in xls.sheet_names}
                aliases = {
                    "contacts": ["contacts", "contact"],
                    "interactions": ["interactions", "interaction"],
                    "evenements": ["evenements", "Ã©vÃ©nements", "events"],
                    "participations": ["participations", "participation"],
                    "paiements": ["paiements", "paiement", "payments"],
                    "certifications": ["certifications", "certification"]
                }
                found = {}
                for tbl, names in aliases.items():
                    for n in names:
                        k = norm(n)
                        if k in sheets:
                            found[tbl] = sheets[k]
                            break

                if "contacts" in found:
                    gdf = pd.read_excel(xls, sheet_name=found["contacts"], dtype=str).fillna("")
                    for c in C_COLS:
                        if c not in gdf.columns:
                            gdf[c] = ""
                    sub_c = gdf[C_COLS].fillna("")
                    sub_c["Top20"] = sub_c["SociÃ©tÃ©"].fillna("").apply(lambda x: x in SET["entreprises_cibles"])

                    seen = set()
                    keep = []
                    for _, r in sub_c.iterrows():
                        key = r.get("Email", "") or r.get("TÃ©lÃ©phone", "") or (r.get("Nom", ""), r.get("PrÃ©nom", ""), r.get("SociÃ©tÃ©", ""))
                        if key in seen:
                            continue
                        seen.add(key)
                        keep.append(r)
                    valid_c = pd.DataFrame(keep, columns=C_COLS)
                    base = df_contacts.copy()
                    collisions = []
                    if "ID" in valid_c.columns and not valid_c.empty:
                        incoming = set(x for x in valid_c["ID"].astype(str) if x and x.lower() != "nan")
                        existing = set(base["ID"].astype(str))
                        collisions = sorted(list(incoming & existing))
                        if collisions:
                            base = base[~base["ID"].isin(collisions)]
                    patt = re.compile(r"^CNT_(\d+)$")
                    base_max = 0
                    for x in base["ID"].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    next_id = base_max + 1
                    new_rows = []
                    for _, r in valid_c.iterrows():
                        rid = r["ID"]
                        if not isinstance(rid, str) or rid.strip() == "" or rid.strip().lower() == "nan":
                            rid = f"CNT_{str(next_id).zfill(3)}"
                            next_id += 1
                        rr = r.to_dict()
                        rr["ID"] = rid
                        new_rows.append(rr)
                    out = pd.concat([base, pd.DataFrame(new_rows, columns=C_COLS)], ignore_index=True)
                    save_df(out, PATHS["contacts"])
                    globals()["df_contacts"] = out
                    log["counts"]["contacts"] = len(new_rows)
                    log["collisions"]["contacts"] = collisions

                def save_sheet(tbl, cols, path, prefix):
                    if tbl not in found:
                        return 0, []
                    sdf = pd.read_excel(xls, sheet_name=found[tbl], dtype=str).fillna("")
                    for c in cols:
                        if c not in sdf.columns:
                            sdf[c] = ""
                    sdf = sdf[cols]
                    id_col = cols[0]
                    base_df = ensure_df(path, cols)
                    incoming = set(x for x in sdf[id_col].astype(str) if x and x.lower() != "nan")
                    existing = set(base_df[id_col].astype(str))
                    coll = sorted(list(incoming & existing))
                    if coll:
                        base_df = base_df[~base_df[id_col].isin(coll)]
                    patt = re.compile(rf"^{prefix}_(\d+)$")
                    base_max = 0
                    for x in base_df[id_col].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    gen = base_max + 1
                    new_rows = []
                    for _, r in sdf.iterrows():
                        cur = r[id_col]
                        if not isinstance(cur, str) or cur.strip() == "" or cur.strip().lower() == "nan":
                            cur = f"{prefix}_{str(gen).zfill(3)}"
                            gen += 1
                        rr = r.to_dict()
                        rr[id_col] = cur
                        new_rows.append(rr)
                    out = pd.concat([base_df, pd.DataFrame(new_rows, columns=cols)], ignore_index=True)
                    save_df(out, path)
                    globals()["df_" + ("inter" if tbl == "interactions" else 
                                      "events" if tbl == "evenements" else 
                                      "parts" if tbl == "participations" else 
                                      "pay" if tbl == "paiements" else "cert")] = out
                    return len(new_rows), coll

                for spec in [("interactions", I_COLS, PATHS["inter"], "INT"),
                             ("evenements", E_COLS, PATHS["events"], "EVT"),
                             ("participations", P_COLS, PATHS["parts"], "PAR"),
                             ("paiements", PAY_COLS, PATHS["pay"], "PAY"),
                             ("certifications", CERT_COLS, PATHS["cert"], "CER")]:
                    cnt, coll = save_sheet(*spec)
                    log["counts"][spec[0]] = cnt
                    log["collisions"][spec] = coll

                st.success("Import Excel multi-onglets terminÃ©.")
                st.json(log)
                log_event("import_excel_multisheets", log)
            except Exception as e:
                st.error(f"Erreur d'import multi-onglets: {e}")
                log_event("error_import_excel_multisheets", {"error": str(e)})

        bufm = io.BytesIO()
        with pd.ExcelWriter(bufm, engine="openpyxl") as w:
            pd.DataFrame(columns=C_COLS).to_excel(w, index=False, sheet_name="contacts")
            pd.DataFrame(columns=I_COLS).to_excel(w, index=False, sheet_name="interactions")
            pd.DataFrame(columns=E_COLS).to_excel(w, index=False, sheet_name="evenements")
            pd.DataFrame(columns=P_COLS).to_excel(w, index=False, sheet_name="participations")
            pd.DataFrame(columns=PAY_COLS).to_excel(w, index=False, sheet_name="paiements")
            pd.DataFrame(columns=CERT_COLS).to_excel(w, index=False, sheet_name="certifications")
        st.download_button("â¬‡ï¸ ModÃ¨le Multi-onglets (xlsx)", bufm.getvalue(), file_name="IIBA_multisheets_template.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    elif mode_mig == "Import CSV global":
        up = st.file_uploader("CSV global (colonne __TABLE__)", type=["csv"], key="g_up")
        if st.button("Importer le CSV global") and up is not None:
            try:
                gdf = pd.read_csv(up, dtype=str, encoding="utf-8")
                if "__TABLE__" not in gdf.columns:
                    raise ValueError("Colonne __TABLE__ manquante.")
                def save_subset(tbl, cols, path, prefix):
                    sub = gdf[gdf["__TABLE__"] == tbl].copy()
                    for c in cols:
                        if c not in sub.columns:
                            sub[c] = ""
                    sub = sub[cols].fillna("")
                    id_col = cols[0]
                    base_df = ensure_df(path, cols)
                    incoming = set(x for x in sub[id_col].astype(str) if x and x.lower() != "nan")
                    existing = set(base_df[id_col].astype(str))
                    coll = sorted(list(incoming & existing))
                    if coll:
                        base_df = base_df[~base_df[id_col].isin(coll)]
                    patt = re.compile(rf"^{prefix}_(\d+)$")
                    base_max = 0
                    for x in base_df[id_col].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    gen = base_max + 1
                    ids = []
                    for _, r in sub.iterrows():
                        rid = r[id_col]
                        if not isinstance(rid, str) or rid.strip() == "" or rid.strip().lower() == "nan":
                            ids.append(f"{prefix}_{str(gen).zfill(3)}")
                            gen += 1
                        else:
                            ids.append(rid.strip())
                    sub[id_col] = ids
                    out = pd.concat([base_df, sub], ignore_index=True)
                    save_df(out, path)
                    globals()["df_" + ("contacts" if tbl == "contacts" else "inter" if tbl == "interactions" else "events" if tbl == "evenements" else "parts" if tbl == "participations" else "pay" if tbl == "paiements" else "cert")] = out
                save_subset("contacts", C_COLS, PATHS["contacts"], "CNT")
                save_subset("interactions", I_COLS, PATHS["inter"], "INT")
                save_subset("evenements", E_COLS, PATHS["events"], "EVT")
                save_subset("participations", P_COLS, PATHS["parts"], "PAR")
                save_subset("paiements", PAY_COLS, PATHS["pay"], "PAY")
                save_subset("certifications", CERT_COLS, PATHS["cert"], "CER")
                st.success("Import CSV global terminÃ©.")
            except Exception as e:
                st.error(f"Erreur d'import CSV global : {e}")



    # ... code existant load_and_compute_kpis() ...

    st.markdown("---")
    st.header("ğŸ”§ Maintenance Base de DonnÃ©es")
    
    col_reset, col_purge = st.columns(2)
    
    with col_reset:
        st.subheader("ğŸ—‘ï¸ RÃ©initialisation ComplÃ¨te")
        st.warning("âš ï¸ Cette action supprime TOUTES les donnÃ©es et recrÃ©e les fichiers vides.")
        
        confirm_reset = st.text_input(
            "Tapez 'RESET' pour confirmer:",
            placeholder="RESET"
        )
        
        if st.button("ğŸ’£ RÃ‰INITIALISER LA BASE", type="secondary"):
            if confirm_reset == "RESET":
                try:
                    # Suppression de tous les fichiers CSV
                    for path in PATHS.values():
                        if path.exists():
                            path.unlink()
                    
                    # RecrÃ©ation des fichiers vides
                    for table, cols in ALL_SCHEMAS.items():
                        empty_df = pd.DataFrame(columns=cols)
                        save_df(empty_df, PATHS[table])
                    
                    # RecrÃ©ation parametres.csv
                    df_params = pd.DataFrame({
                        "key": list(ALL_DEFAULTS.keys()), 
                        "value": list(ALL_DEFAULTS.values())
                    })
                    df_params.to_csv(PATHS["params"], index=False, encoding="utf-8")
                    
                    # Journalisation
                    log_event("reset_database", {
                        "action": "RÃ©initialisation complÃ¨te",
                        "tables_recreated": list(ALL_SCHEMAS.keys()),
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    st.success("âœ… Base de donnÃ©es rÃ©initialisÃ©e avec succÃ¨s!")
                    st.info("ğŸ”„ Rechargez la page pour voir les modifications.")
                    
                except Exception as e:
                    st.error(f"âŒ Erreur lors de la rÃ©initialisation: {e}")
                    log_event("error_reset_database", {"error": str(e)})
            else:
                st.error("âŒ Veuillez taper 'RESET' pour confirmer.")
    
    with col_purge:
        st.subheader("ğŸ¯ Purge d'un Identifiant")
        st.info("Supprime un contact, Ã©vÃ©nement, interaction, etc. par son ID")
        
        purge_id = st.text_input(
            "ID Ã  supprimer (ex: CNT_001, EVT_005, INT_023):",
            placeholder="CNT_001"
        )
        
        purge_type = st.selectbox(
            "Type d'entitÃ©:",
            ["Auto-dÃ©tection", "Contact", "Ã‰vÃ©nement", "Interaction", "Participation", "Paiement", "Certification"]
        )
        
        if st.button("ğŸ—‘ï¸ PURGER CET ID", type="secondary"):
            if purge_id:
                try:
                    deleted_count = 0
                    deleted_from = []
                    
                    if purge_type == "Auto-dÃ©tection":
                        # DÃ©tection automatique basÃ©e sur le prÃ©fixe
                        if purge_id.startswith("CNT_"):
                            purge_type = "Contact"
                        elif purge_id.startswith("EVT_"):
                            purge_type = "Ã‰vÃ©nement"
                        elif purge_id.startswith("INT_"):
                            purge_type = "Interaction"
                        elif purge_id.startswith("PAR_"):
                            purge_type = "Participation"
                        elif purge_id.startswith("PAY_"):
                            purge_type = "Paiement"
                        elif purge_id.startswith("CER_"):
                            purge_type = "Certification"
                    
                    # Suppression selon le type
                    if purge_type == "Contact":
                        # Suppression en cascade: contact + toutes ses relations
                        original_len = len(df_contacts)
                        globals()["df_contacts"] = df_contacts[df_contacts["ID"] != purge_id]
                        deleted_count += original_len - len(df_contacts)
                        if deleted_count > 0:
                            save_df(df_contacts, PATHS["contacts"])
                            deleted_from.append("contacts")
                        
                        # Suppression interactions liÃ©es
                        original_len = len(df_inter)
                        globals()["df_inter"] = df_inter[df_inter["ID"] != purge_id]
                        inter_deleted = original_len - len(df_inter)
                        if inter_deleted > 0:
                            save_df(df_inter, PATHS["inter"])
                            deleted_from.append(f"interactions ({inter_deleted})")
                        
                        # Suppression participations liÃ©es
                        original_len = len(df_parts)
                        globals()["df_parts"] = df_parts[df_parts["ID"] != purge_id]
                        part_deleted = original_len - len(df_parts)
                        if part_deleted > 0:
                            save_df(df_parts, PATHS["parts"])
                            deleted_from.append(f"participations ({part_deleted})")
                        
                        # Suppression paiements liÃ©s
                        original_len = len(df_pay)
                        globals()["df_pay"] = df_pay[df_pay["ID"] != purge_id]
                        pay_deleted = original_len - len(df_pay)
                        if pay_deleted > 0:
                            save_df(df_pay, PATHS["pay"])
                            deleted_from.append(f"paiements ({pay_deleted})")
                        
                        # Suppression certifications liÃ©es
                        original_len = len(df_cert)
                        globals()["df_cert"] = df_cert[df_cert["ID"] != purge_id]
                        cert_deleted = original_len - len(df_cert)
                        if cert_deleted > 0:
                            save_df(df_cert, PATHS["cert"])
                            deleted_from.append(f"certifications ({cert_deleted})")
                    
                    elif purge_type == "Ã‰vÃ©nement":
                        # Suppression Ã©vÃ©nement + participations + paiements liÃ©s
                        original_len = len(df_events)
                        globals()["df_events"] = df_events[df_events["ID_Ã‰vÃ©nement"] != purge_id]
                        deleted_count += original_len - len(df_events)
                        if deleted_count > 0:
                            save_df(df_events, PATHS["events"])
                            deleted_from.append("evenements")
                        
                        # Suppression participations Ã  cet Ã©vÃ©nement
                        original_len = len(df_parts)
                        globals()["df_parts"] = df_parts[df_parts["ID_Ã‰vÃ©nement"] != purge_id]
                        part_deleted = original_len - len(df_parts)
                        if part_deleted > 0:
                            save_df(df_parts, PATHS["parts"])
                            deleted_from.append(f"participations ({part_deleted})")
                        
                        # Suppression paiements Ã  cet Ã©vÃ©nement
                        original_len = len(df_pay)
                        globals()["df_pay"] = df_pay[df_pay["ID_Ã‰vÃ©nement"] != purge_id]
                        pay_deleted = original_len - len(df_pay)
                        if pay_deleted > 0:
                            save_df(df_pay, PATHS["pay"])
                            deleted_from.append(f"paiements ({pay_deleted})")
                    
                    elif purge_type == "Interaction":
                        original_len = len(df_inter)
                        globals()["df_inter"] = df_inter[df_inter["ID_Interaction"] != purge_id]
                        deleted_count += original_len - len(df_inter)
                        if deleted_count > 0:
                            save_df(df_inter, PATHS["inter"])
                            deleted_from.append("interactions")
                    
                    elif purge_type == "Participation":
                        original_len = len(df_parts)
                        globals()["df_parts"] = df_parts[df_parts["ID_Participation"] != purge_id]
                        deleted_count += original_len - len(df_parts)
                        if deleted_count > 0:
                            save_df(df_parts, PATHS["parts"])
                            deleted_from.append("participations")
                    
                    elif purge_type == "Paiement":
                        original_len = len(df_pay)
                        globals()["df_pay"] = df_pay[df_pay["ID_Paiement"] != purge_id]
                        deleted_count += original_len - len(df_pay)
                        if deleted_count > 0:
                            save_df(df_pay, PATHS["pay"])
                            deleted_from.append("paiements")
                    
                    elif purge_type == "Certification":
                        original_len = len(df_cert)
                        globals()["df_cert"] = df_cert[df_cert["ID_Certif"] != purge_id]
                        deleted_count += original_len - len(df_cert)
                        if deleted_count > 0:
                            save_df(df_cert, PATHS["cert"])
                            deleted_from.append("certifications")
                    
                    # Journalisation
                    log_event("purge_id", {
                        "purged_id": purge_id,
                        "type": purge_type,
                        "deleted_count": deleted_count,
                        "tables_affected": deleted_from,
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    if deleted_count > 0 or deleted_from:
                        st.success(f"âœ… ID '{purge_id}' purgÃ© avec succÃ¨s!")
                        st.info(f"ğŸ“Š Suppressions: {', '.join(deleted_from)}")
                        st.info("ğŸ”„ Rechargez la page pour voir les modifications.")
                    else:
                        st.warning(f"âš ï¸ ID '{purge_id}' introuvable dans la base.")
                
                except Exception as e:
                    st.error(f"âŒ Erreur lors de la purge: {e}")
                    log_event("error_purge_id", {"purge_id": purge_id, "error": str(e)})
            else:
                st.error("âŒ Veuillez saisir un ID Ã  purger.")

    # ... reste du code existant (load_and_compute_kpis etc.) ...
    
    
