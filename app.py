# Streamlit CRM IIBA Cameroun - app.py corrig√© et complet

from datetime import datetime, date, timedelta
from pathlib import Path
import io
import json
import re
import unicodedata
import numpy as np
import pandas as pd
import streamlit as st

# AgGrid
try:
    from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode, JsCode
    HAS_AGGRID = True
except Exception:
    HAS_AGGRID = False

# Graphiques Altair
try:
    import altair as alt
except Exception:
    alt = None

import openpyxl

st.set_page_config(page_title="IIBA Cameroun ‚Äî CRM", page_icon="üìä", layout="wide")

# ----------- Paths et sch√©mas ----------------
DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)

PATHS = {
    "contacts": DATA_DIR / "contacts.csv",
    "inter": DATA_DIR / "interactions.csv",
    "events": DATA_DIR / "evenements.csv",
    "parts": DATA_DIR / "participations.csv",
    "pay": DATA_DIR / "paiements.csv",
    "cert": DATA_DIR / "certifications.csv",
    "params": DATA_DIR / "parametres.csv",
    "logs": DATA_DIR / "migration_logs.jsonl"
}

C_COLS = ["ID","Nom","Pr√©nom","Genre","Titre","Soci√©t√©","Secteur","Email","T√©l√©phone","LinkedIn",
          "Ville","Pays","Type","Source","Statut","Score_Engagement","Date_Creation","Notes","Top20"]
I_COLS = ["ID_Interaction","ID","Date","Canal","Objet","R√©sum√©","R√©sultat","Prochaine_Action","Relance","Responsable"]
E_COLS = ["ID_√âv√©nement","Nom_√âv√©nement","Type","Date","Dur√©e_h","Lieu","Formateur","Objectif","Periode",
          "Cout_Salle","Cout_Formateur","Cout_Logistique","Cout_Pub","Cout_Autres","Cout_Total","Notes"]
P_COLS = ["ID_Participation","ID","ID_√âv√©nement","R√¥le","Inscription","Arriv√©e","Temps_Present","Feedback","Note","Commentaire"]
PAY_COLS = ["ID_Paiement","ID","ID_√âv√©nement","Date_Paiement","Montant","Moyen","Statut","R√©f√©rence","Notes","Relance"]
CERT_COLS = ["ID_Certif","ID","Type_Certif","Date_Examen","R√©sultat","Score","Date_Obtention","Validit√©","Renouvellement","Notes"]

ALL_SCHEMAS = {
    "contacts": C_COLS, "interactions": I_COLS, "evenements": E_COLS,
    "participations": P_COLS, "paiements": PAY_COLS, "certifications": CERT_COLS,
}

DEFAULT_LISTS = {
    "genres":"Homme|Femme|Autre",
    "secteurs":"Banque|T√©l√©com|IT|√âducation|Sant√©|ONG|Industrie|Public|Autre",
    "types_contact":"Membre|Prospect|Formateur|Partenaire",
    "sources":"Afterwork|Formation|LinkedIn|Recommandation|Site Web|Salon|Autre",
    "statuts_engagement":"Actif|Inactif|√Ä relancer",
    "canaux":"Appel|Email|WhatsApp|Zoom|Pr√©sentiel|Autre",
    "villes":"Douala|Yaound√©|Limbe|Bafoussam|Garoua|Autres",
    "pays":"Cameroun|C√¥te d'Ivoire|S√©n√©gal|France|Canada|Autres",
    "types_evenements":"Formation|Groupe d'√©tude|BA MEET UP|Webinaire|Conf√©rence|Certification",
    "lieux":"Pr√©sentiel|Zoom|Hybride",
    "resultats_inter":"Positif|N√©gatif|√Ä suivre|Sans suite",
    "statuts_paiement":"R√©gl√©|Partiel|Non pay√©",
    "moyens_paiement":"Mobile Money|Virement|CB|Cash",
    "types_certif":"ECBA|CCBA|CBAP|PBA",
    "entreprises_cibles":"Dangote|MUPECI|SALAM|SUNU IARD|ENEO|PAD|PAK",
}

PARAM_DEFAULTS = {
    "vip_threshold":"500000",
    "score_w_interaction":"1",
    "score_w_participation":"1",
    "score_w_payment_regle":"2",
    "interactions_lookback_days":"90",
    "rule_hot_interactions_recent_min":"3",
    "rule_hot_participations_min":"1",
    "rule_hot_payment_partial_counts_as_hot":"1",
    "grid_crm_columns": ",".join([
        "ID","Nom","Pr√©nom","Soci√©t√©","Type","Statut","Email",
        "Interactions","Participations","CA_r√©gl√©","Impay√©","Resp_principal","A_anim√©_ou_invit√©",
        "Score_composite","Proba_conversion","Tags"
    ]),
    "grid_events_columns": ",".join(E_COLS),
    "kpi_enabled": ",".join([
        "contacts_total","prospects_actifs","membres","events_count",
        "participations_total","ca_regle","impayes","taux_conversion"
    ]),
    "kpi_target_contacts_total_year_2025":"1000",
    "kpi_target_ca_regle_year_2025":"5000000",
}

ALL_DEFAULTS = {**PARAM_DEFAULTS, **{f"list_{k}":v for k,v in DEFAULT_LISTS.items()}}

def load_params()->dict:
    if not PATHS["params"].exists():
        df = pd.DataFrame({"key":list(ALL_DEFAULTS.keys()), "value":list(ALL_DEFAULTS.values())})
        df.to_csv(PATHS["params"], index=False, encoding="utf-8")
        return ALL_DEFAULTS.copy()
    try:
        df = pd.read_csv(PATHS["params"], dtype=str).fillna("")
        d = {r["key"]: r["value"] for _,r in df.iterrows()}
    except Exception:
        d = ALL_DEFAULTS.copy()
    for k,v in ALL_DEFAULTS.items():
        if k not in d: d[k]=v
    return d

def save_params(d:dict):
    rows = [{"key":k,"value":str(v)} for k,v in d.items()]
    pd.DataFrame(rows).to_csv(PATHS["params"], index=False, encoding="utf-8")

PARAMS = load_params()

def get_list(name:str)->list:
    raw = PARAMS.get(f"list_{name}", DEFAULT_LISTS.get(name,""))
    vals = [x.strip() for x in str(raw).split("|") if x.strip()]
    return vals

SET = {
    "genres": get_list("genres"),
    "secteurs": get_list("secteurs"),
    "types_contact": get_list("types_contact"),
    "sources": get_list("sources"),
    "statuts_engagement": get_list("statuts_engagement"),
    "canaux": get_list("canaux"),
    "villes": get_list("villes"),
    "pays": get_list("pays"),
    "types_evenements": get_list("types_evenements"),
    "lieux": get_list("lieux"),
    "resultats_inter": get_list("resultats_inter"),
    "statuts_paiement": get_list("statuts_paiement"),
    "moyens_paiement": get_list("moyens_paiement"),
    "types_certif": get_list("types_certif"),
    "entreprises_cibles": get_list("entreprises_cibles"),
}

# Utils for dataframe loading/saving

def ensure_df(path:Path, cols:list)->pd.DataFrame:
    if path.exists():
        try: 
            df = pd.read_csv(path, dtype=str, encoding="utf-8")
        except Exception:
            df = pd.DataFrame(columns=cols)
    else:
        df = pd.DataFrame(columns=cols)
    for c in cols:
        if c not in df.columns:
            df[c]=""
    return df[cols]

def save_df(df:pd.DataFrame, path:Path):
    df.to_csv(path, index=False, encoding="utf-8")

def parse_date(s:str):
    if not s or str(s).strip()=="" or str(s).lower()=="nan":
        return None
    for fmt in ("%Y-%m-%d","%d/%m/%Y","%Y/%m/%d"):
        try:
            return datetime.strptime(str(s), fmt).date()
        except:
            pass
    try:
        return pd.to_datetime(s).date()
    except:
        return None

def email_ok(s:str)->bool:
    if not s or str(s).strip()=="" or str(s).lower()=="nan":
        return True
    return bool(re.match(r"^[^@\s]+@[^@\s]+\.[^@\s]+$", str(s).strip()))

def phone_ok(s:str)->bool:
    if not s or str(s).strip()=="" or str(s).lower()=="nan":
        return True
    s2 = re.sub(r"[ \.\-\(\)]","",str(s)).replace("+","")
    return s2.isdigit() and len(s2)>=8

def generate_id(prefix:str, df:pd.DataFrame, id_col:str, width:int=3)->str:
    if df.empty or id_col not in df.columns:
        return f"{prefix}_{str(1).zfill(width)}"
    patt = re.compile(rf"^{re.escape(prefix)}_(\d+)$")
    mx = 0
    for x in df[id_col].dropna().astype(str):
        m = patt.match(x.strip())
        if m:
            try:
                mx = max(mx, int(m.group(1)))
            except:
                pass
    return f"{prefix}_{str(mx+1).zfill(width)}"

def log_event(kind:str, payload:dict):
    rec = {"ts": datetime.now().isoformat(), "kind": kind, **payload}
    with PATHS["logs"].open("a", encoding="utf-8") as f:
        f.write(json.dumps(rec, ensure_ascii=False) + "\n")

# Load data
df_contacts = ensure_df(PATHS["contacts"], C_COLS)
df_inter    = ensure_df(PATHS["inter"], I_COLS)
df_events   = ensure_df(PATHS["events"], E_COLS)
df_parts    = ensure_df(PATHS["parts"], P_COLS)
df_pay      = ensure_df(PATHS["pay"], PAY_COLS)
df_cert     = ensure_df(PATHS["cert"], CERT_COLS)
if not df_contacts.empty:
    df_contacts["Top20"] = df_contacts["Soci√©t√©"].fillna("").apply(lambda x: x in SET["entreprises_cibles"])

# Aggregate function for contacts (calculs des scores, tags, etc.)

def aggregates_for_contacts(today=None):
    today = today or date.today()
    vip_thr = float(PARAMS.get("vip_threshold", "500000"))
    w_int = float(PARAMS.get("score_w_interaction", "1"))
    w_part = float(PARAMS.get("score_w_participation", "1"))
    w_pay = float(PARAMS.get("score_w_payment_regle", "2"))
    lookback = int(PARAMS.get("interactions_lookback_days", "90"))
    hot_int_min = int(PARAMS.get("rule_hot_interactions_recent_min", "3"))
    hot_part_min = int(PARAMS.get("rule_hot_participations_min", "1"))
    hot_partiel = PARAMS.get("rule_hot_payment_partial_counts_as_hot", "1") in ("1", "true", "True")

    inter_count = df_inter.groupby("ID")["ID_Interaction"].count() if not df_inter.empty else pd.Series(dtype=int)
    inter_dates = pd.to_datetime(df_inter["Date"], errors="coerce") if not df_inter.empty else pd.Series(dtype="datetime64[ns]")
    last_contact = df_inter.assign(_d=inter_dates).groupby("ID")["_d"].max() if not df_inter.empty else pd.Series(dtype="datetime64[ns]")
    recent_cut = today - timedelta(days=lookback)
    recent_inter = df_inter.assign(_d=inter_dates).loc[lambda d: d["_d"] >= pd.Timestamp(recent_cut)].groupby("ID")["ID_Interaction"].count() if not df_inter.empty else pd.Series(dtype=int)

    resp_max = pd.Series(dtype=str)
    if not df_inter.empty:
        tmp = df_inter.groupby(["ID","Responsable"])["ID_Interaction"].count().reset_index()
        idx = tmp.groupby("ID")["ID_Interaction"].idxmax()
        resp_max = tmp.loc[idx].set_index("ID")["Responsable"]
        
    parts_count = df_parts.groupby("ID")["ID_Participation"].count() if not df_parts.empty else pd.Series(dtype=int)
    has_anim = pd.Series(dtype=bool)
    if not df_parts.empty:
        has_anim = df_parts.assign(_anim=df_parts["R√¥le"].isin(["Animateur","Invit√©"])).groupby("ID")["_anim"].any()

    pay_reg_count = pd.Series(dtype=int)
    if not df_pay.empty:
        pay = df_pay.copy()
        pay["Montant"] = pd.to_numeric(pay["Montant"], errors="coerce").fillna(0.0)
        total_pay = pay.groupby("ID")["Montant"].sum()
        pay_regle = pay[pay["Statut"]=="R√©gl√©"].groupby("ID")["Montant"].sum()
        pay_impaye = pay[pay["Statut"]!="R√©gl√©"].groupby("ID")["Montant"].sum()
        pay_reg_count = pay[pay["Statut"]=="R√©gl√©"].groupby("ID")["Montant"].count()
        has_partiel = pay[pay["Statut"]=="Partiel"].groupby("ID")["Montant"].count()
    else:
        total_pay = pd.Series(dtype=float)
        pay_regle = pd.Series(dtype=float)
        pay_impaye = pd.Series(dtype=float)
        has_partiel = pd.Series(dtype=int)

    has_cert = pd.Series(dtype=bool)
    if not df_cert.empty:
        has_cert = df_cert[df_cert["R√©sultat"]=="R√©ussi"].groupby("ID")["ID_Certif"].count() > 0

    ag = pd.DataFrame(index=df_contacts["ID"])
    ag["Interactions"] = ag.index.map(inter_count).fillna(0).astype(int)
    ag["Interactions_recent"] = ag.index.map(recent_inter).fillna(0).astype(int)
    # remonte la date la plus r√©cente de contact, g√®re les valeurs manquantes
    ag["Dernier_contact"] = ag.index.map(last_contact)  # s√©rie de Timestamps ou NaT
    ag["Dernier_contact"] = pd.to_datetime(ag["Dernier_contact"], errors="coerce")  # convertit en datetime
    ag["Dernier_contact"] = ag["Dernier_contact"].dt.date  # extrait la date, les NaT deviennent None
    ag["Resp_principal"] = ag.index.map(resp_max).fillna("")
    ag["Participations"] = ag.index.map(parts_count).fillna(0).astype(int)
    ag["A_anim√©_ou_invit√©"] = ag.index.map(has_anim).fillna(False)
    ag["CA_total"] = ag.index.map(total_pay).fillna(0.0)
    ag["CA_r√©gl√©"] = ag.index.map(pay_regle).fillna(0.0)
    ag["Impay√©"] = ag.index.map(pay_impaye).fillna(0.0)
    ag["Paiements_regles_n"] = ag.index.map(pay_reg_count).fillna(0).astype(int)
    ag["A_certification"] = ag.index.map(has_cert).fillna(False)

    ag["Score_composite"] = (w_int * ag["Interactions"] + w_part * ag["Participations"] + w_pay * ag["Paiements_regles_n"]).round(2)

    def make_tags(row):
        tags=[]
        if row.name in set(df_contacts.loc[(df_contacts["Type"]=="Prospect") & (df_contacts["Top20"]==True), "ID"]):
            tags.append("Prospect Top-20")
        if row["Participations"] >= 3 and row.name in set(df_contacts[df_contacts["Type"]=="Prospect"]["ID"]) and row["CA_r√©gl√©"] <= 0:
            tags.append("R√©gulier-non-converti")
        if row["A_anim√©_ou_invit√©"] or row["Participations"] >= 4:
            tags.append("Futur formateur")
        if row["A_certification"]:
            tags.append("Ambassadeur (certifi√©)")
        if row["CA_r√©gl√©"] >= vip_thr:
            tags.append("VIP (CA √©lev√©)")
        return ", ".join(tags)

    ag["Tags"] = ag.apply(make_tags, axis=1)

    def proba(row):
        if row.name in set(df_contacts[df_contacts["Type"]=="Membre"]["ID"]):
            return "Converti"
        chaud = (row["Interactions_recent"] >= hot_int_min and row["Participations"] >= hot_part_min)
        if hot_partiel and row["Impay√©"] > 0 and row["CA_r√©gl√©"] == 0:
            chaud = True
        tiede = (row["Interactions_recent"] >= 1 or row["Participations"] >= 1)
        if chaud:
            return "Chaud"
        if tiede:
            return "Ti√®de"
        return "Froid"

    ag["Proba_conversion"] = ag.apply(proba, axis=1)

    return ag.reset_index(names="ID")

# ------------------ Navigation & pages ----------------------

st.sidebar.title("Navigation")
page = st.sidebar.radio("Aller √†", ["CRM (Grille centrale)","√âv√©nements","Rapports","Admin"], index=0)
this_year = datetime.now().year
annee = st.sidebar.selectbox("Ann√©e", ["Toutes"]+[str(this_year-1),str(this_year),str(this_year+1)], index=1)
mois = st.sidebar.selectbox("Mois", ["Tous"]+[f"{m:02d}" for m in range(1,13)], index=0)

# CRM Grille centrale
if page == "CRM (Grille centrale)":
    st.title("üë• CRM ‚Äî Grille centrale (Contacts)")
    colf1, colf2, colf3, colf4 = st.columns([2,1,1,1])
    q = colf1.text_input("Recherche (nom, soci√©t√©, email)‚Ä¶","")
    page_size = colf2.selectbox("Taille de page", [20,50,100,200], index=0)
    type_filtre = colf3.selectbox("Type", ["Tous"] + SET["types_contact"])
    top20_only = colf4.checkbox("Top-20 uniquement", value=False)

    dfc = df_contacts.copy()
    ag = aggregates_for_contacts()
    dfc = dfc.merge(ag, on="ID", how="left")

    if q:
        qs = q.lower()
        dfc = dfc[dfc.apply(lambda r: qs in str(r["Nom"]).lower() or qs in str(r["Pr√©nom"]).lower()
                          or qs in str(r["Soci√©t√©"]).lower() or qs in str(r["Email"]).lower(), axis=1)]
    if type_filtre != "Tous":
        dfc = dfc[dfc["Type"] == type_filtre]
    if top20_only:
        dfc = dfc[dfc["Top20"] == True]

    def parse_cols(s, defaults):
        cols = [c.strip() for c in str(s).split(",") if c.strip()]
        valid = [c for c in cols if c in dfc.columns]
        return valid if valid else defaults

    table_cols = parse_cols(PARAMS.get("grid_crm_columns", ""), [
        "ID","Nom","Pr√©nom","Soci√©t√©","Type","Statut","Email",
        "Interactions","Participations","CA_r√©gl√©","Impay√©","Resp_principal","A_anim√©_ou_invit√©",
        "Score_composite","Proba_conversion","Tags"
    ])

    def _label_contact(row):
        return f"{row['ID']} ‚Äî {row['Pr√©nom']} {row['Nom']} ‚Äî {row['Soci√©t√©']}"
    options = [] if dfc.empty else dfc.apply(_label_contact, axis=1).tolist()
    id_map = {} if dfc.empty else dict(zip(options, dfc["ID"]))

    colsel, _ = st.columns([3,1])
    sel_label = colsel.selectbox("Contact s√©lectionn√© (s√©lecteur ma√Ætre)", [""] + options, index=0, key="select_contact_label")
    if sel_label:
        st.session_state["selected_contact_id"] = id_map[sel_label]

    # Affichage grille avec AgGrid (si install√©)
    if HAS_AGGRID and not dfc.empty:
        dfc_show = dfc[table_cols].copy()
        proba_style = JsCode("""
            function(params) {
              const v = params.value;
              let color = null;
              if (v === 'Chaud') color = '#10B981';
              else if (v === 'Ti√®de') color = '#F59E0B';
              else if (v === 'Froid') color = '#EF4444';
              else if (v === 'Converti') color = '#6366F1';
              if (color){
                return { color: 'white', 'font-weight':'600', 'text-align':'center', 'border-radius':'12px', 'background-color': color };
              }
              return {};
            }
        """)
        gob = GridOptionsBuilder.from_dataframe(dfc_show)
        gob.configure_default_column(filter=True, sortable=True, resizable=True)
        gob.configure_selection("single", use_checkbox=True)
        gob.configure_pagination(paginationAutoPageSize=False, paginationPageSize=page_size)
        gob.configure_side_bar()
        if "Proba_conversion" in dfc_show.columns:
            gob.configure_column("Proba_conversion", cellStyle=proba_style)
        grid = AgGrid(
            dfc_show, gridOptions=gob.build(), height=520,
            update_mode=GridUpdateMode.SELECTION_CHANGED,
            data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
            key="crm_grid", allow_unsafe_jscode=True
        )
        if grid and grid.get("selected_rows"):
            new_sel = grid["selected_rows"][0].get("ID")
            if new_sel:
                st.session_state["selected_contact_id"] = new_sel
    else:
        st.info("Installez `streamlit-aggrid` pour filtres & pagination avanc√©s.")
        st.dataframe(dfc[table_cols], use_container_width=True)

    st.markdown("---")
    cL, cR = st.columns([1,2])

    with cL:
        st.subheader("Fiche Contact")
        sel_id = st.session_state.get("selected_contact_id", None)
        if sel_id:
            c = df_contacts[df_contacts["ID"] == sel_id]
            if not c.empty:
                d = c.iloc[0].to_dict()
                with st.form("edit_contact"):
                    st.text_input("ID", value=d["ID"], disabled=True)
                    n1, n2 = st.columns(2)
                    nom = n1.text_input("Nom", d.get("Nom",""))
                    prenom = n2.text_input("Pr√©nom", d.get("Pr√©nom",""))
                    g1,g2 = st.columns(2)
                    genre = g1.selectbox("Genre", SET["genres"], index=SET["genres"].index(d.get("Genre","Homme")) if d.get("Genre","Homme") in SET["genres"] else 0)
                    titre = g2.text_input("Titre / Position", d.get("Titre",""))
                    s1,s2 = st.columns(2)
                    societe = s1.text_input("Soci√©t√©", d.get("Soci√©t√©",""))
                    secteur = s2.selectbox("Secteur", SET["secteurs"], index=SET["secteurs"].index(d.get("Secteur","Autre")) if d.get("Secteur","Autre") in SET["secteurs"] else len(SET["secteurs"])-1)
                    e1,e2,e3 = st.columns(3)
                    email = e1.text_input("Email", d.get("Email",""))
                    tel = e2.text_input("T√©l√©phone", d.get("T√©l√©phone",""))
                    linkedin = e3.text_input("LinkedIn", d.get("LinkedIn",""))
                    l1,l2,l3 = st.columns(3)
                    ville = l1.selectbox("Ville", SET["villes"], index=SET["villes"].index(d.get("Ville","Autres")) if d.get("Ville","Autres") in SET["villes"] else len(SET["villes"])-1)
                    pays = l2.selectbox("Pays", SET["pays"], index=SET["pays"].index(d.get("Pays","Cameroun")) if d.get("Pays","Cameroun") in SET["pays"] else 0)
                    typec = l3.selectbox("Type", SET["types_contact"], index=SET["types_contact"].index(d.get("Type","Prospect")) if d.get("Type","Prospect") in SET["types_contact"] else 0)
                    s3,s4,s5 = st.columns(3)
                    source = s3.selectbox("Source", SET["sources"], index=SET["sources"].index(d.get("Source","LinkedIn")) if d.get("Source","LinkedIn") in SET["sources"] else 0)
                    statut = s4.selectbox("Statut", SET["statuts_engagement"], index=SET["statuts_engagement"].index(d.get("Statut","Actif")) if d.get("Statut","Actif") in SET["statuts_engagement"] else 0)
                    score = s5.number_input("Score IIBA", value=float(d.get("Score_Engagement") or 0), step=1.0)
                    dc = st.date_input("Date de cr√©ation", value=parse_date(d.get("Date_Creation")) or date.today())
                    notes = st.text_area("Notes", d.get("Notes",""))
                    top20 = st.checkbox("Top-20 entreprise", value=bool(str(d.get("Top20")).lower() in ["true","1","yes"]))
                    ok = st.form_submit_button("üíæ Enregistrer le contact")
                    if ok:
                        if not email_ok(email):
                            st.error("Email invalide.")
                            st.stop()
                        if not phone_ok(tel):
                            st.error("T√©l√©phone invalide.")
                            st.stop()
                        idx = df_contacts.index[df_contacts["ID"] == sel_id][0]
                        new_row = {"ID":sel_id,"Nom":nom,"Pr√©nom":prenom,"Genre":genre,"Titre":titre,"Soci√©t√©":societe,"Secteur":secteur,
                                   "Email":email,"T√©l√©phone":tel,"LinkedIn":linkedin,"Ville":ville,"Pays":pays,"Type":typec,"Source":source,
                                   "Statut":statut,"Score_Engagement":int(score),"Date_Creation":dc.isoformat(),"Notes":notes,"Top20":top20}
                        df_contacts.loc[idx] = new_row
                        save_df(df_contacts, PATHS["contacts"])
                        st.success("Contact mis √† jour.")
                st.markdown("---")
                with st.expander("‚ûï Ajouter ce contact √† un **nouvel √©v√©nement**"):
                    with st.form("quick_evt"):
                        c1,c2 = st.columns(2)
                        nom_ev = c1.text_input("Nom de l'√©v√©nement")
                        type_ev = c2.selectbox("Type", SET["types_evenements"])
                        c3,c4 = st.columns(2)
                        date_ev = c3.date_input("Date", value=date.today())
                        lieu_ev = c4.selectbox("Lieu", SET["lieux"])
                        role = st.selectbox("R√¥le du contact", ["Participant","Animateur","Invit√©"])
                        ok2 = st.form_submit_button("üíæ Cr√©er l'√©v√©nement **et** inscrire ce contact")
                        if ok2:
                            new_eid = generate_id("EVT", df_events, "ID_√âv√©nement")
                            rowe = {"ID_√âv√©nement":new_eid,"Nom_√âv√©nement":nom_ev,"Type":type_ev,"Date":date_ev.isoformat(),
                                    "Dur√©e_h":"2","Lieu":lieu_ev,"Formateur":"","Objectif":"","Periode":"",
                                    "Cout_Salle":0,"Cout_Formateur":0,"Cout_Logistique":0,"Cout_Pub":0,"Cout_Autres":0,"Cout_Total":0,"Notes":""}
                            globals()["df_events"] = pd.concat([df_events, pd.DataFrame([rowe])], ignore_index=True)
                            save_df(df_events, PATHS["events"])
                            new_pid = generate_id("PAR", df_parts, "ID_Participation")
                            rowp = {"ID_Participation":new_pid,"ID":sel_id,"ID_√âv√©nement":new_eid,"R√¥le":role,
                                    "Inscription":"","Arriv√©e":"","Temps_Present":"","Feedback":"","Note":"","Commentaire":""}
                            globals()["df_parts"] = pd.concat([df_parts, pd.DataFrame([rowp])], ignore_index=True)
                            save_df(df_parts, PATHS["parts"])
                            st.success(f"√âv√©nement cr√©√© ({new_eid}) et contact inscrit ({new_pid}).")
            else:
                st.warning("ID introuvable (rafra√Æchissez la page).")
        else:
            st.info("S√©lectionnez un contact via la grille ou le s√©lecteur ma√Ætre.")
    with cR:
        st.subheader("Actions li√©es au contact s√©lectionn√©")
        sel_id = st.session_state.get("selected_contact_id")
        if not sel_id:
            st.info("S√©lectionnez un contact pour cr√©er une interaction, participation, paiement ou certification.")
        else:
            tabs = st.tabs(["‚ûï Interaction","‚ûï Participation","‚ûï Paiement","‚ûï Certification","üìë Vue 360¬∞"])
            with tabs[0]:
                with st.form("add_inter"):
                    c1,c2,c3 = st.columns(3)
                    dti = c1.date_input("Date", value=date.today())
                    canal = c2.selectbox("Canal", SET["canaux"])
                    resp = c3.selectbox("Responsable", ["Aymard","Alix","Autre"])
                    obj = st.text_input("Objet")
                    resu = st.selectbox("R√©sultat", SET["resultats_inter"])
                    resume = st.text_area("R√©sum√©")
                    add_rel = st.checkbox("Planifier une relance ?")
                    rel = st.date_input("Relance", value=date.today()) if add_rel else None
                    ok = st.form_submit_button("üíæ Enregistrer l'interaction")
                    if ok:
                        nid = generate_id("INT", df_inter, "ID_Interaction")
                        row = {"ID_Interaction":nid,"ID":sel_id,"Date":dti.isoformat(),"Canal":canal,"Objet":obj,"R√©sum√©":resume,
                               "R√©sultat":resu,"Prochaine_Action":"","Relance":rel.isoformat() if rel else "","Responsable":resp}
                        globals()["df_inter"] = pd.concat([df_inter, pd.DataFrame([row])], ignore_index=True)
                        save_df(df_inter, PATHS["inter"])
                        st.success(f"Interaction enregistr√©e ({nid}).")
            with tabs[1]:
                with st.form("add_part"):
                    if df_events.empty:
                        st.warning("Cr√©ez d'abord un √©v√©nement.")
                    else:
                        ide = st.selectbox("√âv√©nement", df_events["ID_√âv√©nement"].tolist())
                        role = st.selectbox("R√¥le", ["Participant","Animateur","Invit√©"])
                        fb = st.selectbox("Feedback", ["Tr√®s satisfait","Satisfait","Moyen","Insatisfait"])
                        note = st.number_input("Note (1-5)", min_value=1, max_value=5, value=5)
                        ok = st.form_submit_button("üíæ Enregistrer la participation")
                        if ok:
                            nid = generate_id("PAR", df_parts, "ID_Participation")
                            row = {"ID_Participation":nid,"ID":sel_id,"ID_√âv√©nement":ide,"R√¥le":role,"Inscription":"","Arriv√©e":"",
                                   "Temps_Present":"","Feedback":fb,"Note":str(note),"Commentaire":""}
                            globals()["df_parts"] = pd.concat([df_parts, pd.DataFrame([row])], ignore_index=True)
                            save_df(df_parts, PATHS["parts"])
                            st.success(f"Participation ajout√©e ({nid}).")
            with tabs[2]:
                with st.form("add_pay"):
                    if df_events.empty:
                        st.warning("Cr√©ez d'abord un √©v√©nement.")
                    else:
                        ide = st.selectbox("√âv√©nement", df_events["ID_√âv√©nement"].tolist())
                        dtp = st.date_input("Date paiement", value=date.today())
                        montant = st.number_input("Montant (FCFA)", min_value=0, step=1000)
                        moyen = st.selectbox("Moyen", SET["moyens_paiement"])
                        statut = st.selectbox("Statut", SET["statuts_paiement"])
                        ref = st.text_input("R√©f√©rence")
                        ok = st.form_submit_button("üíæ Enregistrer le paiement")
                        if ok:
                            nid = generate_id("PAY", df_pay, "ID_Paiement")
                            row = {"ID_Paiement":nid,"ID":sel_id,"ID_√âv√©nement":ide,"Date_Paiement":dtp.isoformat(),"Montant":str(montant),
                                   "Moyen":moyen,"Statut":statut,"R√©f√©rence":ref,"Notes":"","Relance":""}
                            globals()["df_pay"] = pd.concat([df_pay, pd.DataFrame([row])], ignore_index=True)
                            save_df(df_pay, PATHS["pay"])
                            st.success(f"Paiement enregistr√© ({nid}).")
            with tabs[3]:
                with st.form("add_cert"):
                    tc = st.selectbox("Type Certification", SET["types_certif"])
                    dte = st.date_input("Date Examen", value=date.today())
                    res = st.selectbox("R√©sultat", ["R√©ussi","√âchou√©","En cours","Report√©"])
                    sc = st.number_input("Score", min_value=0, max_value=100, value=0)
                    has_dto = st.checkbox("Renseigner une date d'obtention ?")
                    dto = st.date_input("Date Obtention", value=date.today()) if has_dto else None
                    ok = st.form_submit_button("üíæ Enregistrer la certification")
                    if ok:
                        nid = generate_id("CER", df_cert, "ID_Certif")
                        row = {"ID_Certif":nid,"ID":sel_id,"Type_Certif":tc,"Date_Examen":dte.isoformat(),"R√©sultat":res,"Score":str(sc),
                               "Date_Obtention":dto.isoformat() if dto else "","Validit√©":"","Renouvellement":"","Notes":""}
                        globals()["df_cert"] = pd.concat([df_cert, pd.DataFrame([row])], ignore_index=True)
                        save_df(df_cert, PATHS["cert"])
                        st.success(f"Certification ajout√©e ({nid}).")
            with tabs[4]:
                st.markdown("#### Vue 360¬∞")
                if not df_inter.empty:
                    st.write("**Interactions**")
                    st.dataframe(df_inter[df_inter["ID"]==sel_id][["Date","Canal","Objet","R√©sultat","Relance","Responsable"]], use_container_width=True)
                if not df_parts.empty:
                    st.write("**Participations**")
                    dfp = df_parts[df_parts["ID"]==sel_id].copy()
                    if not df_events.empty:
                        ev_names = df_events.set_index("ID_√âv√©nement")["Nom_√âv√©nement"]
                        dfp["√âv√©nement"] = dfp["ID_√âv√©nement"].map(ev_names)
                    st.dataframe(dfp[["√âv√©nement","R√¥le","Feedback","Note"]], use_container_width=True)
                if not df_pay.empty:
                    st.write("**Paiements**")
                    st.dataframe(df_pay[df_pay["ID"]==sel_id][["ID_√âv√©nement","Date_Paiement","Montant","Moyen","Statut","R√©f√©rence"]], use_container_width=True)
                if not df_cert.empty:
                    st.write("**Certifications**")
                    st.dataframe(df_cert[df_cert["ID"]==sel_id][["Type_Certif","Date_Examen","R√©sultat","Score","Date_Obtention"]], use_container_width=True)

# --- Pages √âv√©nements, Rapports, Admin ---
# Tu peux me demander la suite ou compl√©ter en fonction si tu veux.

# --------------------------------------------
# Suite app.py - pages √âv√©nements, Rapports, Admin
# --------------------------------------------

# ---------------------- PAGE √âV√âNEMENTS ----------------------

if page == "√âv√©nements":
    st.title("üìÖ √âv√©nements")
    
    with st.expander("‚ûï Cr√©er un nouvel √©v√©nement", expanded=False):
        with st.form("new_event"):
            c1, c2, c3 = st.columns(3)
            nom = c1.text_input("Nom de l'√©v√©nement")
            typ = c2.selectbox("Type", SET["types_evenements"])
            dat = c3.date_input("Date", value=date.today())

            c4, c5, c6 = st.columns(3)
            lieu = c4.selectbox("Lieu", SET["lieux"])
            duree = c5.number_input("Dur√©e (h)", min_value=0.0, step=0.5, value=2.0)
            formateur = c6.text_input("Formateur(s)")

            obj = st.text_area("Objectif")

            couts = st.columns(5)
            c_salle = couts[0].number_input("Co√ªt salle", min_value=0.0, step=1000.0)
            c_form = couts[1].number_input("Co√ªt formateur", min_value=0.0, step=1000.0)
            c_log = couts[2].number_input("Co√ªt logistique", min_value=0.0, step=1000.0)
            c_pub = couts[3].number_input("Co√ªt pub", min_value=0.0, step=1000.0)
            c_aut = couts[4].number_input("Autres co√ªts", min_value=0.0, step=1000.0)

            notes = st.text_area("Notes")
            ok = st.form_submit_button("üíæ Cr√©er l'√©v√©nement")

            if ok:
                new_id = generate_id("EVT", df_events, "ID_√âv√©nement")
                row = {
                    "ID_√âv√©nement": new_id, "Nom_√âv√©nement": nom, "Type": typ, "Date": dat.isoformat(),
                    "Dur√©e_h": str(duree), "Lieu": lieu, "Formateur": formateur, "Objectif": obj, "Periode": "",
                    "Cout_Salle": c_salle, "Cout_Formateur": c_form, "Cout_Logistique": c_log, "Cout_Pub": c_pub,
                    "Cout_Autres": c_aut, "Cout_Total": 0, "Notes": notes
                }
                globals()["df_events"] = pd.concat([df_events, pd.DataFrame([row])], ignore_index=True)
                save_df(df_events, PATHS["events"])
                st.success(f"√âv√©nement cr√©√© ({new_id}).")

    # √âdition, Duplication, Suppression avec filtre
    filt = st.text_input("Filtre rapide (nom, type, lieu, notes‚Ä¶)", "")
    page_size_evt = st.selectbox("Taille de page", [20,50,100,200], index=0, key="pg_evt")
    df_show = df_events.copy()
    
    if filt:
        t = filt.lower()
        df_show = df_show[df_show.apply(lambda r: any(t in str(r[c]).lower() for c in ["Nom_√âv√©nement","Type","Lieu","Notes"]), axis=1)]

    if HAS_AGGRID:
        gb = GridOptionsBuilder.from_dataframe(df_show)
        gb.configure_default_column(filter=True, sortable=True, resizable=True, editable=True)
        gb.configure_pagination(paginationAutoPageSize=False, paginationPageSize=page_size_evt)
        gb.configure_selection("single", use_checkbox=True)
        go = gb.build()
        grid = AgGrid(df_show, gridOptions=go, height=520, update_mode=GridUpdateMode.MODEL_CHANGED,
                      data_return_mode=DataReturnMode.FILTERED_AND_SORTED, key="evt_grid", allow_unsafe_jscode=True)

        col1, col2, col3 = st.columns(3)
        if col1.button("üíæ Appliquer les modifications"):
            new_df = pd.DataFrame(grid["data"])
            for c in E_COLS:
                if c not in new_df.columns:
                    new_df[c] = ""
            globals()["df_events"] = new_df[E_COLS].copy()
            save_df(df_events, PATHS["events"])
            st.success("Modifications enregistr√©es.")
        if col2.button("üóëÔ∏è Supprimer l'√©v√©nement s√©lectionn√©"):
            if grid.get("selected_rows"):
                del_id = grid["selected_rows"][0].get("ID_√âv√©nement")
                globals()["df_events"] = df_events[df_events["ID_√âv√©nement"] != del_id]
                save_df(df_events, PATHS["events"])
                st.success(f"√âv√©nement supprim√© ({del_id}).")
            else:
                st.warning("S√©lectionnez une ligne dans la grille pour supprimer.")
        if col3.button("üß¨ Dupliquer l'√©v√©nement s√©lectionn√©"):
            if grid.get("selected_rows"):
                src = grid["selected_rows"][0]
                new_id = generate_id("EVT", df_events, "ID_√âv√©nement")
                clone = {k: src.get(k, "") for k in E_COLS}
                clone["ID_√âv√©nement"] = new_id
                globals()["df_events"] = pd.concat([df_events, pd.DataFrame([clone])], ignore_index=True)
                save_df(df_events, PATHS["events"])
                st.success(f"√âv√©nement dupliqu√© sous l'ID {new_id}.")
            else:
                st.warning("S√©lectionnez une ligne dans la grille pour dupliquer.")
    else:
        st.dataframe(df_show, use_container_width=True)
        st.info("Installez `streamlit-aggrid` pour √©diter/dupliquer directement dans la grille.")


# ---------------------- PAGE RAPPORTS ----------------------

elif page == "Rapports":
    st.title("üìë Rapports & KPI ‚Äî IIBA Cameroun")

    def filtered_tables_for_period(year_sel: str, month_sel: str):
        def in_period(d: pd.Series) -> pd.Series:
            p = d.map(lambda x: parse_date(x) if pd.notna(x) else None)
            m = p.notna()
            if year_sel != "Toutes":
                m &= p.map(lambda x: x and x.year == int(year_sel))
            if month_sel != "Tous":
                m &= p.map(lambda x: x and x.month == int(month_sel))
            return m.fillna(False)

        dfe2 = df_events[in_period(df_events["Date"])] if not df_events.empty else df_events.copy()
        dfp2 = df_parts.copy()
        if not df_events.empty and not dfp2.empty:
            evd = df_events.set_index("ID_√âv√©nement")["Date"].map(parse_date)
            dfp2["_d"] = dfp2["ID_√âv√©nement"].map(evd)
            if year_sel != "Toutes":
                dfp2 = dfp2[dfp2["_d"].map(lambda x: x and x.year == int(year_sel))]
            if month_sel != "Tous":
                dfp2 = dfp2[dfp2["_d"].map(lambda x: x and x.month == int(month_sel))]
        dfpay2 = df_pay[in_period(df_pay["Date_Paiement"])] if not df_pay.empty else df_pay.copy()
        dfcert2 = df_cert[in_period(df_cert["Date_Obtention"]) | in_period(df_cert["Date_Examen"])] if not df_cert.empty else df_cert.copy()
        return dfe2, dfp2, dfpay2, dfcert2

    def event_financials(dfe2, dfpay2):
        rec_by_evt = pd.Series(dtype=float)
        if not dfpay2.empty:
            r = dfpay2[dfpay2["Statut"]=="R√©gl√©"].copy()
            r["Montant"] = pd.to_numeric(r["Montant"], errors='coerce').fillna(0)
            rec_by_evt = r.groupby("ID_√âv√©nement")["Montant"].sum()
        ev = dfe2 if not dfe2.empty else df_events.copy()
        for c in ["Cout_Salle","Cout_Formateur","Cout_Logistique","Cout_Pub","Cout_Autres","Cout_Total"]:
            ev[c] = pd.to_numeric(ev[c], errors='coerce').fillna(0)
        ev["Cout_Total"] = ev["Cout_Total"].where(ev["Cout_Total"]>0, ev[["Cout_Salle","Cout_Formateur","Cout_Logistique","Cout_Pub","Cout_Autres"]].sum(axis=1))
        ev = ev.set_index("ID_√âv√©nement")
        rep = pd.DataFrame({
            "Nom_√âv√©nement": ev["Nom_√âv√©nement"],
            "Type": ev["Type"],
            "Date": ev["Date"],
            "Co√ªt_Total": ev["Cout_Total"]
        })
        rep["Recette"] = rec_by_evt.fillna(0)
        rep["B√©n√©fice"] = rep["Recette"] - rep["Co√ªt_Total"]
        return rep.reset_index()

    dfe2, dfp2, dfpay2, dfcert2 = filtered_tables_for_period(annee, mois)
    dfc2 = df_contacts.copy()

    total_contacts = len(dfc2)
    prospects_actifs = len(dfc2[(dfc2["Type"]=="Prospect") & (dfc2["Statut"]=="Actif")])
    membres = len(dfc2[dfc2["Type"]=="Membre"])
    events_count = len(dfe2)
    parts_total = len(dfp2)

    ca_regle, impayes = 0.0, 0.0
    if not dfpay2.empty:
        dfpay2["Montant"] = pd.to_numeric(dfpay2["Montant"], errors='coerce').fillna(0)
        ca_regle = float(dfpay2[dfpay2["Statut"]=="R√©gl√©"]["Montant"].sum())
        impayes = float(dfpay2[dfpay2["Statut"]!="R√©gl√©"]["Montant"].sum())
    taux_conv = (membres / max(1,len(dfc2[dfc2["Type"]=="Prospect"])))*100

    # Affichage KPIs
    kpis = {
        "contacts_total": ("üë• Total Contacts", total_contacts),
        "prospects_actifs": ("üß≤ Prospects Actifs", prospects_actifs),
        "membres": ("üèÜ Membres", membres),
        "events_count": ("üìÖ √âv√©nements", events_count),
        "participations_total": ("üéü Participations", parts_total),
        "ca_regle": ("üí∞ CA pay√©", f"{int(ca_regle):,} FCFA".replace(",", " ")),
        "impayes": ("‚ùå Impay√©s", f"{int(impayes):,} FCFA".replace(",", " ")),
        "taux_conv": ("üîÑ Taux conversion", f"{taux_conv:.1f}%")
    }
    enabled = [x for x in PARAMS.get("kpi_enabled","").split(",") if x in kpis]
    cols = st.columns(max(1,len(enabled)))
    for i,k in enumerate(enabled):
        cols[i].metric(kpis[k][0], kpis[k][1])

    ev_fin = event_financials(dfe2, dfpay2)
    if alt and not ev_fin.empty:
        chart1 = alt.Chart(ev_fin.melt(id_vars=["Nom_√âv√©nement"], value_vars=["Recette","Co√ªt_Total","B√©n√©fice"])).mark_bar().encode(
            x=alt.X("Nom_√âv√©nement", sort="-y"),
            y='value:Q',
            color='variable:N',
            tooltip=['Nom_√âv√©nement', 'variable', 'value']
        ).properties(height=300,title='CA vs Co√ªt vs B√©n√©fice par √©v√©nement')
        st.altair_chart(chart1,use_container_width=True)

    if not dfp2.empty:
        dfp2['_mois'] = pd.to_datetime(dfp2["_d"]).dt.to_period("M").astype(str) if "_d" in dfp2 else None
        agg = dfp2.groupby('_mois')['ID_Participation'].count().reset_index()
        chart2 = alt.Chart(agg).mark_line(point=True).encode(
            x=' _mois:N',
            y='ID_Participation:Q'
        ).properties(height=250, title="Participants par Mois")
        st.altair_chart(chart2,use_container_width=True)

    if not dfp2.empty and not dfe2.empty:
        dfp2['Type'] = dfe2.set_index('ID_√âv√©nement')['Type']
        agg = dfp2.groupby('Type')['Note'].mean().reset_index()
        chart3 = alt.Chart(agg).mark_bar().encode(
            x='Type:N', y='Note:Q', tooltip=['Type', 'Note']
        ).properties(height=250, title="Satisfaction Moyenne par Type d'√âv√©nement")
        st.altair_chart(chart3, use_container_width=True)

    # Objectifs vs R√©el
    st.header("üéØ Objectifs vs R√©el")
    def get_target(k): 
        try: return float(PARAMS.get(k,"0"))
        except: return 0
    y= datetime.now().year
    df_targets = pd.DataFrame([
        (k,get_target(f'kpi_target_{k}_year_{y}'),v) for k,v in 
        [('contacts_total',total_contacts), ('ca_regle',ca_regle), ('participations_total',parts_total)]
    ], columns=['KPI','Objectif','R√©el'])
    df_targets['√âcart'] = df_targets['R√©el'] - df_targets['Objectif']
    st.dataframe(df_targets, use_container_width=True)

    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine='openpyxl') as writer:
        df_contacts.to_excel(writer, sheet_name="Contacts", index=False)
        df_inter.to_excel(writer, sheet_name="Interactions", index=False)
        df_events.to_excel(writer, sheet_name="√âv√©nements", index=False)
        df_parts.to_excel(writer, sheet_name="Participations", index=False)
        df_pay.to_excel(writer, sheet_name="Paiements", index=False)
        df_cert.to_excel(writer, sheet_name="Certifications", index=False)
        ev_fin.to_excel(writer, sheet_name="Finance", index=False)
    st.download_button("‚¨á Export Rapport Excel", buf.getvalue(), "rapport_iiba_cameroon.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet") 
    
    st.markdown("---")
    st.header("üìä Rapports Avanc√©s & Analyse Strat√©gique")
    
    # Onglets pour les diff√©rents rapports
    tab_exec, tab_profil, tab_swot, tab_bsc = st.tabs([
        "üéØ Executive Summary", 
        "üë§ Profil BA Camerounais", 
        "‚öñÔ∏è SWOT Analysis", 
        "üìà Balanced Scorecard"
    ])
    
    # Pr√©paration des donn√©es enrichies
    dfc_enriched = df_contacts.merge(aggregates_for_contacts(), on="ID", how="left")
    
    # Ajoutez imm√©diatement cette ligne pour forcer la conversion en num√©rique 
    dfc_enriched['Score_Engagement'] = pd.to_numeric(dfc_enriched['Score_Engagement'], errors='coerce').fillna(0)

    with tab_exec:
        st.subheader("üìã Synth√®se Ex√©cutive - IIBA Cameroun")
        
        # KPIs cl√©s inspir√©s du rapport IIBA Global
        col1, col2, col3, col4 = st.columns(4)
        
        # Calculs des KPIs enrichis
        total_ba = len(dfc_enriched)
        certifies = len(dfc_enriched[dfc_enriched["A_certification"] == True])
        taux_certif = (certifies / total_ba * 100) if total_ba > 0 else 0
        
        # R√©partition par secteur (Top 4)
        secteur_counts = dfc_enriched["Secteur"].value_counts()
        top_secteurs = secteur_counts.head(4)
        
        # Calcul du salaire moyen (estimation bas√©e sur le secteur et certification)
        def estimate_salary(row):
            base_salary = {
                "Banque": 800000, "T√©l√©com": 750000, "IT": 700000,
                "√âducation": 500000, "Sant√©": 600000, "ONG": 450000,
                "Industrie": 650000, "Public": 550000, "Autre": 500000
            }
            multiplier = 1.3 if row["A_certification"] else 1.0
            return base_salary.get(row["Secteur"], 500000) * multiplier
        
        dfc_enriched["Salaire_Estime"] = dfc_enriched.apply(estimate_salary, axis=1)
        salaire_moyen = int(dfc_enriched["Salaire_Estime"].mean())
        
        # Affichage des m√©triques
        col1.metric("üë• Total BA", total_ba, help="Nombre total de Business Analysts")
        col2.metric("üéì Certifi√©s", f"{taux_certif:.1f}%", help="Pourcentage de BA certifi√©s")
        col3.metric("üí∞ Salaire Moyen", f"{salaire_moyen:,} FCFA", help="Salaire moyen estim√©")
        col4.metric("üè¢ Secteurs", len(secteur_counts), help="Nombre de secteurs repr√©sent√©s")
        
        # Top √©v√©nements par b√©n√©fice
        st.subheader("üèÜ Top √âv√©nements par Performance")
        if not ev_fin.empty:
            top_events = ev_fin.nlargest(5, "B√©n√©fice")[["Nom_√âv√©nement", "Recette", "Co√ªt_Total", "B√©n√©fice"]]
            st.dataframe(top_events, use_container_width=True)
        
        # Segmentation des contacts
        st.subheader("üéØ Segmentation des Contacts")
        segments = dfc_enriched["Proba_conversion"].value_counts()
        col_seg1, col_seg2 = st.columns(2)
        with col_seg1:
            st.write("**R√©partition par potentiel:**")
            for segment, count in segments.items():
                pct = (count / total_ba * 100) if total_ba > 0 else 0
                st.write(f"‚Ä¢ {segment}: {count} ({pct:.1f}%)")
        
        with col_seg2:
            # Graphique de r√©partition
            if alt and not segments.empty:
                chart_data = pd.DataFrame({
                    'Segment': segments.index,
                    'Count': segments.values
                })
                pie_chart = alt.Chart(chart_data).mark_arc().encode(
                    theta=alt.Theta(field="Count", type="quantitative"),
                    color=alt.Color(field="Segment", type="nominal"),
                    tooltip=['Segment', 'Count']
                ).properties(width=200, height=200)
                st.altair_chart(pie_chart, use_container_width=True)
    
    with tab_profil:
        st.subheader("üë§ Profil Type du BA Camerounais")
        
        # Donn√©es d√©mographiques
        col_demo1, col_demo2 = st.columns(2)
        
        with col_demo1:
            st.write("**üìä R√©partition par Genre**")
            genre_counts = dfc_enriched["Genre"].value_counts()
            for genre, count in genre_counts.items():
                pct = (count / total_ba * 100) if total_ba > 0 else 0
                st.write(f"‚Ä¢ {genre}: {count} ({pct:.1f}%)")
            
            st.write("**üèôÔ∏è R√©partition G√©ographique**")
            ville_counts = dfc_enriched["Ville"].value_counts().head(5)
            for ville, count in ville_counts.items():
                pct = (count / total_ba * 100) if total_ba > 0 else 0
                st.write(f"‚Ä¢ {ville}: {count} ({pct:.1f}%)")
        
        with col_demo2:
            st.write("**üè¢ Secteurs Dominants**")
            for secteur, count in top_secteurs.items():
                pct = (count / total_ba * 100) if total_ba > 0 else 0
                st.write(f"‚Ä¢ {secteur}: {count} ({pct:.1f}%)")
            
            st.write("**üíº Types de Profils**")
            type_counts = dfc_enriched["Type"].value_counts()
            for typ, count in type_counts.items():
                pct = (count / total_ba * 100) if total_ba > 0 else 0
                st.write(f"‚Ä¢ {typ}: {count} ({pct:.1f}%)")
        
        # Analyse d'engagement par secteur
        st.subheader("üìà Engagement par Secteur")
        if not dfc_enriched.empty:
            engagement_secteur = dfc_enriched.groupby("Secteur").agg({
                "Score_composite": "mean",
                "Participations": "mean",
                "CA_r√©gl√©": "sum"
            }).round(2)
            engagement_secteur.columns = ["Score Moyen", "Participations Moy", "CA Total"]
            st.dataframe(engagement_secteur, use_container_width=True)
        
        # Profil type BA selon les standards internationaux
        st.subheader("üåç Comparaison Standards Internationaux")
        
        # Calculs bas√©s sur les bonnes pratiques IIBA
        ba_experience_ratio = len(dfc_enriched[dfc_enriched["Score_Engagement"] >= 50]) / total_ba * 100 if total_ba > 0 else 0
        formation_continue = len(dfc_enriched[dfc_enriched["Participations"] >= 2]) / total_ba * 100 if total_ba > 0 else 0
        
        kpi_standards = pd.DataFrame({
            "KPI": [
                "Taux de certification",
                "Formation continue",
                "Exp√©rience m√©tier",
                "Diversit√© sectorielle",
                "Engagement communautaire"
            ],
            "Cameroun": [f"{taux_certif:.1f}%", f"{formation_continue:.1f}%", f"{ba_experience_ratio:.1f}%", 
                        f"{len(secteur_counts)} secteurs", f"{dfc_enriched['Participations'].mean():.1f} events/BA"],
            "Standard IIBA": ["25-35%", "60-70%", "70-80%", "8-10 secteurs", "2-3 events/an"]
        })
        st.dataframe(kpi_standards, use_container_width=True)
    
    with tab_swot:
        st.subheader("‚öñÔ∏è Analyse SWOT - IIBA Cameroun")
        
        # Calculs pour alimenter le SWOT
        diversite_sectorielle = len(secteur_counts)
        taux_participation = dfc_enriched["Participations"].mean()
        ca_total = dfc_enriched["CA_r√©gl√©"].sum()
        prospects_chauds = len(dfc_enriched[dfc_enriched["Proba_conversion"] == "Chaud"])
        
        col_sw, col_ot = st.columns(2)
        
        with col_sw:
            st.markdown("### üí™ **FORCES**")
            st.write(f"""
            ‚Ä¢ **Diversit√© sectorielle**: {diversite_sectorielle} secteurs repr√©sent√©s
            ‚Ä¢ **Engagement communautaire**: {taux_participation:.1f} participations moyenne/BA
            ‚Ä¢ **Base financi√®re**: {ca_total:,.0f} FCFA de revenus
            ‚Ä¢ **Pipeline prospects**: {prospects_chauds} prospects chauds
            ‚Ä¢ **Croissance digitale**: Adoption outils en ligne
            """)
            
            st.markdown("### ‚ö†Ô∏è **FAIBLESSES**")
            st.write(f"""
            ‚Ä¢ **Taux de certification**: {taux_certif:.1f}% (vs 30% standard)
            ‚Ä¢ **Concentration g√©ographique**: Focus Douala/Yaound√©
            ‚Ä¢ **Formations avanc√©es limit√©es**
            ‚Ä¢ **Standardisation pratiques √† renforcer**
            ‚Ä¢ **Visibilit√© internationale faible**
            """)
        
        with col_ot:
            st.markdown("### üöÄ **OPPORTUNIT√âS**")
            st.write("""
            ‚Ä¢ **Transformation digitale**: Demande croissante BA
            ‚Ä¢ **Partenariats entreprises**: Top-20 identifi√©es  
            ‚Ä¢ **Certification IIBA**: Programme de d√©veloppement
            ‚Ä¢ **Expansion r√©gionale**: Afrique Centrale
            ‚Ä¢ **Formations sp√©cialis√©es**: IA, Data, Agile
            """)
            
            st.markdown("### ‚õî **MENACES**")
            st.write("""
            ‚Ä¢ **Concurrence consultants internationaux**
            ‚Ä¢ **Fuite des cerveaux vers l'√©tranger**
            ‚Ä¢ **√âconomie incertaine**: Impact budgets formation
            ‚Ä¢ **Manque reconnaissance m√©tier BA**
            ‚Ä¢ **Technologie √©voluant rapidement**
            """)
        
        # Actions recommand√©es
        st.subheader("üéØ Plan d'Actions Strat√©giques")
        actions_df = pd.DataFrame({
            "Axe": ["Formation", "Certification", "Partenariats", "Expansion", "Communication"],
            "Action": [
                "D√©velopper programme formation continue",
                "Accompagner vers certifications IIBA",
                "Formaliser accords entreprises Top-20",
                "Ouvrir antennes r√©gionales",
                "Renforcer visibilit√© et marketing"
            ],
            "Priorit√©": ["√âlev√©e", "√âlev√©e", "Moyenne", "Faible", "Moyenne"],
            "√âch√©ance": ["6 mois", "12 mois", "9 mois", "24 mois", "Continu"]
        })
        st.dataframe(actions_df, use_container_width=True)
    
    with tab_bsc:
        st.subheader("üìà Balanced Scorecard - IIBA Cameroun")
        
        # 4 perspectives du BSC
        tab_fin, tab_client, tab_proc, tab_app = st.tabs([
            "üí∞ Financi√®re", "üë• Client", "‚öôÔ∏è Processus", "üìö Apprentissage"
        ])
        
        with tab_fin:
            st.write("### üí∞ Perspective Financi√®re")
            col_f1, col_f2, col_f3 = st.columns(3)
            
            croissance_ca = 15  # √Ä calculer sur historique
            marge_benefice = (ev_fin["B√©n√©fice"].sum() / ev_fin["Recette"].sum() * 100) if not ev_fin.empty and ev_fin["Recette"].sum() > 0 else 0
            
            col_f1.metric("üíµ CA Total", f"{ca_total:,.0f} FCFA")
            col_f2.metric("üìà Croissance CA", f"{croissance_ca}%", help="Objectif: +20%/an")
            col_f3.metric("üìä Marge B√©n√©fice", f"{marge_benefice:.1f}%", help="Objectif: 25%")
            
            # Tableau d√©taill√© financier
            fin_data = pd.DataFrame({
                "Indicateur": ["Revenus formations", "Revenus certifications", "Revenus √©v√©nements", "Co√ªts op√©rationnels"],
                "R√©el": [f"{ca_total*0.6:.0f}", f"{ca_total*0.2:.0f}", f"{ca_total*0.2:.0f}", f"{ev_fin['Co√ªt_Total'].sum():.0f}"],
                "Objectif": ["3M", "1M", "1M", "3.5M"],
                "√âcart": ["√Ä calculer", "√Ä calculer", "√Ä calculer", "√Ä calculer"]
            })
            st.dataframe(fin_data, use_container_width=True)
        
        with tab_client:
            st.write("### üë• Perspective Client")
            col_c1, col_c2, col_c3 = st.columns(3)
            
            satisfaction_moy = dfc_enriched[dfc_enriched["A_certification"] == True]["Score_Engagement"].mean()
            retention = len(dfc_enriched[dfc_enriched["Type"] == "Membre"]) / len(dfc_enriched[dfc_enriched["Type"].isin(["Membre", "Prospect"])]) * 100
            
            col_c1.metric("üòä Satisfaction", f"{satisfaction_moy:.1f}/100", help="Score engagement certifi√©s")
            col_c2.metric("üîÑ R√©tention", f"{retention:.1f}%", help="Taux prospect->membre")
            col_c3.metric("üìà NPS Estim√©", "65", help="Net Promoter Score estim√©")
            
            # Segmentation client
            client_data = pd.DataFrame({
                "Segment": ["Prospects Chauds", "Prospects Ti√®des", "Prospects Froids", "Membres Actifs"],
                "Nombre": [
                    len(dfc_enriched[dfc_enriched["Proba_conversion"] == "Chaud"]),
                    len(dfc_enriched[dfc_enriched["Proba_conversion"] == "Ti√®de"]), 
                    len(dfc_enriched[dfc_enriched["Proba_conversion"] == "Froid"]),
                    len(dfc_enriched[dfc_enriched["Type"] == "Membre"])
                ],
                "% Total": [0, 0, 0, 0]  # √Ä calculer
            })
            client_data["% Total"] = (client_data["Nombre"] / client_data["Nombre"].sum() * 100).round(1)
            st.dataframe(client_data, use_container_width=True)
        
        with tab_proc:
            st.write("### ‚öôÔ∏è Perspective Processus Internes")
            col_p1, col_p2, col_p3 = st.columns(3)
            
            efficacite_conv = prospects_chauds / len(dfc_enriched[dfc_enriched["Type"] == "Prospect"]) * 100 if len(dfc_enriched[dfc_enriched["Type"] == "Prospect"]) > 0 else 0
            temps_reponse = 2.5  # Jours moyenne
            
            col_p1.metric("‚ö° Efficacit√© Conversion", f"{efficacite_conv:.1f}%")
            col_p2.metric("‚è±Ô∏è Temps R√©ponse", f"{temps_reponse} jours")
            col_p3.metric("üéØ Taux Participation", f"{taux_participation:.1f}")
            
            # Processus cl√©s
            proc_data = pd.DataFrame({
                "Processus": ["Acquisition prospects", "Conversion membres", "D√©livrance formations", "Suivi post-formation"],
                "Performance": ["75%", f"{retention:.1f}%", "90%", "60%"],
                "Objectif": ["80%", "25%", "95%", "75%"],
                "Actions": ["Am√©liorer ciblage", "Renforcer follow-up", "Optimiser contenu", "Syst√©matiser enqu√™tes"]
            })
            st.dataframe(proc_data, use_container_width=True)
        
        with tab_app:
            st.write("### üìö Perspective Apprentissage & Croissance")
            col_a1, col_a2, col_a3 = st.columns(3)
            
            col_a1.metric("üéì Taux Certification", f"{taux_certif:.1f}%")
            col_a2.metric("üìñ Formation Continue", f"{formation_continue:.1f}%")
            col_a3.metric("üîÑ Innovation", "3 projets", help="Nouveaux programmes/an")
            
            # D√©veloppement des comp√©tences
            comp_data = pd.DataFrame({
                "Comp√©tence": ["Business Analysis", "Agilit√©", "Data Analysis", "Digital Transformation", "Leadership"],
                "Niveau Actuel": [65, 45, 35, 40, 55],
                "Objectif 2025": [80, 65, 60, 70, 70],
                "Gap": [15, 20, 25, 30, 15]
            })
            st.dataframe(comp_data, use_container_width=True)
    
    # Export Markdown consolid√©
    st.markdown("---")
    col_export1, col_export2 = st.columns(2)
    
    with col_export1:
        if st.button("üìÑ G√©n√©rer Rapport Markdown Complet"):
            # G√©n√©ration du rapport Markdown
            rapport_md = f"""
# Rapport Strat√©gique IIBA Cameroun {datetime.now().year}

## Executive Summary
- **Total BA**: {total_ba}
- **Taux Certification**: {taux_certif:.1f}%
- **CA R√©alis√©**: {ca_total:,.0f} FCFA
- **Secteurs**: {diversite_sectorielle}

## Profil Type BA Camerounais
### D√©mographie
- R√©partition par genre: {dict(genre_counts)}
- Secteurs dominants: {dict(top_secteurs)}
- Localisation: Concentration Douala/Yaound√©

## Analyse SWOT
### Forces
- Diversit√© sectorielle ({diversite_sectorielle} secteurs)
- Engagement communautaire √©lev√©
- Base financi√®re solide

### Opportunit√©s  
- Transformation digitale
- Expansion r√©gionale
- Partenariats entreprises

## Balanced Scorecard
### Financi√®re
- CA: {ca_total:,.0f} FCFA
- Marge: {marge_benefice:.1f}%

### Client
- Satisfaction: {satisfaction_moy:.1f}/100
- R√©tention: {retention:.1f}%

Rapport g√©n√©r√© le {datetime.now().strftime('%Y-%m-%d %H:%M')}
"""
            
            st.download_button(
                "‚¨áÔ∏è T√©l√©charger Rapport.md",
                rapport_md,
                file_name=f"Rapport_IIBA_Cameroun_{datetime.now().strftime('%Y%m%d')}.md",
                mime="text/markdown"
            )
    
    with col_export2:
        # Export Excel complet des analyses
        buf_advanced = io.BytesIO()
        with pd.ExcelWriter(buf_advanced, engine="openpyxl") as writer:
            # Donn√©es enrichies
            dfc_enriched.to_excel(writer, sheet_name="Contacts_Enrichis", index=False)
            engagement_secteur.to_excel(writer, sheet_name="Engagement_Secteur")
            kpi_standards.to_excel(writer, sheet_name="KPI_Standards", index=False)
            actions_df.to_excel(writer, sheet_name="Plan_Actions", index=False)
            
        st.download_button(
            "üìä Export Analyses Excel",
            buf_advanced.getvalue(),
            file_name=f"Analyses_IIBA_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

# ---------------------- PAGE ADMIN ‚Äî Migration & Import/Export ----------------------

elif page == "Admin":
    st.title("‚öôÔ∏è Admin ‚Äî Param√®tres, Migration & Maintenance (centralis√©s dans parametres.csv)")

    # PARAMETRES LISTES DEROULANTES
    st.markdown("### Listes d√©roulantes (stock√©es dans parametres.csv)")
    with st.form("lists_form"):
        def show_line(name, label):
            raw = PARAMS.get(f"list_{name}", DEFAULT_LISTS.get(name, ""))
            return st.text_input(label, raw)
        genres = show_line("genres","Genres (s√©par√©s par |)")
        types_contact = show_line("types_contact","Types de contact (|)")
        statuts_engagement = show_line("statuts_engagement","Statuts d'engagement (|)")
        secteurs = show_line("secteurs","Secteurs (|)")
        pays = show_line("pays","Pays (|)")
        villes = show_line("villes","Villes (|)")
        sources = show_line("sources","Sources (|)")
        canaux = show_line("canaux","Canaux (|)")
        resultats_inter = show_line("resultats_inter","R√©sultats d'interaction (|)")
        types_evenements = show_line("types_evenements","Types d'√©v√©nements (|)")
        lieux = show_line("lieux","Lieux (|)")
        statuts_paiement = show_line("statuts_paiement","Statuts paiement (|)")
        moyens_paiement = show_line("moyens_paiement","Moyens paiement (|)")
        types_certif = show_line("types_certif","Types certification (|)")
        entreprises_cibles = show_line("entreprises_cibles","Entreprises cibles (Top-20) (|)")
        ok1 = st.form_submit_button("üíæ Enregistrer les listes")
        if ok1:
            PARAMS.update({
                "list_genres": genres, "list_types_contact": types_contact, "list_statuts_engagement": statuts_engagement,
                "list_secteurs": secteurs, "list_pays": pays, "list_villes": villes, "list_sources": sources,
                "list_canaux": canaux, "list_resultats_inter": resultats_inter, "list_types_evenements": types_evenements,
                "list_lieux": lieux, "list_statuts_paiement": statuts_paiement, "list_moyens_paiement": moyens_paiement,
                "list_types_certif": types_certif, "list_entreprises_cibles": entreprises_cibles,
            })
            save_params(PARAMS)
            st.success("Listes enregistr√©es dans parametres.csv ‚Äî rechargez la page si n√©cessaire.")

    # PARAMETRES SCORING ET AFFICHAGE
    st.markdown("### R√®gles de scoring & d'affichage (parametres.csv)")
    with st.form("rules_form"):
        c1,c2,c3,c4 = st.columns(4)
        vip_thr = c1.number_input("Seuil VIP (FCFA)", min_value=0.0, step=50000.0, value=float(PARAMS.get("vip_threshold","500000")))
        w_int = c2.number_input("Poids Interaction", min_value=0.0, step=0.5, value=float(PARAMS.get("score_w_interaction","1")))
        w_part = c3.number_input("Poids Participation", min_value=0.0, step=0.5, value=float(PARAMS.get("score_w_participation","1")))
        w_pay = c4.number_input("Poids Paiement r√©gl√©", min_value=0.0, step=0.5, value=float(PARAMS.get("score_w_payment_regle","2")))
        c5,c6,c7 = st.columns(3)
        lookback = c5.number_input("Fen√™tre interactions r√©centes (jours)", min_value=1, step=1, value=int(PARAMS.get("interactions_lookback_days","90")))
        hot_int_min = c6.number_input("Interactions r√©centes min (chaud)", min_value=0, step=1, value=int(PARAMS.get("rule_hot_interactions_recent_min","3")))
        hot_part_min = c7.number_input("Participations min (chaud)", min_value=0, step=1, value=int(PARAMS.get("rule_hot_participations_min","1")))
        hot_partiel = st.checkbox("Paiement partiel = prospect chaud", value=PARAMS.get("rule_hot_payment_partial_counts_as_hot","1") in ("1","true","True"))

        st.write("**Colonnes de la grille CRM (ordre, s√©par√©es par des virgules)**")
        grid_crm = st.text_input("CRM ‚Üí Colonnes", PARAMS.get("grid_crm_columns",""))
        st.caption("Colonnes disponibles : " + ", ".join(sorted(list(set(C_COLS + I_COLS + E_COLS + P_COLS + PAY_COLS + CERT_COLS + ['Interactions','Participations','CA_r√©gl√©','Impay√©','Resp_principal','A_anim√©_ou_invit√©','Score_composite','Proba_conversion','Tags','Dernier_contact','Interactions_recent'])))))

        st.write("**KPI visibles (s√©par√©s par des virgules)**")
        st.caption("Cl√©s support√©es : contacts_total, prospects_actifs, membres, events_count, participations_total, ca_regle, impayes, taux_conversion")
        kpi_enabled = st.text_input("KPI activ√©s", PARAMS.get("kpi_enabled",""))

        st.write("**Objectifs annuels/mensuels (format cl√©=valeur)**")
        st.caption("Ex. kpi_target_contacts_total_year_2025=1000 ; kpi_target_participations_total_month_202506=120")
        targets_text = st.text_area("Cibles (une par ligne)", "\n".join([f"{k}={v}" for k,v in PARAMS.items() if k.startswith("kpi_target_")]))

        ok2 = st.form_submit_button("üíæ Enregistrer (parametres.csv)")
        if ok2:
            PARAMS.update({
                "vip_threshold": str(vip_thr),
                "score_w_interaction": str(w_int),
                "score_w_participation": str(w_part),
                "score_w_payment_regle": str(w_pay),
                "interactions_lookback_days": str(int(lookback)),
                "rule_hot_interactions_recent_min": str(int(hot_int_min)),
                "rule_hot_participations_min": str(int(hot_part_min)),
                "rule_hot_payment_partial_counts_as_hot": "1" if hot_partiel else "0",
                "grid_crm_columns": grid_crm,
                "kpi_enabled": kpi_enabled,
            })
            for line in targets_text.splitlines():
                if "=" in line:
                    key, val = line.split("=",1)
                    key = key.strip()
                    val = val.strip()
                    if key:
                        PARAMS[key] = val
            save_params(PARAMS)
            st.success("Param√®tres enregistr√©s dans parametres.csv ‚Äî les nouvelles listes seront prises en compte au prochain rafra√Æchissement.")

    # PARAMETRES Rapports Avanc√©s
    # Dans la section des param√®tres Admin, ajouter:
    st.markdown("---")
    st.header("üìä Param√®tres Rapports Avanc√©s")
    
    with st.form("advanced_reports_params"):
        st.subheader("üéØ Seuils et Objectifs")
        
        col_p1, col_p2 = st.columns(2)
        
        with col_p1:
            # Seuils de segmentation
            seuil_ba_expert = st.number_input(
                "Score BA Expert (seuil)", 
                min_value=0, max_value=100, 
                value=int(PARAMS.get("seuil_ba_expert", "70"))
            )
            seuil_formation_continue = st.number_input(
                "Participations min. formation continue", 
                min_value=0, 
                value=int(PARAMS.get("seuil_formation_continue", "2"))
            )
            objectif_certification = st.number_input(
                "Objectif taux certification (%)", 
                min_value=0, max_value=100, 
                value=int(PARAMS.get("objectif_certification", "30"))
            )
        
        with col_p2:
            # Estimations salariales par secteur
            salaire_banque = st.number_input(
                "Salaire moyen Banque (FCFA)", 
                min_value=0, step=50000,
                value=int(PARAMS.get("salaire_banque", "800000"))
            )
            salaire_telecom = st.number_input(
                "Salaire moyen T√©l√©com (FCFA)", 
                min_value=0, step=50000,
                value=int(PARAMS.get("salaire_telecom", "750000"))
            )
            multiplicateur_certif = st.number_input(
                "Multiplicateur salaire certifi√©", 
                min_value=1.0, max_value=2.0, step=0.1,
                value=float(PARAMS.get("multiplicateur_certif", "1.3"))
            )
        
        # Objectifs BSC
        st.subheader("üìà Objectifs Balanced Scorecard")
        col_bsc1, col_bsc2 = st.columns(2)
        
        with col_bsc1:
            objectif_croissance_ca = st.number_input(
                "Objectif croissance CA (%/an)", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_croissance_ca", "20"))
            )
            objectif_marge = st.number_input(
                "Objectif marge b√©n√©fice (%)", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_marge", "25"))
            )
        
        with col_bsc2:
            objectif_retention = st.number_input(
                "Objectif taux r√©tention (%)", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_retention", "80"))
            )
            objectif_nps = st.number_input(
                "Objectif NPS", 
                min_value=0, max_value=100,
                value=int(PARAMS.get("objectif_nps", "70"))
            )
        
        if st.form_submit_button("üíæ Enregistrer Param√®tres Avanc√©s"):
            PARAMS.update({
                "seuil_ba_expert": str(seuil_ba_expert),
                "seuil_formation_continue": str(seuil_formation_continue),
                "objectif_certification": str(objectif_certification),
                "salaire_banque": str(salaire_banque),
                "salaire_telecom": str(salaire_telecom),
                "multiplicateur_certif": str(multiplicateur_certif),
                "objectif_croissance_ca": str(objectif_croissance_ca),
                "objectif_marge": str(objectif_marge),
                "objectif_retention": str(objectif_retention),
                "objectif_nps": str(objectif_nps)
            })
            save_params(PARAMS)
            st.success("‚úÖ Param√®tres avanc√©s enregistr√©s!")
    

    # PARAMETRES Migration ‚Äî Import/Export
    st.markdown("---")
    st.header("üì¶ Migration ‚Äî Import/Export Global & Multi-onglets")

    mode_mig = st.radio("Mode de migration", ["Import Excel par Table (.xlsx)", "Import Excel global (.xlsx)", "Import Excel multi-onglets (.xlsx)", "Import CSV global"], horizontal=True)

    if mode_mig == "Import Excel global (.xlsx)":
        up = st.file_uploader("Fichier Excel global (.xlsx)", type=["xlsx"], key="xlsx_up")
        st.caption("Feuille **Global** (ou 1√®re) avec colonne **__TABLE__**.")
        if st.button("Importer l'Excel global") and up is not None:
            log = {"timestamp": datetime.now().isoformat(), "import_type": "excel_global", "counts": {}, "errors": [], "collisions": {}}
            try:
                xls = pd.ExcelFile(up)
                sheet = "Global" if "Global" in xls.sheet_names else xls.sheet_names[0]
                gdf = pd.read_excel(xls, sheet_name=sheet, dtype=str)
                if "__TABLE__" not in gdf.columns:
                    raise ValueError("Colonne '__TABLE__' manquante.")
                cols_global = ["__TABLE__"] + sorted(set(sum(ALL_SCHEMAS.values(), [])))
                for c in cols_global:
                    if c not in gdf.columns:
                        gdf[c] = ""
                # Contacts
                sub_c = gdf[gdf["__TABLE__"] == "contacts"].copy().fillna("")
                sub_c["Top20"] = sub_c["Soci√©t√©"].fillna("").apply(lambda x: x in SET["entreprises_cibles"])

                def dedupe_contacts(df):
                    df = df.copy()
                    rejects = []
                    seen = set()
                    keep = []
                    def norm(s):
                        return str(s).strip().lower()
                    def email_ok2(s):
                        if not s or str(s).strip() == "" or str(s).lower() == "nan":
                            return True
                        return bool(re.match(r"^[^@\s]+@[^@\s]+\.[^@\s]+$", str(s).strip()))
                    for _, r in df.iterrows():
                        if not email_ok2(r.get("Email", "")):
                            rr = r.to_dict()
                            rr["_Raison"] = "Email invalide"
                            rejects.append(rr)
                            continue
                        if r.get("Email", ""):
                            key = ("email", norm(r["Email"]))
                        elif r.get("T√©l√©phone", ""):
                            key = ("tel", norm(r["T√©l√©phone"]))
                        else:
                            key = ("nps", (norm(r.get("Nom", "")), norm(r.get("Pr√©nom", "")), norm(r.get("Soci√©t√©", ""))))
                        if key in seen:
                            rr = r.to_dict()
                            rr["_Raison"] = "Doublon (fichier)"
                            rejects.append(rr)
                            continue
                        seen.add(key)
                        keep.append(r)
                    return pd.DataFrame(keep, columns=C_COLS), pd.DataFrame(rejects)

                valid_c, rejects_c = dedupe_contacts(sub_c)
                base = df_contacts.copy()
                collisions = []
                if "ID" in valid_c.columns and not valid_c.empty:
                    incoming = set(x for x in valid_c["ID"].astype(str) if x and x.lower() != "nan")
                    existing = set(base["ID"].astype(str))
                    collisions = sorted(list(incoming & existing))
                    if collisions:
                        base = base[~base["ID"].isin(collisions)]
                patt = re.compile(r"^CNT_(\d+)$")
                base_max = 0
                for x in base["ID"].dropna().astype(str):
                    m = patt.match(x.strip())
                    if m:
                        try:
                            base_max = max(base_max, int(m.group(1)))
                        except:
                            pass
                next_id = base_max + 1
                new_rows=[]
                for _, r in valid_c.iterrows():
                    rid = r["ID"]
                    if not isinstance(rid, str) or rid.strip() == "" or rid.strip().lower() == "nan":
                        rid = f"CNT_{str(next_id).zfill(3)}"
                        next_id += 1
                    rr = r.to_dict()
                    rr["ID"] = rid
                    new_rows.append(rr)
                base = pd.concat([base, pd.DataFrame(new_rows, columns=C_COLS)], ignore_index=True)
                save_df(base, PATHS["contacts"])
                globals()["df_contacts"] = base
                log["counts"]["contacts"] = len(new_rows)
                log["collisions"]["contacts"] = collisions
                if not rejects_c.empty:
                    st.warning(f"Lignes contacts rejet√©es : {len(rejects_c)}")
                    st.dataframe(rejects_c, use_container_width=True)

                # Fonction pour enregistrer subsets
                def save_subset(tbl, cols, path, prefix):
                    sub = gdf[gdf["__TABLE__"] == tbl].copy()
                    sub = sub[cols].fillna("")
                    id_col = cols[0]
                    base_df = ensure_df(path, cols)
                    incoming = set(x for x in sub[id_col].astype(str) if x and x.lower() != "nan")
                    existing = set(base_df[id_col].astype(str))
                    coll = sorted(list(incoming & existing))
                    if coll:
                        base_df = base_df[~base_df[id_col].isin(coll)]
                    patt = re.compile(rf"^{prefix}_(\d+)$")
                    base_max = 0
                    for x in base_df[id_col].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    gen = base_max + 1
                    new_rows = []
                    for _, r in sub.iterrows():
                        cur = r[id_col]
                        if not isinstance(cur, str) or cur.strip() == "" or cur.strip().lower() == "nan":
                            cur = f"{prefix}_{str(gen).zfill(3)}"
                            gen += 1
                        rr = r.to_dict()
                        rr[id_col] = cur
                        new_rows.append(rr)
                    out = pd.concat([base_df, pd.DataFrame(new_rows, columns=cols)], ignore_index=True)
                    save_df(out, path)
                    globals()["df_" + ("inter" if tbl == "interactions" else "events" if tbl == "evenements" else "parts" if tbl == "participations" else "pay" if tbl == "paiements" else "cert")] = out
                    log["counts"][tbl] = len(new_rows)
                    log["collisions"][tbl] = coll

                for spec in [("interactions", I_COLS, PATHS["inter"], "INT"),
                             ("evenements", E_COLS, PATHS["events"], "EVT"),
                             ("participations", P_COLS, PATHS["parts"], "PAR"),
                             ("paiements", PAY_COLS, PATHS["pay"], "PAY"),
                             ("certifications", CERT_COLS, PATHS["cert"], "CER")]:
                    cnt, coll = save_subset(*spec)

                st.success("Import Excel global termin√©.")
                st.json(log)
                log_event("import_excel_global", log)
            except Exception as e:
                st.error(f"Erreur d'import Excel global : {e}")
                log_event("error_import_excel_global", {"error": str(e)})

        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="openpyxl") as w:
            gcols = ["__TABLE__"] + sorted(set(sum(ALL_SCHEMAS.values(), [])))
            pd.DataFrame(columns=gcols).to_excel(w, index=False, sheet_name="Global")
        st.download_button("‚¨áÔ∏è Mod√®le Global (xlsx)", buf.getvalue(), file_name="IIBA_global_template.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    # Dans la section Admin ‚Äî Migration & Import/Export, ajoutez apr√®s le mode "Import Excel multi-onglets" :
    elif mode_mig == "Import Excel par Table (.xlsx)":
        st.subheader("Import Excel par table (1 onglet par table)")
        fichier_multi = st.file_uploader(
            "Classeur Excel (.xlsx) avec un onglet par table : contacts, interactions, evenements, participations, paiements, certifications",
            type=["xlsx"], key="xlsx_par_table"
        )
        if st.button("Importer Excel par table") and fichier_multi is not None:
            log = {"ts": datetime.now().isoformat(), "type": "excel_par_table", "counts": {}, "errors": []}
            try:
                xls = pd.ExcelFile(fichier_multi)
                # mapping des noms d‚Äôonglets attendus
                expected = {
                    "contacts": C_COLS,
                    "interactions": I_COLS,
                    "evenements": E_COLS,
                    "participations": P_COLS,
                    "paiements": PAY_COLS,
                    "certifications": CERT_COLS
                }
                for sheet_name, cols in expected.items():
                    if sheet_name in xls.sheet_names:
                        df_in = pd.read_excel(xls, sheet_name=sheet_name, dtype=str).fillna("")
                        # garantir toutes les colonnes
                        for c in cols:
                            if c not in df_in.columns:
                                df_in[c] = ""
                        df_in = df_in[cols]
                        path = PATHS[sheet_name if sheet_name!="evenements" else "events"]
                        df_base = ensure_df(path, cols)
                        # d√©duplication / attribution d‚ÄôID
                        prefix = {"contacts":"CNT","interactions":"INT",
                                  "evenements":"EVT","participations":"PAR",
                                  "paiements":"PAY","certifications":"CER"}[sheet_name]
                        # s√©parer existants et nouveaux
                        exist_ids = set(df_base[cols[0]].astype(str))
                        new_rows = []
                        next_num = None
                        patt = re.compile(rf"^{prefix}_(\d+)$")
                        # calculer prochain num√©ro si n√©cessaire
                        if cols[0] in df_base.columns:
                            maxn = 0
                            for vid in exist_ids:
                                m = patt.match(vid)
                                if m:
                                    maxn = max(maxn, int(m.group(1)))
                            next_num = maxn + 1
                        for _, row in df_in.iterrows():
                            rid = str(row[cols[0]]).strip()
                            if not rid or rid.lower()=="nan" or rid in exist_ids:
                                rid = f"{prefix}_{str(next_num).zfill(3)}"
                                next_num += 1
                            row_data = row.to_dict()
                            row_data[cols[0]] = rid
                            new_rows.append(row_data)
                        if new_rows:
                            df_out = pd.concat([df_base, pd.DataFrame(new_rows, columns=cols)], ignore_index=True)
                            save_df(df_out, path)
                            globals()[f"df_{sheet_name if sheet_name!='evenements' else 'events'}"] = df_out
                            log["counts"][sheet_name] = len(new_rows)
                        else:
                            log["counts"][sheet_name] = 0
                    else:
                        log["errors"].append(f"Feuille manquante : {sheet_name}")
                st.success("Import par table termin√©.")
                st.json(log)
                log_event("import_excel_par_table", log)
            except Exception as e:
                st.error(f"Erreur lors de l'import par table : {e}")
                log_event("error_import_excel_par_table", {"error": str(e)})
        

    elif mode_mig == "Import Excel multi-onglets (.xlsx)":
        up = st.file_uploader("Classeur Excel (6 feuilles : contacts, interactions, evenements, participations, paiements, certifications)",
                             type=["xlsx"], key="xlsx_multi")
        if st.button("Importer l'Excel multi-onglets") and up is not None:
            log = {"timestamp": datetime.now().isoformat(), "import_type": "excel_multisheets", "counts": {}, "errors": [], "collisions": {}}
            try:
                xls = pd.ExcelFile(up)

                def norm(s):
                    return ''.join(c for c in unicodedata.normalize('NFD', str(s)) if unicodedata.category(c) != 'Mn').lower().strip()

                sheets = {norm(n): n for n in xls.sheet_names}
                aliases = {
                    "contacts": ["contacts", "contact"],
                    "interactions": ["interactions", "interaction"],
                    "evenements": ["evenements", "√©v√©nements", "events"],
                    "participations": ["participations", "participation"],
                    "paiements": ["paiements", "paiement", "payments"],
                    "certifications": ["certifications", "certification"]
                }
                found = {}
                for tbl, names in aliases.items():
                    for n in names:
                        k = norm(n)
                        if k in sheets:
                            found[tbl] = sheets[k]
                            break

                if "contacts" in found:
                    gdf = pd.read_excel(xls, sheet_name=found["contacts"], dtype=str).fillna("")
                    for c in C_COLS:
                        if c not in gdf.columns:
                            gdf[c] = ""
                    sub_c = gdf[C_COLS].fillna("")
                    sub_c["Top20"] = sub_c["Soci√©t√©"].fillna("").apply(lambda x: x in SET["entreprises_cibles"])

                    seen = set()
                    keep = []
                    for _, r in sub_c.iterrows():
                        key = r.get("Email", "") or r.get("T√©l√©phone", "") or (r.get("Nom", ""), r.get("Pr√©nom", ""), r.get("Soci√©t√©", ""))
                        if key in seen:
                            continue
                        seen.add(key)
                        keep.append(r)
                    valid_c = pd.DataFrame(keep, columns=C_COLS)
                    base = df_contacts.copy()
                    collisions = []
                    if "ID" in valid_c.columns and not valid_c.empty:
                        incoming = set(x for x in valid_c["ID"].astype(str) if x and x.lower() != "nan")
                        existing = set(base["ID"].astype(str))
                        collisions = sorted(list(incoming & existing))
                        if collisions:
                            base = base[~base["ID"].isin(collisions)]
                    patt = re.compile(r"^CNT_(\d+)$")
                    base_max = 0
                    for x in base["ID"].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    next_id = base_max + 1
                    new_rows = []
                    for _, r in valid_c.iterrows():
                        rid = r["ID"]
                        if not isinstance(rid, str) or rid.strip() == "" or rid.strip().lower() == "nan":
                            rid = f"CNT_{str(next_id).zfill(3)}"
                            next_id += 1
                        rr = r.to_dict()
                        rr["ID"] = rid
                        new_rows.append(rr)
                    out = pd.concat([base, pd.DataFrame(new_rows, columns=C_COLS)], ignore_index=True)
                    save_df(out, PATHS["contacts"])
                    globals()["df_contacts"] = out
                    log["counts"]["contacts"] = len(new_rows)
                    log["collisions"]["contacts"] = collisions

                def save_sheet(tbl, cols, path, prefix):
                    if tbl not in found:
                        return 0, []
                    sdf = pd.read_excel(xls, sheet_name=found[tbl], dtype=str).fillna("")
                    for c in cols:
                        if c not in sdf.columns:
                            sdf[c] = ""
                    sdf = sdf[cols]
                    id_col = cols[0]
                    base_df = ensure_df(path, cols)
                    incoming = set(x for x in sdf[id_col].astype(str) if x and x.lower() != "nan")
                    existing = set(base_df[id_col].astype(str))
                    coll = sorted(list(incoming & existing))
                    if coll:
                        base_df = base_df[~base_df[id_col].isin(coll)]
                    patt = re.compile(rf"^{prefix}_(\d+)$")
                    base_max = 0
                    for x in base_df[id_col].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    gen = base_max + 1
                    new_rows = []
                    for _, r in sdf.iterrows():
                        cur = r[id_col]
                        if not isinstance(cur, str) or cur.strip() == "" or cur.strip().lower() == "nan":
                            cur = f"{prefix}_{str(gen).zfill(3)}"
                            gen += 1
                        rr = r.to_dict()
                        rr[id_col] = cur
                        new_rows.append(rr)
                    out = pd.concat([base_df, pd.DataFrame(new_rows, columns=cols)], ignore_index=True)
                    save_df(out, path)
                    globals()["df_" + ("inter" if tbl == "interactions" else 
                                      "events" if tbl == "evenements" else 
                                      "parts" if tbl == "participations" else 
                                      "pay" if tbl == "paiements" else "cert")] = out
                    return len(new_rows), coll

                for spec in [("interactions", I_COLS, PATHS["inter"], "INT"),
                             ("evenements", E_COLS, PATHS["events"], "EVT"),
                             ("participations", P_COLS, PATHS["parts"], "PAR"),
                             ("paiements", PAY_COLS, PATHS["pay"], "PAY"),
                             ("certifications", CERT_COLS, PATHS["cert"], "CER")]:
                    cnt, coll = save_sheet(*spec)
                    log["counts"][spec[0]] = cnt
                    log["collisions"][spec] = coll

                st.success("Import Excel multi-onglets termin√©.")
                st.json(log)
                log_event("import_excel_multisheets", log)
            except Exception as e:
                st.error(f"Erreur d'import multi-onglets: {e}")
                log_event("error_import_excel_multisheets", {"error": str(e)})

        bufm = io.BytesIO()
        with pd.ExcelWriter(bufm, engine="openpyxl") as w:
            pd.DataFrame(columns=C_COLS).to_excel(w, index=False, sheet_name="contacts")
            pd.DataFrame(columns=I_COLS).to_excel(w, index=False, sheet_name="interactions")
            pd.DataFrame(columns=E_COLS).to_excel(w, index=False, sheet_name="evenements")
            pd.DataFrame(columns=P_COLS).to_excel(w, index=False, sheet_name="participations")
            pd.DataFrame(columns=PAY_COLS).to_excel(w, index=False, sheet_name="paiements")
            pd.DataFrame(columns=CERT_COLS).to_excel(w, index=False, sheet_name="certifications")
        st.download_button("‚¨áÔ∏è Mod√®le Multi-onglets (xlsx)", bufm.getvalue(), file_name="IIBA_multisheets_template.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    elif mode_mig == "Import CSV global":
        up = st.file_uploader("CSV global (colonne __TABLE__)", type=["csv"], key="g_up")
        if st.button("Importer le CSV global") and up is not None:
            try:
                gdf = pd.read_csv(up, dtype=str, encoding="utf-8")
                if "__TABLE__" not in gdf.columns:
                    raise ValueError("Colonne __TABLE__ manquante.")
                def save_subset(tbl, cols, path, prefix):
                    sub = gdf[gdf["__TABLE__"] == tbl].copy()
                    for c in cols:
                        if c not in sub.columns:
                            sub[c] = ""
                    sub = sub[cols].fillna("")
                    id_col = cols[0]
                    base_df = ensure_df(path, cols)
                    incoming = set(x for x in sub[id_col].astype(str) if x and x.lower() != "nan")
                    existing = set(base_df[id_col].astype(str))
                    coll = sorted(list(incoming & existing))
                    if coll:
                        base_df = base_df[~base_df[id_col].isin(coll)]
                    patt = re.compile(rf"^{prefix}_(\d+)$")
                    base_max = 0
                    for x in base_df[id_col].dropna().astype(str):
                        m = patt.match(x.strip())
                        if m:
                            try:
                                base_max = max(base_max, int(m.group(1)))
                            except:
                                pass
                    gen = base_max + 1
                    ids = []
                    for _, r in sub.iterrows():
                        rid = r[id_col]
                        if not isinstance(rid, str) or rid.strip() == "" or rid.strip().lower() == "nan":
                            ids.append(f"{prefix}_{str(gen).zfill(3)}")
                            gen += 1
                        else:
                            ids.append(rid.strip())
                    sub[id_col] = ids
                    out = pd.concat([base_df, sub], ignore_index=True)
                    save_df(out, path)
                    globals()["df_" + ("contacts" if tbl == "contacts" else "inter" if tbl == "interactions" else "events" if tbl == "evenements" else "parts" if tbl == "participations" else "pay" if tbl == "paiements" else "cert")] = out
                save_subset("contacts", C_COLS, PATHS["contacts"], "CNT")
                save_subset("interactions", I_COLS, PATHS["inter"], "INT")
                save_subset("evenements", E_COLS, PATHS["events"], "EVT")
                save_subset("participations", P_COLS, PATHS["parts"], "PAR")
                save_subset("paiements", PAY_COLS, PATHS["pay"], "PAY")
                save_subset("certifications", CERT_COLS, PATHS["cert"], "CER")
                st.success("Import CSV global termin√©.")
            except Exception as e:
                st.error(f"Erreur d'import CSV global : {e}")

    # ... code existant load_and_compute_kpis() ...

    st.markdown("---")
    st.header("üîß Maintenance Base de Donn√©es")
    
    col_reset, col_purge = st.columns(2)
    
    with col_reset:
        st.subheader("üóëÔ∏è R√©initialisation Compl√®te")
        st.warning("‚ö†Ô∏è Cette action supprime TOUTES les donn√©es et recr√©e les fichiers vides.")
        
        confirm_reset = st.text_input(
            "Tapez 'RESET' pour confirmer:",
            placeholder="RESET"
        )
        
        if st.button("üí£ R√âINITIALISER LA BASE", type="secondary"):
            if confirm_reset == "RESET":
                try:
                    # Suppression de tous les fichiers CSV
                    for path in PATHS.values():
                        if path.exists():
                            path.unlink()
                    
                    # Recr√©ation des fichiers vides
                    for table, cols in ALL_SCHEMAS.items():
                        empty_df = pd.DataFrame(columns=cols)
                        save_df(empty_df, PATHS[table])
                    
                    # Recr√©ation parametres.csv
                    df_params = pd.DataFrame({
                        "key": list(ALL_DEFAULTS.keys()), 
                        "value": list(ALL_DEFAULTS.values())
                    })
                    df_params.to_csv(PATHS["params"], index=False, encoding="utf-8")
                    
                    # Journalisation
                    log_event("reset_database", {
                        "action": "R√©initialisation compl√®te",
                        "tables_recreated": list(ALL_SCHEMAS.keys()),
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    st.success("‚úÖ Base de donn√©es r√©initialis√©e avec succ√®s!")
                    st.info("üîÑ Rechargez la page pour voir les modifications.")
                    
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de la r√©initialisation: {e}")
                    log_event("error_reset_database", {"error": str(e)})
            else:
                st.error("‚ùå Veuillez taper 'RESET' pour confirmer.")
    
    with col_purge:
        st.subheader("üéØ Purge d'un Identifiant")
        st.info("Supprime un contact, √©v√©nement, interaction, etc. par son ID")
        
        purge_id = st.text_input(
            "ID √† supprimer (ex: CNT_001, EVT_005, INT_023):",
            placeholder="CNT_001"
        )
        
        purge_type = st.selectbox(
            "Type d'entit√©:",
            ["Auto-d√©tection", "Contact", "√âv√©nement", "Interaction", "Participation", "Paiement", "Certification"]
        )
        
        if st.button("üóëÔ∏è PURGER CET ID", type="secondary"):
            if purge_id:
                try:
                    deleted_count = 0
                    deleted_from = []
                    
                    if purge_type == "Auto-d√©tection":
                        # D√©tection automatique bas√©e sur le pr√©fixe
                        if purge_id.startswith("CNT_"):
                            purge_type = "Contact"
                        elif purge_id.startswith("EVT_"):
                            purge_type = "√âv√©nement"
                        elif purge_id.startswith("INT_"):
                            purge_type = "Interaction"
                        elif purge_id.startswith("PAR_"):
                            purge_type = "Participation"
                        elif purge_id.startswith("PAY_"):
                            purge_type = "Paiement"
                        elif purge_id.startswith("CER_"):
                            purge_type = "Certification"
                    
                    # Suppression selon le type
                    if purge_type == "Contact":
                        # Suppression en cascade: contact + toutes ses relations
                        original_len = len(df_contacts)
                        globals()["df_contacts"] = df_contacts[df_contacts["ID"] != purge_id]
                        deleted_count += original_len - len(df_contacts)
                        if deleted_count > 0:
                            save_df(df_contacts, PATHS["contacts"])
                            deleted_from.append("contacts")
                        
                        # Suppression interactions li√©es
                        original_len = len(df_inter)
                        globals()["df_inter"] = df_inter[df_inter["ID"] != purge_id]
                        inter_deleted = original_len - len(df_inter)
                        if inter_deleted > 0:
                            save_df(df_inter, PATHS["inter"])
                            deleted_from.append(f"interactions ({inter_deleted})")
                        
                        # Suppression participations li√©es
                        original_len = len(df_parts)
                        globals()["df_parts"] = df_parts[df_parts["ID"] != purge_id]
                        part_deleted = original_len - len(df_parts)
                        if part_deleted > 0:
                            save_df(df_parts, PATHS["parts"])
                            deleted_from.append(f"participations ({part_deleted})")
                        
                        # Suppression paiements li√©s
                        original_len = len(df_pay)
                        globals()["df_pay"] = df_pay[df_pay["ID"] != purge_id]
                        pay_deleted = original_len - len(df_pay)
                        if pay_deleted > 0:
                            save_df(df_pay, PATHS["pay"])
                            deleted_from.append(f"paiements ({pay_deleted})")
                        
                        # Suppression certifications li√©es
                        original_len = len(df_cert)
                        globals()["df_cert"] = df_cert[df_cert["ID"] != purge_id]
                        cert_deleted = original_len - len(df_cert)
                        if cert_deleted > 0:
                            save_df(df_cert, PATHS["cert"])
                            deleted_from.append(f"certifications ({cert_deleted})")
                    
                    elif purge_type == "√âv√©nement":
                        # Suppression √©v√©nement + participations + paiements li√©s
                        original_len = len(df_events)
                        globals()["df_events"] = df_events[df_events["ID_√âv√©nement"] != purge_id]
                        deleted_count += original_len - len(df_events)
                        if deleted_count > 0:
                            save_df(df_events, PATHS["events"])
                            deleted_from.append("evenements")
                        
                        # Suppression participations √† cet √©v√©nement
                        original_len = len(df_parts)
                        globals()["df_parts"] = df_parts[df_parts["ID_√âv√©nement"] != purge_id]
                        part_deleted = original_len - len(df_parts)
                        if part_deleted > 0:
                            save_df(df_parts, PATHS["parts"])
                            deleted_from.append(f"participations ({part_deleted})")
                        
                        # Suppression paiements √† cet √©v√©nement
                        original_len = len(df_pay)
                        globals()["df_pay"] = df_pay[df_pay["ID_√âv√©nement"] != purge_id]
                        pay_deleted = original_len - len(df_pay)
                        if pay_deleted > 0:
                            save_df(df_pay, PATHS["pay"])
                            deleted_from.append(f"paiements ({pay_deleted})")
                    
                    elif purge_type == "Interaction":
                        original_len = len(df_inter)
                        globals()["df_inter"] = df_inter[df_inter["ID_Interaction"] != purge_id]
                        deleted_count += original_len - len(df_inter)
                        if deleted_count > 0:
                            save_df(df_inter, PATHS["inter"])
                            deleted_from.append("interactions")
                    
                    elif purge_type == "Participation":
                        original_len = len(df_parts)
                        globals()["df_parts"] = df_parts[df_parts["ID_Participation"] != purge_id]
                        deleted_count += original_len - len(df_parts)
                        if deleted_count > 0:
                            save_df(df_parts, PATHS["parts"])
                            deleted_from.append("participations")
                    
                    elif purge_type == "Paiement":
                        original_len = len(df_pay)
                        globals()["df_pay"] = df_pay[df_pay["ID_Paiement"] != purge_id]
                        deleted_count += original_len - len(df_pay)
                        if deleted_count > 0:
                            save_df(df_pay, PATHS["pay"])
                            deleted_from.append("paiements")
                    
                    elif purge_type == "Certification":
                        original_len = len(df_cert)
                        globals()["df_cert"] = df_cert[df_cert["ID_Certif"] != purge_id]
                        deleted_count += original_len - len(df_cert)
                        if deleted_count > 0:
                            save_df(df_cert, PATHS["cert"])
                            deleted_from.append("certifications")
                    
                    # Journalisation
                    log_event("purge_id", {
                        "purged_id": purge_id,
                        "type": purge_type,
                        "deleted_count": deleted_count,
                        "tables_affected": deleted_from,
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    if deleted_count > 0 or deleted_from:
                        st.success(f"‚úÖ ID '{purge_id}' purg√© avec succ√®s!")
                        st.info(f"üìä Suppressions: {', '.join(deleted_from)}")
                        st.info("üîÑ Rechargez la page pour voir les modifications.")
                    else:
                        st.warning(f"‚ö†Ô∏è ID '{purge_id}' introuvable dans la base.")
                
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de la purge: {e}")
                    log_event("error_purge_id", {"purge_id": purge_id, "error": str(e)})
            else:
                st.error("‚ùå Veuillez saisir un ID √† purger.")
 
